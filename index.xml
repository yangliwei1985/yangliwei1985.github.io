<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ylw&#39;s blog</title>
    <link>https://iblog.zone/</link>
    <description>Recent content on ylw&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 25 May 2022 16:03:39 +0800</lastBuildDate><atom:link href="https://iblog.zone/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linux计划任务没有正常执行</title>
      <link>https://iblog.zone/archives/linux%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%E6%B2%A1%E6%9C%89%E6%AD%A3%E5%B8%B8%E6%89%A7%E8%A1%8C/</link>
      <pubDate>Wed, 25 May 2022 16:03:39 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/linux%E8%AE%A1%E5%88%92%E4%BB%BB%E5%8A%A1%E6%B2%A1%E6%9C%89%E6%AD%A3%E5%B8%B8%E6%89%A7%E8%A1%8C/</guid>
      <description>1、查看日志，报错如下：
May 25 15:50:01 localhost crond[42423]: (root) FAILED to authorize user with PAM (Authentication token is no longer valid; new one required) May 25 15:51:01 localhost crond[43791]: (root) PAM ERROR (Authentication token is no longer valid; new one required) 2、查找原因，可能为密码过期
查看密码过期时间
[root@localhost log]# chage -l root Last password change : Feb 21, 2022 Password expires : May 22, 2022 Password inactive : never Account expires : never Minimum number of days between password change : 0 Maximum number of days between password change : 90 Number of days of warning before password expires : 7 今天25日，22日就过期了</description>
    </item>
    
    <item>
      <title>GVM升级后启动异常处理</title>
      <link>https://iblog.zone/archives/gvm%E5%8D%87%E7%BA%A7%E5%90%8E%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 13 May 2022 18:10:06 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/gvm%E5%8D%87%E7%BA%A7%E5%90%8E%E5%90%AF%E5%8A%A8%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</guid>
      <description>1. Kali升级 apt-get update  apt-get dist-upgrade 2. 升级完成后，启动GVM（OpenVas）发现打不开 oot@Fkali:~# gvm-start [*] Please wait for the GVM / OpenVAS services to start. [*] [*] You might need to refresh your browser once it opens. [*] [*] Web UI (Greenbone Security Assistant): https://127.0.0.1:9392  Job for gvmd.service failed because a timeout was exceeded. See &amp;#34;systemctl status gvmd.service&amp;#34; and &amp;#34;journalctl -xe&amp;#34; for details. 3. 按照要求检测原因 oot@Fkali:~# systemctl status gvmd.service ● gvmd.service - Greenbone Vulnerability Manager daemon (gvmd)  Loaded: loaded (/lib/systemd/system/gvmd.</description>
    </item>
    
    <item>
      <title>Docker容器日志查看与清理</title>
      <link>https://iblog.zone/archives/docker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%E4%B8%8E%E6%B8%85%E7%90%86/</link>
      <pubDate>Fri, 06 May 2022 10:09:27 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker%E5%AE%B9%E5%99%A8%E6%97%A5%E5%BF%97%E6%9F%A5%E7%9C%8B%E4%B8%8E%E6%B8%85%E7%90%86/</guid>
      <description>1. 问题 docker容器日志导致主机磁盘空间满了。docker logs -f container_name噼里啪啦一大堆，很占用空间，不用的日志可以清理掉了。
2. 解决方法 2.1 找出Docker容器日志 在linux上，容器日志一般存放在/var/lib/docker/containers/container_id/下面， 以json.log结尾的文件（业务日志）很大，查看各个日志文件大小的脚本docker_log_size.sh，内容如下：
#!/bin/sh  echo &amp;#34;======== docker containers logs file size ========&amp;#34;  logs=$(find /var/lib/docker/containers/ -name *-json.log)  for log in $logs  do  ls -lh $log  done # chmod +x docker_log_size.sh  # ./docker_log_size.sh 2.2 清理Docker容器日志（治标) 如果docker容器正在运行，那么使用rm -rf方式删除日志后，通过df -h会发现磁盘空间并没有释放。原因是在Linux或者Unix系统中，通过rm -rf或者文件管理器删除文件，将会从文件系统的目录结构上解除链接（unlink）。如果文件是被打开的（有一个进程正在使用），那么进程将仍然可以读取该文件，磁盘空间也一直被占用。正确姿势是cat /dev/null &amp;gt; *-json.log，当然你也可以通过rm -rf删除后重启docker。接下来，提供一个日志清理脚本clean_docker_log.sh，内容如下：
#!/bin/sh  echo &amp;#34;======== start clean docker containers logs ========&amp;#34;  logs=$(find /var/lib/docker/containers/ -name *-json.</description>
    </item>
    
    <item>
      <title>Nginx Stream日志设置</title>
      <link>https://iblog.zone/archives/nginx-stream%E6%97%A5%E5%BF%97%E8%AE%BE%E7%BD%AE/</link>
      <pubDate>Wed, 27 Apr 2022 17:20:18 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nginx-stream%E6%97%A5%E5%BF%97%E8%AE%BE%E7%BD%AE/</guid>
      <description>nginx自1.9.0开始提供tcp/udp的反向代理功能，直到1.11.4才开始提供session日志功能。
启用stream日志配置文件 主配置文件/etc/nginx/nginx.conf增加内容：
stream { log_format proxy &amp;#39;$remote_addr [$time_local] &amp;#39; &amp;#39;$protocol $status $bytes_sent $bytes_received &amp;#39; &amp;#39;$session_time &amp;#34;$upstream_addr&amp;#34; &amp;#39; &amp;#39;&amp;#34;$upstream_bytes_sent&amp;#34; &amp;#34;$upstream_bytes_received&amp;#34; &amp;#34;$upstream_connect_time&amp;#34;&amp;#39;; access_log /var/log/nginx/tcp-access.log proxy ; open_log_file_cache off; include /etc/nginx/conf.d/*.stream; } 具体的tcp.stream配置文件
 upstream TCP59001 { hash $remote_addr consistent; server 192.168.1.176:59001; } server { listen 59001; proxy_connect_timeout 5s; proxy_timeout 30s; proxy_pass TCP59001; } nginx重读配置并检查tcp session日志的生成 nginx重读配置
nginx -s reload 检查日志
tail /var/log/nginx/tcp-access.log
192.168.3.218 [25/Apr/2017:17:55:57 +0800] TCP 200 103 122 10.671 &amp;#34;192.168.1.176:59001&amp;#34; &amp;#34;122&amp;#34; &amp;#34;103&amp;#34; &amp;#34;0.</description>
    </item>
    
    <item>
      <title>Docker Compose教程</title>
      <link>https://iblog.zone/archives/docker-compose%E6%95%99%E7%A8%8B/</link>
      <pubDate>Mon, 25 Apr 2022 17:37:50 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-compose%E6%95%99%E7%A8%8B/</guid>
      <description>1.Compose介绍 Docker Compose是一个用来定义和运行复杂应用的Docker工具。一个使用Docker容器的应用，通常由多个容器组成。使用Docker Compose不再需要使用shell脚本来启动容器。
Compose 通过一个配置文件来管理多个Docker容器，在配置文件中，所有的容器通过services来定义，然后使用docker-compose脚本来启动，停止和重启应用，和应用中的服务以及所有依赖服务的容器，非常适合组合使用多个容器进行开发的场景。
2.Compose和Docker兼容性    compose文件格式版本 docker版本     3.4 17.09.0+   3.3 17.06.0+   3.2 17.04.0+   3.1 1.13.1+   3.0 1.13.0+   2.3 17.06.0+   2.2 1.13.0+   2.1 1.12.0+   2.0 1.10.0+   1.0 1.9.1.+    Docker版本变化说明：
Docker从1.13.x版本开始，版本分为企业版EE和社区版CE，版本号也改为按照时间线来发布，比如17.03就是2017年3月。
Docker的linux发行版的软件仓库从以前的https://apt.dockerproject.org和https://yum.dockerproject.org变更为目前的https://download.docker.com, 软件包名字改为docker-ce和docker-ee。
3.安装docker Docker的社区版（Docker Community Edition）叫做docker-ce。老版本的Docker包叫做docker或者docker-engine，如果安装了老版本的docker得先卸载然后再安装新版本的docker。docker的发展非常迅速，apt源的更新往往比较滞后。所以docker官网推荐的安装方式都是下载docker安装脚本安装。
卸载老旧的版本（若未安装过可省略此步）：
$ sudo apt-get remove docker docker-engine docker.</description>
    </item>
    
    <item>
      <title>Java基础加强03</title>
      <link>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA03/</link>
      <pubDate>Sun, 24 Apr 2022 16:08:43 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA03/</guid>
      <description>1.管理系统与服务器集成 1.1准备工作【应用】   需求
对之前写过的黑马信息管理系统进行改进,实现可以通过浏览器进行访问的功能
  准备工作
  将资料中的黑马管理系统代码拷贝到当前模块下
  导包的代码可能报错,因为之前的包路径可能和当前代码不一致,将导包的代码修改下
    业务分析
 解析URL封装到HttpReques对象 DynamicResourceProcess类（执行指定动态资源的service方法） 定义servlet类完成查询学生、添加学生、删除学生、修改学生的逻辑    项目结构
  1.2HttpRequest类代码实现【应用】   实现步骤
 提供一个存储url中用户信息的map集合 提供一个getParamter方法,用于根据请求参数的名称获取请求参数的值 提供一个parseParamter方法,用于解析请求参数把请求参数存储到map集合中    代码实现
// 此处只给出了新增的代码,其他代码同之前没有变化 public class HttpRequest {   //用来存储请求URL中问号后面的那些数据  //id=1 name=itheima  private Map&amp;lt;String,String&amp;gt; paramterHashMap = new HashMap&amp;lt;&amp;gt;();   //parse --- 获取请求数据 并解析  public void parse(){  try {  SocketChannel socketChannel = (SocketChannel) selectionKey.</description>
    </item>
    
    <item>
      <title>Java基础加强02</title>
      <link>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA02/</link>
      <pubDate>Sun, 24 Apr 2022 15:49:35 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA02/</guid>
      <description>1.xml 1.1概述【理解】   万维网联盟(W3C)
万维网联盟(W3C)创建于1994年，又称W3C理事会。1994年10月在麻省理工学院计算机科学实验室成立。 建立者： Tim Berners-Lee (蒂姆·伯纳斯·李)。 是Web技术领域最具权威和影响力的国际中立性技术标准机构。 到目前为止，W3C已发布了200多项影响深远的Web技术标准及实施指南，
  如广为业界采用的超文本标记语言HTML（标准通用标记语言下的一个应用）、
  可扩展标记语言XML（标准通用标记语言下的一个子集）
  以及帮助残障人士有效获得Web信息的无障碍指南（WCAG）等
    xml概述
XML的全称为(EXtensible Markup Language)，是一种可扩展的标记语言 标记语言: 通过标签来描述数据的一门语言(标签有时我们也将其称之为元素) 可扩展：标签的名字是可以自定义的,XML文件是由很多标签组成的,而标签名是可以自定义的
  作用
 用于进行存储数据和传输数据 作为软件的配置文件    作为配置文件的优势
 可读性好 可维护性高    1.2标签的规则【应用】   标签由一对尖括号和合法标识符组成
&amp;lt;student&amp;gt;   标签必须成对出现
&amp;lt;student&amp;gt; &amp;lt;/student&amp;gt; 前边的是开始标签，后边的是结束标签   特殊的标签可以不成对,但是必须有结束标记
&amp;lt;address/&amp;gt;   标签中可以定义属性,属性和标签名空格隔开,属性值必须用引号引起来
&amp;lt;student id=&amp;#34;1&amp;#34;&amp;gt; &amp;lt;/student&amp;gt;   标签需要正确的嵌套</description>
    </item>
    
    <item>
      <title>Java基础加强01</title>
      <link>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA01/</link>
      <pubDate>Sun, 24 Apr 2022 15:31:20 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%9F%BA%E7%A1%80%E5%8A%A0%E5%BC%BA01/</guid>
      <description>1.类加载器 1.1类加载器【理解】   作用
负责将.class文件（存储的物理文件）加载在到内存中
  1.2类加载的过程【理解】   类加载时机
 创建类的实例（对象） 调用类的类方法 访问类或者接口的类变量，或者为该类变量赋值 使用反射方式来强制创建某个类或接口对应的java.lang.Class对象 初始化某个类的子类 直接使用java.exe命令来运行某个主类    类加载过程
  加载
 通过包名 + 类名，获取这个类，准备用流进行传输 在这个类加载到内存中 加载完毕创建一个class对象    链接
  验证
确保Class文件字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身安全
(文件中的信息是否符合虚拟机规范有没有安全隐患)
    准备
负责为类的类变量（被static修饰的变量）分配内存，并设置默认初始化值
(初始化静态变量)
    解析
将类的二进制数据流中的符号引用替换为直接引用
(本类中如果用到了其他类，此时就需要找到对应的类)
    初始化
根据程序员通过程序制定的主观计划去初始化类变量和其他资源
(静态变量赋值以及初始化其他资源)
    小结
 当一个类被使用的时候，才会加载到内存 类加载的过程: 加载、验证、准备、解析、初始化    1.</description>
    </item>
    
    <item>
      <title>解决Docker日志文件太大的问题</title>
      <link>https://iblog.zone/archives/%E8%A7%A3%E5%86%B3docker%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%A4%AA%E5%A4%A7%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Thu, 21 Apr 2022 17:58:05 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/%E8%A7%A3%E5%86%B3docker%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E5%A4%AA%E5%A4%A7%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>Docker 在不重建容器的情况下，日志文件默认会一直追加，时间一长会逐渐占满服务器的硬盘的空间，内存消耗也会一直增加，本篇来了解一些控制日志文件的方法。
 清理单个文件 运行时控制 全局配置  Docker 的日志文件存在 /var/lib/docker/containers 目录中，通过下面的命令可以将日志文件夹根据升序的方式罗列出来。
$ sudo du -d1 -h /var/lib/docker/containers | sort -h  28K /var/lib/docker/containers/0db860afe94df368335c2e96f290275f4c396b996b4e8d22770b01baafd9982c 36K /var/lib/docker/containers/6ee184044661c436b44769d56c203f1fc296dbfe08f6ed4cf79aa6fb8cae6659 44K /var/lib/docker/containers/66c44231981fcb5ecd33bf0fc3390e71c5cbbabb839d79441eb3317b8500d551 60K /var/lib/docker/containers/bc4136199037e73d712614ef57de0915d294cbe51045d213f0d822d71a86cf2c 344K /var/lib/docker/containers/7bd3a179cf67b1537e0965c1d1f518420ac5d4cd151ecb75c37ada8c2347ca6b 984K /var/lib/docker/containers/6bd1f79f16b8b06f2bd203dd84443004ba08c150ac51d23fa620e8b2cbf4b773 1.7M /var/lib/docker/containers/a93a4275571b0033367f9cab8213c467b21a03c600e2203195640b5a5bc7f523 4.4M /var/lib/docker/containers/082564c5bdb19b642491b09419a69061122483c0f959a36eb186dd1fec53c163 14M /var/lib/docker/containers/05fc24ef7a14e31e4557c9881482d350cfb05f2f1cb870638de344581154ca01 32M /var/lib/docker/containers/5d70c82942083d16593670058aefed339cfe874c9027205b1e6eb8e569894d65 129M /var/lib/docker/containers/a88d104d20e5ee58ffeaeecbb559b3231c5b8c73ad1443538928ebeae4ff705c 285M /var/lib/docker/containers/b623602a667c0b31068563f244610a548ed055ff9802197f372ff436a294ab5c 917M /var/lib/docker/containers/3d71c509ab6aea34400d37f6c006914eed2cb05e6e6cd07b3ee03eb783dc367b 1.4G /var/lib/docker/containers 有三种方式可以清理日志文件
清理单个文件 感觉哪个容器的日志太大就清理哪个
$ sudo sh -c &amp;#34;cat /dev/null &amp;gt; ${log_file}&amp;#34; ${log_file} 就是日志文件，可以通过 find 命令查找全部日志
$ sudo find /var/lib/docker/containers -name *.log  /var/lib/docker/containers/3d71c509ab6aea34400d37f6c006914eed2cb05e6e6cd07b3ee03eb783dc367b/3d71c509ab6aea34400d37f6c006914eed2cb05e6e6cd07b3ee03eb783dc367b-json.</description>
    </item>
    
    <item>
      <title>Docker容器中安装curl、telnet、vim基础工具</title>
      <link>https://iblog.zone/archives/docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%AE%89%E8%A3%85curltelnetvim%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Wed, 20 Apr 2022 17:55:51 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker%E5%AE%B9%E5%99%A8%E4%B8%AD%E5%AE%89%E8%A3%85curltelnetvim%E5%9F%BA%E7%A1%80%E5%B7%A5%E5%85%B7/</guid>
      <description>#因在容器中排查故障需要，需要安装基础工具
# 查看系统版本： cat /etc/os-release
Debian基础镜像
#先添加163源 tee /etc/apt/sources.list &amp;lt;&amp;lt; EOF deb http://mirrors.163.com/debian/ jessie main non-ffree contrib deb http://mirrirs.163.com/debian/ jessie-updates main non-free contrib EOF  #安装 curl telnet apt-get update &amp;amp;&amp;amp; apt-get install -y curl telnet vim Alpine基础镜像
#先添加阿里源 cat &amp;gt; /etc/apk/repositories &amp;lt;&amp;lt; EOF http://mirrors.aliyun.com/alpine/v3.12/main/ http://mirrors.aliyun.com/alpine/v3.12/community EOF  #安装 curl scp telnet vim apk update &amp;amp;&amp;amp; apk add curl openssh-client busybox-extras vim </description>
    </item>
    
    <item>
      <title>Docker部署Grafana</title>
      <link>https://iblog.zone/archives/docker%E9%83%A8%E7%BD%B2grafana/</link>
      <pubDate>Wed, 20 Apr 2022 17:53:51 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker%E9%83%A8%E7%BD%B2grafana/</guid>
      <description>搜索镜像 docker search grafana/grafana 拉取镜像 版本号可以去官网查看：https://hub.docker.com/r/grafana/grafana
docker pull grafana/grafana:8.3.3 创建容器  --restart=always：容器退出后（kill后）自动重启。 --link prometheus：需要将prometheus容器（容器名）的hostname链接过来，否则无法连接到prometheus。 $PWD/grafana/config：映射配置文件位置 $PWD/grafana/data：映射数据存储位置。 /etc/localtime:/etc/localtime:ro：容器内部的时间格式化保持和宿主机一致。  docker run -d --restart=always \ -u root \ --name=grafana \ --link prometheus \ -p 3000:3000 \ -v $PWD/grafana/config:/etc/grafana \ -v $PWD/grafana/data:/var/lib/grafana \ -v /etc/localtime:/etc/localtime:ro \ grafana/grafana:8.3.3 可能出现的错误 使用-u root指定为root用户启动。
mkdir: can&amp;#39;t create directory &amp;#39;/var/lib/grafana/plugins&amp;#39;: Permission denied 缺少配置文件
msg=&amp;#34;failed to parse \&amp;#34;/etc/grafana/grafana.ini\&amp;#34;: open /etc/grafana/grafana.ini: no such file or directory&amp;#34; 创建容器时需要先创建好grafana.ini配置文件。
docker cp grafana:/etc/grafana/grafana.ini .</description>
    </item>
    
    <item>
      <title>Influxdb学习</title>
      <link>https://iblog.zone/archives/influxdb%E5%AD%A6%E4%B9%A0/</link>
      <pubDate>Wed, 20 Apr 2022 14:40:08 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/influxdb%E5%AD%A6%E4%B9%A0/</guid>
      <description>InfluxDB is the Time Series Database in the TICK stack
https://www.influxdata.com/time-series-platform/
摘要: Docker监控方案之数据存储工具Influxdb工具的介绍和安装。Influxdb也是和telegraf属于一家公司，用go开发的用来存储时间序列数据的数据库。可以将存储的数据进行时间序列化，是每个监控系统中最重要的一个环节。Docker监控方案(TIG)采用Influxdb来进行数据存储，当然可选的还有很多，比如Opentsdb，Graphite等。
前言： Influxdb也是有influxdata公司(www.influxdata.com )开发的用于数据存储的时间序列数据库.可用于数据的时间排列。在整个TIG(Telegraf+influxdb+grafana)方案中，influxdb可算作一个中间件，主要负责原始数据的存储，并按照时间序列进行索引构建以提供时间序列查询接口。在整个TIG方案中，应该先构建的就是Influxdb。
Influxdb研究与实践： influxdb介绍：
使用TSM(Time Structured Merge)存储引擎，允许高摄取速度和数据压缩； 使用go编写，无需其他依赖； 简单，高性能写查询httpAPI接口； 支持其他数据获取协议的插件，比如graphite,collected,OpenTSDB； 使用relay构建高可用https://docs.influxdata.com/influxdb/v1.0/high_availability/relay/； 扩展的类sql语言，很容易查询汇总数据； tag的支持，可用让查询变的更加高效和快速； 保留策略有效地自动淘汰过期的数据； 持续所产生的自动计算的数据会使得频繁的查询更加高效； web管理页面的支持
下载安装：
github：https://github.com/influxdata/influxdb 源码编译 官网下载： Centos系列：wgethttps://dl.influxdata.com/influxdb/releases/influxdb-1.0.0.x86_64.rpm &amp;amp;&amp;amp; sudo yum localinstall influxdb-1.0.0.x86_64.rpm 源码包系列：wgethttps://dl.influxdata.com/influxdb/releases/influxdb-1.0.0_linux_amd64.tar.gz &amp;amp;&amp;amp; tar xvfz influxdb-1.0.0_linux_amd64.tar.gz docker系列：docker pull influxdb 安装手册：https://docs.influxdata.com/influxdb/v0.9/introduction/installation/
配置：
#cat /etc/influxdb/influxdb.conf reporting-disabled = false [registration] [meta] dir = &amp;#34;/var/lib/influxdb/meta&amp;#34; hostname = &amp;#34;10.0.0.2&amp;#34; #此hostname必须写本机，否则无法连接到数据操作的API bind-address = &amp;#34;:8088&amp;#34; retention-autocreate = true election-timeout = &amp;#34;1s&amp;#34; heartbeat-timeout = &amp;#34;1s&amp;#34; leader-lease-timeout = &amp;#34;500ms&amp;#34; commit-timeout = &amp;#34;50ms&amp;#34; cluster-tracing = false [data] dir = &amp;#34;/var/lib/influxdb/data&amp;#34; max-wal-size = 104857600 # Maximum size the WAL can reach before a flush.</description>
    </item>
    
    <item>
      <title>Docker安装Consul1.9.3</title>
      <link>https://iblog.zone/archives/docker%E5%AE%89%E8%A3%85consul1.9.3/</link>
      <pubDate>Tue, 19 Apr 2022 15:12:42 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker%E5%AE%89%E8%A3%85consul1.9.3/</guid>
      <description>拉取Consul镜像 $ docker pull consul # 默认拉取latest $ docker pull consul:1.9.3 # 拉取指定版本 安装并运行 docker run -d -p 8500:8500 --restart=always --name=consul consul:1.9.3 agent -server -bootstrap -ui -node=1 -client=&amp;#39;0.0.0.0&amp;#39;  agent: 表示启动 Agent 进程。 server：表示启动 Consul Server 模式 client：表示启动 Consul Cilent 模式。 bootstrap：表示这个节点是 Server-Leader ，每个数据中心只能运行一台服务器。技术角度上讲 Leader 是通过 Raft 算法选举的，但是集群第一次启动时需要一个引导 Leader，在引导群集后，建议不要使用此标志。 ui：表示启动 Web UI 管理器，默认开放端口 8500，所以上面使用 Docker 命令把 8500 端口对外开放。 node：节点的名称，集群中必须是唯一的，默认是该节点的主机名。 client：consul服务侦听地址，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1所以不对外提供服务，如果你要对外提供服务改成0.0.0.0 join：表示加入到某一个集群中去。 如：-json=192.168.0.11  </description>
    </item>
    
    <item>
      <title>GRAFANA&#43;INFLUXDB&#43;TELEGRAF 快速监控主机与MYSQL</title>
      <link>https://iblog.zone/archives/grafana-influxdb-telegraf-%E5%BF%AB%E9%80%9F%E7%9B%91%E6%8E%A7%E4%B8%BB%E6%9C%BA%E4%B8%8Emysql/</link>
      <pubDate>Tue, 19 Apr 2022 14:35:30 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/grafana-influxdb-telegraf-%E5%BF%AB%E9%80%9F%E7%9B%91%E6%8E%A7%E4%B8%BB%E6%9C%BA%E4%B8%8Emysql/</guid>
      <description>一、安装 1.1、配置INFLUXDB YUM源 [root@node ~]# cat /etc/yum.repos.d/influxdb.repo  [influxdb] name = InfluxDB Repository - RHEL \$releasever baseurl = https://repos.influxdata.com/rhel/\$releasever/\$basearch/stable enabled = 1 gpgcheck = 1 gpgkey = https://repos.influxdata.com/influxdb.key 1.2、安装GRAFANA+INFLUXDB+TELEGRAF 安装influxdb yum install influxdb 安装telegraf yum install telegraf 安装grafana wget https://dl.grafana.com/oss/release/grafana-6.1.3-1.x86_64.rpm yum localinstall grafana-6.1.3-1.x86_64.rpm 1.3、软件版本 InfluxDB version: 1.7.4 Telegraf version: 1.10.2 Grafana version: 6.1.3 1.4、启动服务，添加开机启动 systemctl start influxdb.service systemctl start telegraf.service systemctl start grafana-server.service  systemctl enable influxdb.service systemctl enable telegraf.service systemctl enable grafana-server.</description>
    </item>
    
    <item>
      <title>单机单盘场景部署ceph环境</title>
      <link>https://iblog.zone/archives/%E5%8D%95%E6%9C%BA%E5%8D%95%E7%9B%98%E5%9C%BA%E6%99%AF%E9%83%A8%E7%BD%B2ceph%E7%8E%AF%E5%A2%83/</link>
      <pubDate>Mon, 18 Apr 2022 11:36:08 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/%E5%8D%95%E6%9C%BA%E5%8D%95%E7%9B%98%E5%9C%BA%E6%99%AF%E9%83%A8%E7%BD%B2ceph%E7%8E%AF%E5%A2%83/</guid>
      <description>一、环境信息 系统：CentOS Linux release 7.7.1908 磁盘：200G（系统盘）
1、创建loop设备 mkdir -p /data/ceph-disk/ fallocate -l 40G /data/ceph-disk/sdb.img fallocate -l 40G /data/ceph-disk/sdc.img fallocate -l 40G /data/ceph-disk/sdd.img  losetup -l -P /dev/loop1 /data/ceph-disk/sdb.img losetup -l -P /dev/loop2 /data/ceph-disk/sdc.img losetup -l -P /dev/loop3 /data/ceph-disk/sdd.img  wipefs -a /dev/loop1 wipefs -a /dev/loop2 wipefs -a /dev/loop3 2、设置开机启动挂载loop设备 cat /etc/rc.local
losetup -l -P /dev/loop1 /data/ceph-disk/sdb.img losetup -l -P /dev/loop2 /data/ceph-disk/sdc.img losetup -l -P /dev/loop3 /data/ceph-disk/sdd.img  #卸载loop设备 #losetup --detach /dev/loop1 #losetup --detach /dev/loop2 #losetup --detach /dev/loop3 chmod a+x /etc/rc.</description>
    </item>
    
    <item>
      <title>Nginx官方推荐的nginx.conf标准配置</title>
      <link>https://iblog.zone/archives/nginx%E5%AE%98%E6%96%B9%E6%8E%A8%E8%8D%90%E7%9A%84nginx.conf%E6%A0%87%E5%87%86%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 18 Apr 2022 11:28:45 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nginx%E5%AE%98%E6%96%B9%E6%8E%A8%E8%8D%90%E7%9A%84nginx.conf%E6%A0%87%E5%87%86%E9%85%8D%E7%BD%AE/</guid>
      <description>Nginx官方发布“避免10大NGINX配置错误”中，推荐nginx.conf配置为：
http {   upstream node_backend {  zone upstreams 64K;  server 127.0.0.1:3000 max_fails=1 fail_timeout=2s;  keepalive 2;  }   server {  listen 80;  server_name example.com;   location / {  proxy_set_header Host $host;  proxy_pass http://node_backend/;  proxy_next_upstream error timeout http_500;   }  } } 即使没有负载平衡或在一台机器内，也要启用upstream{}块，它解锁了几个提高性能的功能：
 该zone指令建立了一个共享内存区域，主机上的所有 NGINX 工作进程都可以访问有关上游服务器的配置和状态信息。几个上游组可以共享该区域。 该server指令有几个参数可用于调整服务器行为。在这个例子中，我们改变了 NGINX 用来确定服务器不健康并因此没有资格接受请求的条件。在这里，如果通信尝试在每 2 秒内失败一次（而不是默认的每10 秒一次），它就会认为服务器不健康。 我们把这个设置和proxy_next_upstream指令结合起来，以配置NGINX认为的失败的通信尝试，在这种情况下，它把请求传递给上游组的下一个服务器。在默认的错误和超时条件中，我们添加了http_500，以便NGINX认为来自上游服务器的HTTP 500（内部服务器错误）代码代表一个失败的尝试。 keepalive指令设置每个工作进程的缓存中保存的与上游服务器的空闲keepalive连接的数量。默认情况下，NGINX 会为每个新的传入请求打开一个到上游（后端）服务器的新连接。这是安全但低效的，因为 NGINX 和服务器必须交换三个数据包来建立连接，并交换三个或四个数据包来终止它。在高流量时，为每个请求打开一个新连接会耗尽系统资源，并且根本无法打开连接。修复是在 NGINX 和上游服务器之间启用keepalive 连接——而不是在请求完成时关闭，连接保持打开状态以用于其他请求。这既减少了源端口用完的可能性，又提高了性能。该参数设置为块中列出的服务器数量的两倍。  </description>
    </item>
    
    <item>
      <title>InfluxDB常用命令</title>
      <link>https://iblog.zone/archives/influxdb%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link>
      <pubDate>Fri, 15 Apr 2022 15:28:38 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/influxdb%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid>
      <description>连接数据库 $ influx -precision rfc3339 Connected to http://localhost:8086 version 1.2.x InfluxDB shell 1.2.x &amp;gt; exit # 退出命令行 说明:
 InfluxDB的HTTP接口默认起在8086上，所以influx默认也是连的本地的8086端口，你可以通过influx --help来看怎么修改默认值。 -precision参数表明了任何返回的时间戳的格式和精度，rfc3339`是让InfluxDB返回RFC339格式(YYYY-MM-DDTHH:MM:SS.nnnnnnnnnZ)的时间戳。  创建数据库 &amp;gt; CREATE DATABASE mydb 查看数据库 &amp;gt; SHOW DATABASES name: databases --------------- name _internal mydb 说明：_internal数据库是用来存储InfluxDB内部的实时监控数据的
使用数据库 &amp;gt; USE mydb Using database mydb 数据存储格式介绍 首先对数据存储的格式来个入门介绍。InfluxDB里存储的数据被称为时间序列数据，其包含一个数值，就像CPU的load值或是温度值类似的。时序数据有零个或多个数据点，每一个都是一个指标值。数据点包括time(一个时间戳)，measurement(例如cpu_load)，至少一个k-v格式的field(也即指标的数值例如 “value=0.64”或者“temperature=21.2”)，零个或多个tag，其一般是对于这个指标值的元数据(例如“host=server01”, “region=EMEA”, “dc=Frankfurt)。
在概念上，你可以将measurement类比于SQL里面的table，其主键索引总是时间戳。tag和field是在table里的其他列，tag是被索引起来的，field没有。不同之处在于，在InfluxDB里，你可以有几百万的measurements，你不用事先定义数据的scheme，并且null值不会被存储。
将数据点写入InfluxDB，只需要遵守如下的行协议：
&amp;lt;measurement&amp;gt;[,&amp;lt;tag-key&amp;gt;=&amp;lt;tag-value&amp;gt;...] &amp;lt;field-key&amp;gt;=&amp;lt;field-value&amp;gt;[,&amp;lt;field2-key&amp;gt;=&amp;lt;field2-value&amp;gt;...] [unix-nano-timestamp] 下面是数据写入InfluxDB的格式示例：
cpu,host=serverA,region=us_west value=0.64 payment,device=mobile,product=Notepad,method=credit billed=33,licenses=3i 1434067467100293230 stock,symbol=AAPL bid=127.46,ask=127.48 temperature,machine=unit42,type=assembly external=25,internal=37 1434067467000000000 写入数据 &amp;gt; INSERT cpu,host=serverA,region=us_west value=0.</description>
    </item>
    
    <item>
      <title>Docker Swarm集群监控方案</title>
      <link>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</link>
      <pubDate>Fri, 15 Apr 2022 14:44:22 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%9B%91%E6%8E%A7%E6%96%B9%E6%A1%88/</guid>
      <description>docker swarm监控方案有很多，主流的有cAdvisor+InfluxDB+Grafana和cAdvisor+Prometheus+Grafana，本文介绍cAdvisor+InfluxDB+Grafana方案
组件说明  cAdvisor：数据收集模块，需要部署在集群中的每一个节点上，当然前提条件是节点接受task。 InfluxDB：数据存储模块。 Grafana：数据展示模块  创建docker compose文件 在manager结点上创建文件，并输入如下内容：
version: &amp;#39;3&amp;#39;  services:  influx:  image: influxdb:1.8	# 保证模板兼容性  volumes:  - influx:/var/lib/influxdb  deploy:  replicas: 1  placement:  constraints:  - node.role == manager   grafana:  image: grafana/grafana:4.2.0  # 保证模板兼容性  ports:  - 0.0.0.0:80:3000  volumes:  - grafana:/var/lib/grafana  depends_on:  - influx  deploy:  replicas: 1  placement:  constraints:  - node.</description>
    </item>
    
    <item>
      <title>Filebeat7.6安装配置</title>
      <link>https://iblog.zone/archives/filebeat7.6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Thu, 14 Apr 2022 18:16:46 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/filebeat7.6%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</guid>
      <description>安装 yum -y install https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.6.0-x86_64.rpm 配置 filebeat.inputs: - type: log  enabled: true  paths:  - /data/logs/server.ser  tags: [&amp;#34;online_server&amp;#34;] - type: log  enabled: true  paths:  - /data/logs/pay.ser  tags: [&amp;#34;online_pay&amp;#34;] - type: log  enabled: true  paths:  - /data/logs/log.*  tags: [&amp;#34;online_admin&amp;#34;]  output.elasticsearch:  hosts: [&amp;#34;10.0.0.1:9200&amp;#34;]  indices:  - index: &amp;#34;online_server-%{+yyyy.MM.dd}&amp;#34;  when.contains:  tags: &amp;#34;online_server&amp;#34;  - index: &amp;#34;online_pay-%{+yyyy.MM.dd}&amp;#34;  when.</description>
    </item>
    
    <item>
      <title>Nginx根据请求IP转发请求</title>
      <link>https://iblog.zone/archives/nginx%E6%A0%B9%E6%8D%AE%E8%AF%B7%E6%B1%82ip%E8%BD%AC%E5%8F%91%E8%AF%B7%E6%B1%82/</link>
      <pubDate>Thu, 14 Apr 2022 16:37:54 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nginx%E6%A0%B9%E6%8D%AE%E8%AF%B7%E6%B1%82ip%E8%BD%AC%E5%8F%91%E8%AF%B7%E6%B1%82/</guid>
      <description>规则：
$remote_addr ~* ^(.*)\.(.*)\.(.*)\.*[0268]$ 匹配末尾为0268这样的偶数ip，跳转到指定域名
$remote_addr ~* ^(112)\.(.*)\.(.*)\.(.*)$ 开头为 112 的 IP 跳转到指定的域名；
$http_x_forwarded_for ~* ^(112)\.(.*)\.(.*)\.(.*)$ 根据 forward 地址段来分流，开头为 112 的跳转到指定域名
例如：
server {  listen 8080; # 监听端口  server_name 10.0.0.1; # 监听地址   access_log /data/logs/nginx_logs/10.0.0.1.log main;   location / {  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  if ( $remote_addr ~* 10.0.0.2) { ## 请求ip为10.0.0.2的流量转发到下列地址  proxy_pass http://172.16.0.2:10000;  break;  }  if ( $remote_addr ~* ^(.*)\.(.*)\.(.*)\.*[0268]$) { ## 请求ip尾数为0268的ip转发到下列地址  proxy_pass http://172.</description>
    </item>
    
    <item>
      <title>MySQL生产级全备&#43;增备备份脚本</title>
      <link>https://iblog.zone/archives/mysql%E7%94%9F%E4%BA%A7%E7%BA%A7%E5%85%A8%E5%A4%87-%E5%A2%9E%E5%A4%87%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC/</link>
      <pubDate>Wed, 13 Apr 2022 17:19:20 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/mysql%E7%94%9F%E4%BA%A7%E7%BA%A7%E5%85%A8%E5%A4%87-%E5%A2%9E%E5%A4%87%E5%A4%87%E4%BB%BD%E8%84%9A%E6%9C%AC/</guid>
      <description>脚本内容如下：Xtrabackup.sh
#!/bin/bash ##备份策略: ##周日(7)： 全备 ##周一 ~ 周六(1-6)： 增量备份  source /etc/profile ulimit -HSn 102400  ## ##========== global var ============ ##  #如果一台服务器上有多个MySQL，可以使用 BAK_DIR_ROOT进行备份路径的区别 #可增加端口作为区分，例如 /opt/backup/mysqk/3306 BAK_DIR_ROOT=&amp;#34;/data/mysql_backup&amp;#34; #默认周日进行全备 (1 - 7), 1 是周一，7是周日 FULL_BAK_DAY_OF_WEEK=7 #备份文件保留周期，默认保留35天 (4-5周) HOLD_DAYS=35  MYSQL_USERNAME=&amp;#34;root&amp;#34; MYSQL_PASSWORD=&amp;#34;root&amp;#34; MYSQL_HOST=&amp;#34;10.0.0.1&amp;#34;  MYSQL_CNF=&amp;#34;/etc/my.cnf&amp;#34; MYSQL_MULTI_GROUP=&amp;#34;--socket=/data/mysql/mysql.sock&amp;#34; #如果使用多实例，比如通过ecloud的方式下发安装，默认使用多实例 #MYSQL_MULTI_GROUP=&amp;#34;--defaults-group=mysqld3307 --socket=/tmp/mysql3307.sock&amp;#34;  CURRENT_WEEK_OF_YEAR=$(date +%U) CURRENT_DAY_OF_WEEK=$(date +%u) CURRENT_DATE=$(date +%F) CURRENT_TIME=$(date +%H-%M-%S) CURRENT_DATETIME=&amp;#34;${CURRENT_DATE}_${CURRENT_TIME}&amp;#34;  BAK_WEEK_DIR=&amp;#34;${BAK_DIR_ROOT}/WEEK_${CURRENT_WEEK_OF_YEAR}&amp;#34;  BAK_FULL_DIR=&amp;#34;${BAK_WEEK_DIR}/FULL&amp;#34;  BAK_LOG=&amp;#34;${BAK_WEEK_DIR}/backup.log&amp;#34;    ## ##========== function ============= ##  function clean_backup() {  find ${BAK_DIR_ROOT} -mtime +${HOLD_DAYS} -prune -exec rm -rf {} \; }   function write_start_log() {   if [[ !</description>
    </item>
    
    <item>
      <title>RocketMQ Console安装及配置</title>
      <link>https://iblog.zone/archives/rocketmq-console%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Wed, 13 Apr 2022 10:32:06 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/rocketmq-console%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE/</guid>
      <description>1、RocketMQ-Console介绍 RocketMQ-Console现在已更名为Rocketmq-Dashboard，为了方便，下面还是使用RocketMQ-Console
Git地址: https://github.com/apache/rocketmq-dashboard
包含了多个功能：运维、驾驶舱、集群、主题、消费者、生产者、消息、消息轨迹、connector 等
2、环境信息  服务器     服务器 操作系统 硬件配置 版本 说明     Linux CentOS 7 4C16G 64位 生产环境建议Linux/Unix     软件     工具/环境 版本 说明     JDK 1.8 RocketMQ Console要求版本在1.7以上   Git 1.8.3.1 源码方式安装需要，版本无要求   Maven 3.6.3 源码方式安装需求，版本无要求    3、安装 安装RocketMQ-Console，可以通过两种方式:
 通过Docker镜像安装； 通过GitHub拉取源代码，进行编译，然后启动安装；  具体如下：
通过Docker方式 # 拉取镜像 # 还可以自己通过源码的方式打包镜像，需要有镜像仓库。打镜像命令：mvn clean package -Dmaven.</description>
    </item>
    
    <item>
      <title>Microsoft SQL Server 2008 R2安装</title>
      <link>https://iblog.zone/archives/microsoft-sql-server-2008-r2%E5%AE%89%E8%A3%85/</link>
      <pubDate>Tue, 12 Apr 2022 16:54:24 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/microsoft-sql-server-2008-r2%E5%AE%89%E8%A3%85/</guid>
      <description>下载Microsoft SQL Server 2008 R2，打开安装文件夹，以管理员身份运行setup.exe。（百度网盘链接: https://pan.baidu.com/s/11b_YAsNm-zO_BDbX8QnpSA?pwd=arxn 提取码: arxn ）
1、安装 弹出安装程序界面，选择安装，“全新安装或向现有安装添加功能”。
进行检测，全部通过即可，一般都是全部通过的（只要不存在失败和警告，即不存在问题，可继续安装），有时可能需要重启计算机，按照要求操作即可。
输入产品秘钥，此安装程序默认输入（软件自动默认输入），直接点击下一步。
接受许可条款，点击下一步。
安装支持文件。
安装程序支持规则，通过即可点击下一步。
2、设置角色 设置角色，选择默认的“SQL Server功能安装”，点击下一步。
3、功能选择 选择功能，“全选”，安装目录可自定义（自定义安装在C/D盘），点击下一步。
4、安装规则 安装规则，全部为“通过/跳过”就没问题（与前面类似，只要不出现警告和失败即不存在问题，可继续下面的安装），点击下一步。
5、实例配置 实例配置，选择：默认实例，实例根目录安装位置可自定义的即可，点击下一步。
磁盘空间需求，满足要求即可点击下一步。
服务器配置，按照如图配置一样的账户名，点击下一步。（下图中启动类型，可根据需要设置成手动或者自动，对于本系统，全部设置成手动即可）。
点击下三角，选择“***\SYSTEM”，***表示本机电脑账户名称，不同电脑账户名称不同。
数据库引擎配置，选择“混合模式”，这里设置密码为xxxxxxx，指定SQL Server 管理员“添加当前用户”。
Analysis Services 配置，添加当前用户，然后点击下一步。
Reporting Services 配置，按照本机模式默认配置。
错误报告，可不勾选发送错误报告，点击下一步。
6、安装配置规则 安装配置规则，通过/跳过，没问题，点击下一步。
开始安装，耐心等待即可。（根据电脑配置不同安装时间在20min-40min不等。）
7、安装完成 安装完成，至此安装完毕。
8、启动数据库 启动SQL Server 2008，选择开始菜单中的Microsoft SQL Server 2008下的“SQL Server Management Studio”（也可将该选项拖到桌面作为快捷方式，便于以后使用），启动SQL Server服务，如图所示：
点击启动后看到如下界面：</description>
    </item>
    
    <item>
      <title>MySQL权限级别介绍</title>
      <link>https://iblog.zone/archives/mysql%E6%9D%83%E9%99%90%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D/</link>
      <pubDate>Tue, 12 Apr 2022 10:26:52 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/mysql%E6%9D%83%E9%99%90%E7%BA%A7%E5%88%AB%E4%BB%8B%E7%BB%8D/</guid>
      <description>MySQL权限级别 全局性的管理权限，作用于整个MySQL实例级别 数据库级别的权限，作用于某个指定的数据库上或者所有的数据库上 数据库对象级别的权限，作用于指定的数据库对象上(表、视图等)或 者所有的数据库对象上 权限存储在mysql库的user, db, tables_priv, columns_priv, and procs_priv这几个系统表中，待MySQL实例启动后就加载到内存中  MySQL权限级别介绍 对比root用户在几个权限系统表中的数据
mysql&amp;gt; select * from user where user=‘root’ and host=‘localhost’; ##都是’Y’ mysql&amp;gt; select * from db where user=‘root’ and host=‘localhost’; ##无记录 mysql&amp;gt; select * from tables_priv where host=‘localhost’ and user=‘root’; ##无记录 mysql&amp;gt; select * from columns_priv where user=‘root’ and host=‘localhost’; ##无记录 mysql&amp;gt; select * from procs_priv where user=‘root’ and host=‘localhost’; ##无记录 MySQL权限详解   All/All Privileges权限代表全局或者全数据库对象级别的所有权限</description>
    </item>
    
    <item>
      <title>Nginx常用操作及配置</title>
      <link>https://iblog.zone/archives/nginx%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%8F%8A%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Mon, 11 Apr 2022 17:20:11 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nginx%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%E5%8F%8A%E9%85%8D%E7%BD%AE/</guid>
      <description>一、nginx获取客户端真实IP、域名、协议、端口 需要在Nginx的配置文件nginx.conf中添加如下配置
proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; 各参数的含义如下所示。
 Host包含客户端真实的域名和端口号； X-Forwarded-Proto表示客户端真实的协议（http还是https）； X-Real-IP表示客户端真实的IP； X-Forwarded-For这个Header和X-Real-IP类似，但它在多层代理时会包含真实客户端及中间每个代理服务器的IP  二、nginx负载均衡配置 http {  ……  upstream real_server {  server 192.168.103.100:2001 weight=1; #轮询服务器和访问权重  server 192.168.103.100:2002 weight=2;  }   server {  listen 80;   location / {  proxy_pass http://real_server;  }  } } nginx负载均衡失败重试配置
upstream real_server {  server 192.168.103.100:2001 weight=1 max_fails=2 fail_timeout=60s;  server 192.</description>
    </item>
    
    <item>
      <title>前端npm私服搭建</title>
      <link>https://iblog.zone/archives/%E5%89%8D%E7%AB%AFnpm%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/</link>
      <pubDate>Fri, 08 Apr 2022 18:08:30 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/%E5%89%8D%E7%AB%AFnpm%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/</guid>
      <description>前言 在工作中，公司有很多内部的包并不希望发布到npm官网仓库，因为可能涉及到一些私有代码不能暴露。对于前端来讲，这时就可以选择在公司内网搭建npm私有仓库。当前比较主流的几种解决方案：verdaccio、nexus、cnpm。大家可以按照自己的需求选择。本文中采用的是cnpm私服搭建。
cnpm私服搭建流程 1. 安装node,新的node版本会自带npm 官网地址：nodejs.org/zh-cn/
2. 拉取代码，对应公司需求做相应更改 git clone https://github.com/cnpm/cnpmjs.org.git 3. 修改配置文件 ./config/index.js  // 仓库站点访问端口  registryPort: 7001,  // 页面访问端口  webPort: 7002,  // 外网可以访问的话则注释，否则只能内网访问  bindingHost: &amp;#39;127.0.0.1&amp;#39;,  // 数据库配置  database: {  db: &amp;#39;cnpmjs&amp;#39;, // 数据库  username: &amp;#39;root&amp;#39;, // 数据库用户名  password: &amp;#39;&amp;#39;, // 数据库密码  dialect: &amp;#39;mysql&amp;#39;, // 数据库类型 &amp;#39;mysql&amp;#39;, &amp;#39;sqlite&amp;#39;, &amp;#39;postgres&amp;#39;, &amp;#39;mariadb&amp;#39;  host: &amp;#39;&amp;#39;, // 数据库服务地址  port: 3306 // 端口  }  // 用户配置 key 为用户名和密码，value为邮箱  admins: {  harlie: &amp;#39;yanghui3021@163.</description>
    </item>
    
    <item>
      <title>Maven私服Nexus的搭建与使用</title>
      <link>https://iblog.zone/archives/maven%E7%A7%81%E6%9C%8Dnexus%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Fri, 08 Apr 2022 17:11:04 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/maven%E7%A7%81%E6%9C%8Dnexus%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E4%BD%BF%E7%94%A8/</guid>
      <description>一、基本介绍 1、如果没有搭建私服会有什么问题？  如果没有私服，我们所需的所有构件都需要通过 Maven 的中央仓库或者第三方的 Maven 仓库下载到本地，而一个团队中的所有人都重复的从 Maven 仓库下载构件无疑加大了仓库的负载和浪费了外网带宽，如果网速慢的话，还会影响项目的进程。 另外，很多情况下项目的开发都是在内网进行的，可能根本连接不了 Maven 的中央仓库和第三方的 Maven 仓库。 我们开发的公共构件如果需要提供给其它项目使用，也需要搭建私服。  2、搭建私服的优点 Maven 私服的概念就是在本地架设一个 Maven 仓库服务器，在代理远程仓库的同时维护本地仓库。当我们需要下载一些构件（artifact）时，如果本地仓库没有，再去私服下载，私服没有，再去中央仓库下载。这样做会有如下一些优点：
 减少网络带宽流量 加速 Maven 构建 部署第三方构件 提高稳定性、增强控制 降低中央仓库的负载  3、Nexus 介绍 Nexus 是一个专门的 Maven 仓库管理软件，它不仅能搭建 Maven 私服，还具备如下一些优点使其日趋成为最流行的 Maven 仓库管理器：
 提供了强大的仓库管理功能，构件搜索功能 它基于 REST，友好的 UI 是一个 ext.js 的 REST 客户端 它占用较少的内存 基于简单文件系统而非数据库  二、Nexus 服务的安装 使用 Docker 镜像进行安装 （1）首先执行如下命令下载 Nexus3 镜像：
docker pull sonatype/nexus3 （2）接着执行如下命令，创建宿主机挂载目录：
mkdir -p /data/nexus-data （3）最后执行如下命令运行 Nexus3 容器即可：</description>
    </item>
    
    <item>
      <title>Docker Swarm 节点标签与服务约束</title>
      <link>https://iblog.zone/archives/docker-swarm-%E8%8A%82%E7%82%B9%E6%A0%87%E7%AD%BE%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%BA%A6%E6%9D%9F/</link>
      <pubDate>Fri, 08 Apr 2022 14:42:54 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-swarm-%E8%8A%82%E7%82%B9%E6%A0%87%E7%AD%BE%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%BA%A6%E6%9D%9F/</guid>
      <description>多节点 Swarm 集群下，可能节点的配置不同（比如 CPU、内存等），部署着不同类型的服务（比如 Web服务、Job服务等），当这些服务以 Service 或者 Stack 的形式部署到集群，默认情况下会随机分配到各个节点。不同类型的服务对服务器需求的资源是不同的，为了更合理的利用服务器资源，我们可能希望某些服务能够部署到指定的服务器上。另外一种场景，Swarm 集群中的节点跨机房，为了内部服务间通信更快，我们可能希望关联比较密切的服务能够部署到同一机房的节点上。那么，如何做到呢？
很简单，先给节点添加标签，然后服务发布时添加限制条件即可！
Node Label 管理 示例集群信息：
docker@node1:~$ docker node ls ID HOSTNAME STATUS AVAILABILITY MANAGER STATUS ENGINE VERSION axr4zun8u1es8ytizjpt3zlnw * node1 Ready Active Leader 18.03.0-ce vdip2js7tfflxv0smj6wdw0bv node2 Ready Active 18.03.0-ce vi17ametnwd58297z6nlcl2o0 node3 Ready Active 18.03.0-ce ※ 添加标签
docker node update --label-add role=web node1 ※ 查看标签
docker node inspect node1 [  {  &amp;#34;ID&amp;#34;: &amp;#34;axr4zun8u1es8ytizjpt3zlnw&amp;#34;,  &amp;#34;Version&amp;#34;: {  &amp;#34;Index&amp;#34;: 476  },  &amp;#34;CreatedAt&amp;#34;: &amp;#34;2018-07-19T03:50:02.</description>
    </item>
    
    <item>
      <title>Docker Swarm集群环境搭建及弹性服务部署</title>
      <link>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%BC%B9%E6%80%A7%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Fri, 08 Apr 2022 11:19:06 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%BC%B9%E6%80%A7%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/</guid>
      <description>一、集群搭建 1、环境准备  五台安装了 Docker 的 CentOS 机器，版本为：CentOS 7.8.2003 Docker Engine 1.12+（最低要求 1.12，本文使用 19.03.12） 防火墙开启以下端口或者关闭防火墙：  TCP 端口 2377，用于集群管理通信； TCP 和 UDP 端口 7946，用于节点之间通信； UDP 端口 4789，用于覆盖网络。　    2、机器分布    角色 IP HOSTNAME Docker 版本     Manager 192.168.10.101 manager1 19.03.12   Manager 192.168.10.102 manager2 19.03.12   Manager 192.168.10.103 manager3 19.03.12   Worker 192.168.10.10 worker1 19.03.12   Worker 192.168.10.11 worker2 19.</description>
    </item>
    
    <item>
      <title>Docker Swarm集群管理利器核心概念扫盲</title>
      <link>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%88%A9%E5%99%A8%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E6%89%AB%E7%9B%B2/</link>
      <pubDate>Fri, 08 Apr 2022 10:37:24 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E7%AE%A1%E7%90%86%E5%88%A9%E5%99%A8%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E6%89%AB%E7%9B%B2/</guid>
      <description>一、Swarm 简介 　Docker Swarm 是 Docker 官方推出的容器集群管理工具，基于 Go 语言实现。代码开源在：https://github.com/docker/swarm 使用它可以将多个 Docker 主机封装为单个大型的虚拟 Docker 主机，快速打造一套容器云平台。
　Docker Swarm 是生产环境中运行 Docker 应用程序最简单的方法。作为容器集群管理器，Swarm 最大的优势之一就是 100% 支持标准的 Docker API。各种基于标准 API 的工具比如 Compose、docker-py、各种管理软件，甚至 Docker 本身等都可以很容易的与 Swarm 进行集成。大大方便了用户将原先基于单节点的系统移植到 Swarm 上，同时 Swarm 内置了对 Docker 网络插件的支持，用户可以很容易地部署跨主机的容器集群服务。
　Docker Swarm 和 Docker Compose 一样，都是 Docker 官方容器编排工具，但不同的是，Docker Compose 是一个在单个服务器或主机上创建多个容器的工具，而 Docker Swarm 则可以在多个服务器或主机上创建容器集群服务，对于微服务的部署，显然 Docker Swarm 会更加适合。
　二、Swarm 核心概念 1、Swarm 　Docker Engine 1.12 引入了 Swarm 模式，一个 Swarm 由多个 Docker 主机组成，它们以 Swarm 集群模式运行。Swarm 集群由 Manager 节点（管理者角色，管理成员和委托任务）和 Worker 节点（工作者角色，运行 Swarm 服务）组成。这些 Docker 主机有些是 Manager 节点，有些是 Worker 节点，或者同时扮演这两种角色。</description>
    </item>
    
    <item>
      <title>CentOS7上安装Apache Maven</title>
      <link>https://iblog.zone/archives/centos7%E4%B8%8A%E5%AE%89%E8%A3%85apache-maven/</link>
      <pubDate>Thu, 07 Apr 2022 17:51:55 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E4%B8%8A%E5%AE%89%E8%A3%85apache-maven/</guid>
      <description>Apache Maven主要用于Java项目的自由开源项目管理。 Maven使用项目对象模型（POM），该对象本质上是一个XML文件，其中包含关于项目，配置，依赖关系等信息。
在本教程中，我们将向您展示两种在CentOS 7上安装Apache Maven的两种不同方法。它们分别：1.yum安装Apache Maven。2.从官方站点下载最新版本Apache Maven并配置环境变量PATH与JAVA_HOME环境变量。
CentOS 默认储存库包含可以通过yum软件包管理器安装的Maven软件包。这是在CentOS上安装Maven的最简单方法，但是存储库中包含的版本可能落后于最新版本的Maven。
要安装最新版本的Maven，请按照本文第二部分提供的说明进行操作，我们将从其官方网站上下载Maven。具体的取决于你的喜好，选择最适合您的设置和环境的安装方法。
先决条件 您所登录的用户必须具有sudo权限，才能安装软件包。
使用Yum在CentOS上安装Apache Maven 使用yum在CentOS 7上安装Maven是一个简单，直接的过程。通过在终端中键入以下命令来安装Maven：
sudo yum install maven 验证安装，通过键入mvn -version命令：
mvn -version 输出应如下所示：
Apache Maven 3.0.5 (Red Hat 3.0.5-17) Maven home: /usr/share/maven Java version: 1.8.0_191, vendor: Oracle Corporation Java home: /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.191.b12-0.el7_5.x86_64/jre Default locale: en_US, platform encoding: UTF-8 OS name: &amp;#34;linux&amp;#34;, version: &amp;#34;3.10.0-862.3.2.el7.x86_64&amp;#34;, arch: &amp;#34;amd64&amp;#34;, family: &amp;#34;unix&amp;#34; 现在，Maven已安装在CentOS系统上。
安装Apache Maven的最新版本 以下提供了有关如何在CentOS 7上安装最新版本的Apache Maven的逐步说明。我们将从官方网站上下载最新版本的Apache Maven。
1.安装OpenJDK Maven 3.3+需要安装JDK 1.7或更高版本。我们将安装OpenJDK ，这是CentOS 7中默认的Java开发和运行时。通过输入以下命令安装OpenJDK软件包：</description>
    </item>
    
    <item>
      <title>CentOS搭建Consul集群</title>
      <link>https://iblog.zone/archives/centos%E6%90%AD%E5%BB%BAconsul%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Thu, 07 Apr 2022 17:29:12 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos%E6%90%AD%E5%BB%BAconsul%E9%9B%86%E7%BE%A4/</guid>
      <description>一、什么是consul 1、Consul 是 HashiCorp 公司推出的开源软件，用于实现分布式系统的服务发现与配置。
Consul 是分布式的、高可用的、 可横向扩展的
2、官方网站:
https://www.consul.io/ 3、Consul 集群间使用了 Gossip 协议通信和 raft 一致性算法
二、下载consul软件 1，下载地址:
https://www.consul.io/downloads 选择64位linux版本下载
2,把consul的安装文件解压:
[root@localhost consul]# cd /usr/local/source/consul [root@localhost consul]# ls consul_1.8.4_linux_amd64.zip [root@localhost consul]# unzip consul_1.8.4_linux_amd64.zip Archive: consul_1.8.4_linux_amd64.zip  inflating: consul [root@localhost consul]# ls consul consul_1.8.4_linux_amd64.zip 3,复制到到各服务器的/usr/local/soft目录下
三、在第一台consul服务器上运行: 1,生成数据目录:
[root@consul1 /]# mkdir /data/ [root@consul1 /]# mkdir /data/consul/ [root@consul1 /]# mkdir /data/consul/data [root@consul1 /]# chmod 777 /data/consul/data 2,运行consul
-server:以server身份启动
-bootstrap-expect=2:集群要求的最少server数量
-bind:监听的ip
-client:客户端ip,0.0.0.0表示不限制客户端ip
-data-dir:指定存放数据的目录
-node:指定节点id,注意：同一集群内节点id不允许重复</description>
    </item>
    
    <item>
      <title>Docker Swarm集群启动时找不到镜像的问题解决</title>
      <link>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%97%B6%E6%89%BE%E4%B8%8D%E5%88%B0%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</link>
      <pubDate>Thu, 07 Apr 2022 14:05:22 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/docker-swarm%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8%E6%97%B6%E6%89%BE%E4%B8%8D%E5%88%B0%E9%95%9C%E5%83%8F%E7%9A%84%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</guid>
      <description>私有镜像仓库搭建
docker run -d -p 5050:5000 --restart always --name registry registry:2 仓库配置
vim /etc/docker/daemon.json
{  &amp;#34;registry-mirrors&amp;#34;: [&amp;#34;https://aqwaeuv8.mirror.aliyuncs.com&amp;#34;],  &amp;#34;insecure-registries&amp;#34;:[&amp;#34;10.3.55.134:5050&amp;#34;] // 取消仓库认证 } 测试，push和pull镜像没有问题，使用docker swarm update时出现找不到镜像错误
问题1：
 update时提示，No such image: 10.3.55.134:5050/ms-group/ly-12320-server-ks_online:5f223018@sha256:261b7ef562bf95a7293046fb0524e5ff2fe70ad55dcd5ffe7981b35f9d50ff56
 解决方案：
需要在所有的docker swarm集群节点都配置daemon.json，并重启docker
systemctl restart docker 问题2：
 修复完以上问题后，再更新时，出现starting container failed: failed to create shim: OCI runtime create failed: container_linux.go:380: starting container process caused: exec: &amp;ldquo;/bin/sh&amp;rdquo;: stat /bin/sh: no such file or directory: unknown
 解决方案：
基础镜像没有/bin/sh导致，检查基础镜像</description>
    </item>
    
    <item>
      <title>CentOS7搭建Rocketmq4.6三主集群</title>
      <link>https://iblog.zone/archives/centos7%E6%90%AD%E5%BB%BArocketmq4.6%E4%B8%89%E4%B8%BB%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Thu, 31 Mar 2022 17:51:01 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E6%90%AD%E5%BB%BArocketmq4.6%E4%B8%89%E4%B8%BB%E9%9B%86%E7%BE%A4/</guid>
      <description>一、下载 wget https://archive.apache.org/dist/rocketmq/4.6.0/rocketmq-all-4.6.0-bin-release.zip unzip rocketmq-all-4.6.0-bin-release.zip mv rocketmq-all-4.6.0-bin-release.zip /data/rocketmq # tree rocketmq rocketmq-all-4.6.0-bin-release ├── LICENSE ├── NOTICE ├── README.md ├── benchmark │ ├── consumer.sh │ ├── producer.sh │ ├── runclass.sh │ └── tproducer.sh ├── bin │ ├── README.md │ ├── cachedog.sh │ ├── cleancache.sh │ ├── cleancache.v1.sh │ ├── dledger │ │ └── fast-try.sh │ ├── mqadmin │ ├── mqadmin.cmd │ ├── mqbroker │ ├── mqbroker.cmd │ ├── mqbroker.numanode0 │ ├── mqbroker.</description>
    </item>
    
    <item>
      <title>CentOS7搭建基于用户认证的MongoDB3.4三节点副本集集群</title>
      <link>https://iblog.zone/archives/centos7%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E7%9A%84mongodb3.4%E4%B8%89%E8%8A%82%E7%82%B9%E5%89%AF%E6%9C%AC%E9%9B%86%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Wed, 30 Mar 2022 15:37:05 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E6%90%AD%E5%BB%BA%E5%9F%BA%E4%BA%8E%E7%94%A8%E6%88%B7%E8%AE%A4%E8%AF%81%E7%9A%84mongodb3.4%E4%B8%89%E8%8A%82%E7%82%B9%E5%89%AF%E6%9C%AC%E9%9B%86%E9%9B%86%E7%BE%A4/</guid>
      <description>基础规划 软件环境 #mongodb下载 # wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel70-3.4.10.tgz #mongodb解压 # tar -zxvf mongodb-linux-x86_64-rhel70-3.4.10.tgz #mongodb安装 # mv mv mongodb-linux-x86_64-rhel70-3.4.10 /usr/local/mongodb #mongodb环境配置 # echo &amp;#39;export PATH=/usr/local/mongodb/bin:$PATH&amp;#39; &amp;gt;&amp;gt; /etc/profile #使配置生效  # source /etc/profile  # 查看是否安装成功 # mongo --version 环境规划&amp;ndash;单机器部署多节点    节点名 节点用途 节点IP 节点端口 集群名     node1 主节点(PRIMARY) 10.0.2.11 27017 mgset   node2 从节点(SECONDARY) 10.0.2.11 27018    node3 仲裁节点(ARBITER) 10.0.2.11 27019        目录 用途 备注     /data/mongodb/node[x]/data Mongo集群数据文件目录    /data/mongodb/node[x]/logs Mongo集群系统日志目录    /data/mongodb/node[x]/conf Mongo集群配置文件目录     搭建步骤 配置文件 node1的配置文件/data/mongodb/node1/conf/mongod.</description>
    </item>
    
    <item>
      <title>CentOS7安装Redis4.0</title>
      <link>https://iblog.zone/archives/centos7%E5%AE%89%E8%A3%85redis4.0/</link>
      <pubDate>Tue, 29 Mar 2022 18:07:53 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E5%AE%89%E8%A3%85redis4.0/</guid>
      <description>一、Redis安装  安装基础依赖  #安装基础依赖包 sudo yum install -y gcc gcc-c++ make jemalloc-devel epel-release  下载Redis（ https://redis.io/download ）  #从官网获取最新版本的下载链接，然后通过wget命令下载 wget http://download.redis.io/releases/redis-4.0.2.tar.gz  解压到指定目录  #解压 sudo tar -zvxf redis-4.0.2.tar.gz -C /usr/local/src/  编译&amp;amp;安装  #进入目录 cd /usr/local/src/redis-4.0.2 #编译&amp;amp;安装 sudo make -j 16 &amp;amp; make install 二、Redis启动与测试  启动redis-server  #进入src目录 cd /usr/local/src/redis-4.0.2/src #启动服务端 sudo ./redis-server  启动redis客户端测试  #进入src目录 cd /usr/local/src/redis-4.0.2/src #启动客户端 sudo ./redis-cli  设置：set key1 value1 获取：get key1</description>
    </item>
    
    <item>
      <title>CentOS7编译安装MySQL5.6</title>
      <link>https://iblog.zone/archives/centos7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85mysql5.6/</link>
      <pubDate>Tue, 29 Mar 2022 17:04:41 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85mysql5.6/</guid>
      <description>1、下载mysql的安装包
#下载mysql wget https://cdn.mysql.com/archives/mysql-5.6/mysql-5.6.30.tar.gz 2、编译安装mysql
#查看系统发行版本号 cat /etc/redhat-release CentOS Linux release 7.8.2003 (Core)  # 安装依赖包 yum install ncurses-devel libaio-devel -y yum install cmake gcc gcc-c++ make autoconf -y  #关闭SELinux #临时关闭selinux setenforce 0 #永久关闭selinux sed -i &amp;#39;s#SELINUX=enforcing#SELINUX=disabled#g&amp;#39; /etc/selinux/config  #关闭防火墙 #查看防火墙状态 systemctl status firewalld.service #临时关闭防火墙 systemctl stop firewalld.service #永久关闭防火墙 systemctl disable firewalld.service  #创建mysql帐号 groupadd -r mysql useradd -r -g mysql -s /sbin/nologin mysql  # 编译安装mysql tar xf mysql-5.</description>
    </item>
    
    <item>
      <title>Mysql备份和恢复（Xtrabackup方式）</title>
      <link>https://iblog.zone/archives/mysql%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8Dxtrabackup%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Fri, 25 Mar 2022 18:03:04 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/mysql%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8Dxtrabackup%E6%96%B9%E5%BC%8F/</guid>
      <description>一、Xtrabackup介绍 　MySQL冷备、mysqldump、MySQL热拷贝都无法实现对数据库进行增量备份。在实际生产环境中增量备份是非常实用的，如果数据大于50G或100G，存储空间足够的情况下，可以每天进行完整备份，如果每天产生的数据量较大，需要定制数据备份策略。例如每周实用完整备份，周一到周六实用增量备份。而Percona-Xtrabackup就是为了实现增量备份而出现的一款主流备份工具，xtrabakackup有2个工具，分别是xtrabakup、innobakupe。
　Percona-xtrabackup是 Percona公司开发的一个用于MySQL数据库物理热备的备份工具，支持MySQL、Percona server和MariaDB，开源免费，是目前较为受欢迎的主流备份工具。xtrabackup只能备份innoDB和xtraDB两种数据引擎的表，而不能备份MyISAM数据表。
二、Xtrabackup优点 （1）备份速度快，物理备份可靠
（2）备份过程不会打断正在执行的事务（无需锁表）
（3）能够基于压缩等功能节约磁盘空间和流量
（4）自动备份校验
（5）还原速度快
（6）可以流传将备份传输到另外一台机器上
（7）在不增加服务器负载的情况备份数据
三、Xtrabackup备份原理 Xtrabackup备份流程图：
（1）innobackupex启动后，会先fork一个进程，用于启动xtrabackup，然后等待xtrabackup备份ibd数据文件；
（2）xtrabackup在备份innoDB数据是，有2种线程：redo拷贝线程和ibd数据拷贝线程。xtrabackup进程开始执行后，会启动一个redo拷贝的线程，用于从最新的checkpoint点开始顺序拷贝redo.log；再启动ibd数据拷贝线程，进行拷贝ibd数据。这里是先启动redo拷贝线程的。在此阶段，innobackupex进行处于等待状态（等待文件被创建）
（4）xtrabackup拷贝完成ibd数据文件后，会通知innobackupex（通过创建文件），同时xtrabackup进入等待状态（redo线程依旧在拷贝redo.log）
（5）innobackupex收到xtrabackup通知后哦，执行FLUSH TABLES WITH READ LOCK（FTWRL），取得一致性位点，然后开始备份非InnoDB文件（如frm、MYD、MYI、CSV、opt、par等格式的文件），在拷贝非InnoDB文件的过程当中，数据库处于全局只读状态。
（6）当innobackup拷贝完所有的非InnoDB文件后，会通知xtrabackup，通知完成后，进入等待状态；
（7）xtrabackup收到innobackupex备份完成的通知后，会停止redo拷贝线程，然后通知innobackupex，redo.log文件拷贝完成；
（8）innobackupex收到redo.log备份完成后，就进行解锁操作，执行：UNLOCK TABLES；
（9）最后innbackupex和xtrabackup进程各自释放资源，写备份元数据信息等，innobackupex等xtrabackup子进程结束后退出。
四、xtrabackup的安装部署以及备份恢复实现 1、xtrabackup的安装 下载地址：https://www.percona.com/downloads/XtraBackup/LATEST/
可以选择rpm包方式安装，也可以下载源码包编译安装，这里直接采用rpm包的方式进行安装
[root@master tools]# wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.9/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm [root@master tools]# yum install -y percona-xtrabackup-24-2.4.9-1.el7.x86_64.rpm  [root@master ~]# rpm -qa |grep xtrabackup percona-xtrabackup-24-2.4.9-1.el7.x86_64  Xtrabackup中主要包含两个工具： xtrabackup：是用于热备innodb，xtradb表中数据的工具，不能备份其他类型的表，也不能备份数据表结构； innobackupex：是将xtrabackup进行封装的perl脚本，提供了备份myisam表的能力。 常用选项:  --host 指定主机  --user 指定用户名  --password 指定密码  --port 指定端口  --databases 指定数据库  --incremental 创建增量备份  --incremental-basedir 指定包含完全备份的目录  --incremental-dir 指定包含增量备份的目录  --apply-log 对备份进行预处理操作  一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。  --redo-only 不回滚未提交事务  --copy-back 恢复备份目录 使用innobackupex备份时，其会调用xtrabackup备份所有的InnoDB表，复制所有关于表结构定义的相关文件(.</description>
    </item>
    
    <item>
      <title>Mysql备份和恢复（mysqldump方式）</title>
      <link>https://iblog.zone/archives/mysql%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8Dmysqldump%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Fri, 25 Mar 2022 17:55:51 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/mysql%E5%A4%87%E4%BB%BD%E5%92%8C%E6%81%A2%E5%A4%8Dmysqldump%E6%96%B9%E5%BC%8F/</guid>
      <description>一、备份单个数据库 1、备份命令：mysqldump
　MySQL数据库自带的一个很好用的备份命令。是逻辑备份，导出的是SQL语句。也就是把数据从MySQL库中以逻辑的SQL语句的形式直接输出或生成备份的文件的过程。
单实例语法（Syntax）: mysqldump -u &amp;lt;username&amp;gt; -p &amp;lt;dbname&amp;gt; &amp;gt; /path/to/***.sql  多实例的备份语法（Syntax）： mysqldump -u &amp;lt;username&amp;gt; -p &amp;lt;dbname&amp;gt; -S &amp;lt;sockPath&amp;gt; &amp;gt; /path/to/***.sql  eg: mysqldump -u root -p wordpress &amp;gt; /opt/wordpress_$(date +%F).sql 2、参数解析
 1 -A --all-databases：导出全部数据库  2 -Y --all-tablespaces：导出全部表空间  3 -y --no-tablespaces：不导出任何表空间信息  4 --add-drop-database每个数据库创建之前添加drop数据库语句。  5 --add-drop-table每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用--skip-add-drop-table取消选项)  6 --add-locks在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(默认为打开状态，使用--skip-add-locks取消选项)  7 --comments附加注释信息。默认为打开，可以用--skip-comments取消  8 --compact导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：--skip-add-drop-table --skip-add-locks --skip-comments --skip-disable-keys  9 -c --complete-insert：使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。 10 -C --compress：在客户端和服务器之间启用压缩传递所有信息 11 -B--databases：导出几个数据库。参数后面所有名字参量都被看作数据库名。 12 --debug输出debug信息，用于调试。默认值为：d:t:o,/tmp/ 13 --debug-info输出调试信息并退出 14 --default-character-set设置默认字符集，默认值为utf8 15 --delayed-insert采用延时插入方式（INSERT DELAYED）导出数据 16 -E--events：导出事件。 17 --master-data：在备份文件中写入备份时的binlog文件，在恢复进，增量数据从这个文件之后的日志开始恢复。值为1时，binlog文件名和位置没有注释，为2时，则在备份文件中将binlog的文件名和位置进行注释 18 --flush-logs开始导出之前刷新日志。请注意：假如一次导出多个数据库(使用选项--databases或者--all-databases)，将会逐个数据库刷新日志。除使用--lock-all-tables或者--master-data外。在这种情况下，日志将会被刷新一次，相应的所以表同时被锁定。因此，如果打算同时导出和刷新日志应该使用--lock-all-tables 或者--master-data 和--flush-logs。 19 --flush-privileges在导出mysql数据库之后，发出一条FLUSH PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。 20 --force在导出过程中忽略出现的SQL错误。 21 -h --host：需要导出的主机信息 22 --ignore-table不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table=database.</description>
    </item>
    
    <item>
      <title>Mysql用户操作</title>
      <link>https://iblog.zone/archives/mysql%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Fri, 25 Mar 2022 17:05:07 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/mysql%E7%94%A8%E6%88%B7%E6%93%8D%E4%BD%9C/</guid>
      <description>Mysql 5.6 -- 创建用户 CREATE USER &amp;#39;joker&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;qweasd11&amp;#39;;  -- 授权用户访问的数据库以及权限 grant all privileges on test.* to &amp;#39;joker&amp;#39;@&amp;#39;%&amp;#39;; -- test为访问数据库 -- all privileges 表示可以对数据进行任意的操作, -- all privileges 可以替换为 select,delete,update,create,drop  -- 修改用户的密码 update mysql.user set password=password(&amp;#39;qweasd11&amp;#39;) where user=&amp;#39;joker&amp;#39;;  -- 修改密码必须刷新才会起作用 flush privileges; Mysql 5.7 -- 创建用户 CREATE USER &amp;#39;joker&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;qweasd11&amp;#39;;  -- 授权用户访问的数据库以及权限 grant all privileges on test.* to &amp;#39;joker&amp;#39;@&amp;#39;%&amp;#39;; -- test为访问数据库 -- all privileges 表示可以对数据进行任意的操作, -- all privileges 可以替换为 select,delete,update,create,drop  -- 修改用户的密码 update mysql.</description>
    </item>
    
    <item>
      <title>Hexo迁移至hugo</title>
      <link>https://iblog.zone/archives/hexo%E8%BF%81%E7%A7%BB%E8%87%B3hugo/</link>
      <pubDate>Thu, 24 Mar 2022 17:19:31 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/hexo%E8%BF%81%E7%A7%BB%E8%87%B3hugo/</guid>
      <description>今天正式把之前的博客文章迁移至hugo了，终于不用再忍受hexo缓慢的生成速度了，以下记录一下迁移过程
一、hugo安装 brew install hugo 二、创建网站 hugo new site iblog 三、安装主题 git clone https://github.com/adityatelange/hugo-PaperMod themes/PaperMod --depth=1 cd themes/PaperMod git pull 四、配置config.yml（不使用config.toml） baseURL: &amp;#34;https://iblog.zone&amp;#34; title: ylw&amp;#39;s blog paginate: 10 theme: PaperMod defaultContentLanguage: zh  permalinks:  posts: /archives/:slug/  enableInlineShortcodes: true enableRobotsTXT: true buildDrafts: false buildFuture: false buildExpired: false enableEmoji: true  # googleAnalytics: UA-123-45  minify:  disableXML: true  minifyOutput: false  params:  env: production # to enable google analytics, opengraph, twitter-cards and schema.</description>
    </item>
    
    <item>
      <title>Nignx导致java程序TruncatedChunkException解决办法</title>
      <link>https://iblog.zone/archives/nignx%E5%AF%BC%E8%87%B4java%E7%A8%8B%E5%BA%8Ftruncatedchunkexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Thu, 24 Mar 2022 16:49:20 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nignx%E5%AF%BC%E8%87%B4java%E7%A8%8B%E5%BA%8Ftruncatedchunkexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid>
      <description>#项目异常信息 org.apache.http.TruncatedChunkException: Truncated chunk ( expected size: 7752; actual size: 4077)  at org.apache.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:186)  at org.apache.http.conn.EofSensorInputStream.read(EofSensorInputStream.java:138)  at &amp;lt;mypackage&amp;gt;.&amp;lt;MyServlet&amp;gt;.service(&amp;lt;MyServlet&amp;gt;.java:XXX)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)  at org.jboss.resteasy.plugins.server.servlet.FilterDispatcher.doFilter(FilterDispatcher.java:63)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)  at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859)  at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:602)  at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)  at java.lang.Thread.run(Thread.java:724) 当系统报以上错误时，接口表现出来的是数据传输不完整， 比如说接口返回 json ， 那么接收到的数据可能会少一截，json 数据说不定会少个 ｝ ，此时json就无法反序列化了。说白了就是丢包了。</description>
    </item>
    
    <item>
      <title>查看mysql库大小，表大小，索引大小</title>
      <link>https://iblog.zone/archives/%E6%9F%A5%E7%9C%8Bmysql%E5%BA%93%E5%A4%A7%E5%B0%8F%E8%A1%A8%E5%A4%A7%E5%B0%8F%E7%B4%A2%E5%BC%95%E5%A4%A7%E5%B0%8F/</link>
      <pubDate>Fri, 18 Mar 2022 16:38:25 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E6%9F%A5%E7%9C%8Bmysql%E5%BA%93%E5%A4%A7%E5%B0%8F%E8%A1%A8%E5%A4%A7%E5%B0%8F%E7%B4%A2%E5%BC%95%E5%A4%A7%E5%B0%8F/</guid>
      <description>说明：
通过MySQL的 information_schema 数据库，可查询数据库中每个表占用的空间、表记录的行数；该库中有一个 TABLES 表，这个表主要字段分别是：
 TABLE_SCHEMA : 数据库名 TABLE_NAME：表名 ENGINE：所使用的存储引擎 TABLES_ROWS：记录数 DATA_LENGTH：数据大小 INDEX_LENGTH：索引大小  其他字段请参考MySQL的手册，查看一个表占用空间的大小，那就相当于是 数据大小 + 索引大小 。
查看所有库的大小
mysql&amp;gt; use information_schema; Database changed mysql&amp;gt; select concat(round(sum(DATA_LENGTH/1024/1024),2),&amp;#39;MB&amp;#39;) as data from TABLES; +----------+ | data | +----------+ | 104.21MB | +----------+ 1 row in set (0.11 sec) 查看指定库的大小
mysql&amp;gt; select concat(round(sum(DATA_LENGTH/1024/1024),2),&amp;#39;MB&amp;#39;) as data from TABLES where table_schema=&amp;#39;jishi&amp;#39;; +---------+ | data | +---------+ | 26.17MB | +---------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>Java网络编程02</title>
      <link>https://iblog.zone/archives/java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B02/</link>
      <pubDate>Fri, 18 Mar 2022 11:44:51 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B02/</guid>
      <description>1.NIO 1.1 NIO通道客户端【应用】   客户端实现步骤
 打开通道 指定IP和端口号 写出数据 释放资源    示例代码
public class NIOClient {  public static void main(String[] args) throws IOException {  //1.打开通道  SocketChannel socketChannel = SocketChannel.open();   //2.指定IP和端口号  socketChannel.connect(new InetSocketAddress(&amp;#34;127.0.0.1&amp;#34;,10000));   //3.写出数据  ByteBuffer byteBuffer = ByteBuffer.wrap(&amp;#34;一点寒毛先制&amp;#34;.getBytes());  socketChannel.write(byteBuffer);   //4.释放资源  socketChannel.close();  } }   1.2 NIO通道服务端【应用】   NIO通道
  服务端通道
只负责建立建立，不负责传递数据</description>
    </item>
    
    <item>
      <title>Java网络编程01</title>
      <link>https://iblog.zone/archives/java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B01/</link>
      <pubDate>Fri, 18 Mar 2022 11:30:56 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B01/</guid>
      <description>1.网络编程入门 1.1 网络编程概述【理解】   计算机网络
是指将地理位置不同的具有独立功能的多台计算机及其外部设备，通过通信线路连接起来，在网络操作系统，网络管理软件及网络通信协议的管理和协调下，实现资源共享和信息传递的计算机系统
  网络编程
在网络通信协议下，不同计算机上运行的程序，可以进行数据传输
  1.2 网络编程三要素【理解】   IP地址
要想让网络中的计算机能够互相通信，必须为每台计算机指定一个标识号，通过这个标识号来指定要接收数据的计算机和识别发送的计算机，而IP地址就是这个标识号。也就是设备的标识
  端口
网络的通信，本质上是两个应用程序的通信。每台计算机都有很多的应用程序，那么在网络通信时，如何区分这些应用程序呢？如果说IP地址可以唯一标识网络中的设备，那么端口号就可以唯一标识设备中的应用程序了。也就是应用程序的标识
  协议
通过计算机网络可以使多台计算机实现连接，位于同一个网络中的计算机在进行连接和通信时需要遵守一定的规则，这就好比在道路中行驶的汽车一定要遵守交通规则一样。在计算机网络中，这些连接和通信的规则被称为网络通信协议，它对数据的传输格式、传输速率、传输步骤等做了统一规定，通信双方必须同时遵守才能完成数据交换。常见的协议有UDP协议和TCP协议
  1.3 IP地址【理解】 IP地址：是网络中设备的唯一标识
  IP地址分为两大类
  IPv4：是给每个连接在网络上的主机分配一个32bit地址。按照TCP/IP规定，IP地址用二进制来表示，每个IP地址长32bit，也就是4个字节。例如一个采用二进制形式的IP地址是“11000000 10101000 00000001 01000010”，这么长的地址，处理起来也太费劲了。为了方便使用，IP地址经常被写成十进制的形式，中间使用符号“.”分隔不同的字节。于是，上面的IP地址可以表示为“192.168.1.66”。IP地址的这种表示法叫做“点分十进制表示法”，这显然比1和0容易记忆得多
  IPv6：由于互联网的蓬勃发展，IP地址的需求量愈来愈大，但是网络地址资源有限，使得IP的分配越发紧张。为了扩大地址空间，通过IPv6重新定义地址空间，采用128位地址长度，每16个字节一组，分成8组十六进制数，这样就解决了网络地址资源数量不够的问题
    DOS常用命令：
  ipconfig：查看本机IP地址
  ping IP地址：检查网络是否连通
    特殊IP地址：
 127.0.0.1：是回送地址，可以代表本机地址，一般用来测试使用    1.4 InetAddress【应用】 InetAddress：此类表示Internet协议（IP）地址
  相关方法</description>
    </item>
    
    <item>
      <title>用yum安装的nginx，报unknown directive “stream”</title>
      <link>https://iblog.zone/archives/%E7%94%A8yum%E5%AE%89%E8%A3%85%E7%9A%84nginx%E6%8A%A5unknown-directive-stream/</link>
      <pubDate>Wed, 16 Mar 2022 16:18:46 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E7%94%A8yum%E5%AE%89%E8%A3%85%E7%9A%84nginx%E6%8A%A5unknown-directive-stream/</guid>
      <description>用yum安装的nginx，报unknown directive “stream”
解决方法：yum install nginx-mod-stream -y
[root@localhost modules]# yum install nginx-mod-stream -y  已安装:  nginx-mod-stream.x86_64 1:1.20.1-2.el7 安装位置
[root@localhost ~]# ll /usr/lib64/nginx/modules 总用量 176 -rwxr-xr-x 1 root root 179864 6月 2 08:24 ngx_stream_module.so nginx配置文件引入
[root@localhost ~]# cat /etc/nginx/nginx.conf # 加载stream模块 load_module /usr/lib64/nginx/modules/ngx_stream_module.so; user nginx; worker_processes auto; ... </description>
    </item>
    
    <item>
      <title>Java多线程02</title>
      <link>https://iblog.zone/archives/java%E5%A4%9A%E7%BA%BF%E7%A8%8B02/</link>
      <pubDate>Tue, 15 Mar 2022 17:30:37 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%A4%9A%E7%BA%BF%E7%A8%8B02/</guid>
      <description>1.线程池 1.1 线程状态介绍 当线程被创建并启动以后，它既不是一启动就进入了执行状态，也不是一直处于执行状态。线程对象在不同的时期有不同的状态。那么Java中的线程存在哪几种状态呢？Java中的线程
状态被定义在了java.lang.Thread.State枚举类中，State枚举类的源码如下：
public class Thread {   public enum State {   /* 新建 */  NEW ,   /* 可运行状态 */  RUNNABLE ,   /* 阻塞状态 */  BLOCKED ,   /* 无限等待状态 */  WAITING ,   /* 计时等待 */  TIMED_WAITING ,   /* 终止 */  TERMINATED;  	}   // 获取当前线程的状态  public State getState() {  return jdk.</description>
    </item>
    
    <item>
      <title>Java多线程01</title>
      <link>https://iblog.zone/archives/java%E5%A4%9A%E7%BA%BF%E7%A8%8B01/</link>
      <pubDate>Tue, 15 Mar 2022 15:02:24 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%A4%9A%E7%BA%BF%E7%A8%8B01/</guid>
      <description>1.实现多线程 1.1简单了解多线程【理解】 是指从软件或者硬件上实现多个线程并发执行的技术。 具有多线程能力的计算机因有硬件支持而能够在同一时间执行多个线程，提升性能。
1.2并发和并行【理解】   并行：在同一时刻，有多个指令在多个CPU上同时执行。
  并发：在同一时刻，有多个指令在单个CPU上交替执行。
  1.3进程和线程【理解】   进程：是正在运行的程序
独立性：进程是一个能独立运行的基本单位，同时也是系统分配资源和调度的独立单位 动态性：进程的实质是程序的一次执行过程，进程是动态产生，动态消亡的 并发性：任何进程都可以同其他进程一起并发执行
  线程：是进程中的单个顺序控制流，是一条执行路径
​	单线程：一个进程如果只有一条执行路径，则称为单线程程序
​	多线程：一个进程如果有多条执行路径，则称为多线程程序
  1.4实现多线程方式一：继承Thread类【应用】   方法介绍
   方法名 说明     void run() 在线程开启后，此方法将被调用执行   void start() 使此线程开始执行，Java虚拟机会调用run方法()      实现步骤
 定义一个类MyThread继承Thread类 在MyThread类中重写run()方法 创建MyThread类的对象 启动线程    代码演示
public class MyThread extends Thread {  @Override  public void run() {  for(int i=0; i&amp;lt;100; i++) {  System.</description>
    </item>
    
    <item>
      <title>Java IO流02</title>
      <link>https://iblog.zone/archives/java-io%E6%B5%8102/</link>
      <pubDate>Mon, 14 Mar 2022 14:15:53 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java-io%E6%B5%8102/</guid>
      <description>1.字符流 1.1为什么会出现字符流【理解】   字符流的介绍
由于字节流操作中文不是特别的方便，所以Java就提供字符流
字符流 = 字节流 + 编码表
  中文的字节存储方式
用字节流复制文本文件时，文本文件也会有中文，但是没有问题，原因是最终底层操作会自动进行字节拼接成中文，如何识别是中文的呢？
汉字在存储的时候，无论选择哪种编码存储，第一个字节都是负数
  1.2编码表【理解】   什么是字符集
是一个系统支持的所有字符的集合，包括各国家文字、标点符号、图形符号、数字等
l计算机要准确的存储和识别各种字符集符号，就需要进行字符编码，一套字符集必然至少有一套字符编码。常见字符集有ASCII字符集、GBXXX字符集、Unicode字符集等
  常见的字符集
  ASCII字符集：
lASCII：是基于拉丁字母的一套电脑编码系统，用于显示现代英语，主要包括控制字符(回车键、退格、换行键等)和可显示字符(英文大小写字符、阿拉伯数字和西文符号)
基本的ASCII字符集，使用7位表示一个字符，共128字符。ASCII的扩展字符集使用8位表示一个字符，共256字符，方便支持欧洲常用字符。是一个系统支持的所有字符的集合，包括各国家文字、标点符号、图形符号、数字等
  GBXXX字符集：
GBK：最常用的中文码表。是在GB2312标准基础上的扩展规范，使用了双字节编码方案，共收录了21003个汉字，完全兼容GB2312标准，同时支持繁体汉字以及日韩汉字等
  Unicode字符集：
UTF-8编码：可以用来表示Unicode标准中任意字符，它是电子邮件、网页及其他存储或传送文字的应用 中，优先采用的编码。互联网工程工作小组（IETF）要求所有互联网协议都必须支持UTF-8编码。它使用一至四个字节为每个字符编码
编码规则：
128个US-ASCII字符，只需一个字节编码
拉丁文等字符，需要二个字节编码
大部分常用字（含中文），使用三个字节编码
其他极少使用的Unicode辅助字符，使用四字节编码
    1.3字符串中的编码解码问题【应用】   相关方法
   方法名 说明     byte[] getBytes() 使用平台的默认字符集将该 String编码为一系列字节   byte[] getBytes(String charsetName) 使用指定的字符集将该 String编码为一系列字节   String(byte[] bytes) 使用平台的默认字符集解码指定的字节数组来创建字符串   String(byte[] bytes, String charsetName) 通过指定的字符集解码指定的字节数组来创建字符串      代码演示</description>
    </item>
    
    <item>
      <title>nginx解决内容安全策略CSP（Content-Security-Policy）配置方式</title>
      <link>https://iblog.zone/archives/nginx%E8%A7%A3%E5%86%B3%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5cspcontent-security-policy%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Thu, 10 Mar 2022 18:39:24 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/nginx%E8%A7%A3%E5%86%B3%E5%86%85%E5%AE%B9%E5%AE%89%E5%85%A8%E7%AD%96%E7%95%A5cspcontent-security-policy%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F/</guid>
      <description>前端发布完页面后，无法正常显示，console控制台报
在nginx配置文件中，增加header配置，有严格的顺序
 add_header Content-Security-Policy &amp;#34;default-src &amp;#39;none&amp;#39; 域名 &amp;#39;unsafe-inline&amp;#39; &amp;#39;unsafe-eval&amp;#39; blob: data: ;&amp;#34;;  add_header X-Xss-Protection &amp;#34;1;mode=block&amp;#34;;  add_header X-Content-Type-Options nosniff; 执行结果，页面正常显示</description>
    </item>
    
    <item>
      <title>Content Security Policy 入门教程</title>
      <link>https://iblog.zone/archives/content-security-policy-%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</link>
      <pubDate>Thu, 10 Mar 2022 18:11:13 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/content-security-policy-%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/</guid>
      <description>跨域脚本攻击 XSS 是最常见、危害最大的网页安全漏洞。
为了防止它们，要采取很多编程措施，非常麻烦。很多人提出，能不能根本上解决问题，浏览器自动禁止外部注入恶意脚本？
这就是&amp;quot;网页安全政策&amp;quot;（Content Security Policy，缩写 CSP）的来历。本文详细介绍如何使用 CSP 防止 XSS 攻击。
一、简介 CSP 的实质就是白名单制度，开发者明确告诉客户端，哪些外部资源可以加载和执行，等同于提供白名单。它的实现和执行全部由浏览器完成，开发者只需提供配置。
CSP 大大增强了网页的安全性。攻击者即使发现了漏洞，也没法注入脚本，除非还控制了一台列入了白名单的可信主机。
两种方法可以启用 CSP。一种是通过 HTTP 头信息的Content-Security-Policy的字段。
 Content-Security-Policy: script-src &amp;#39;self&amp;#39;; object-src &amp;#39;none&amp;#39;; style-src cdn.example.org third-party.org; child-src https:  另一种是通过网页的&amp;lt;meta&amp;gt;标签。
 &amp;lt;meta http-equiv=&amp;#34;Content-Security-Policy&amp;#34; content=&amp;#34;script-src &amp;#39;self&amp;#39;; object-src &amp;#39;none&amp;#39;; style-src cdn.example.org third-party.org; child-src https:&amp;#34;&amp;gt;  上面代码中，CSP 做了如下配置。
  脚本：只信任当前域名 &amp;lt;object&amp;gt;标签：不信任任何URL，即不加载任何资源 样式表：只信任cdn.example.org和third-party.org 框架（frame）：必须使用HTTPS协议加载 其他资源：没有限制   启用后，不符合 CSP 的外部资源就会被阻止加载。
Chrome 的报错信息。
Firefox 的报错信息。
二、限制选项 CSP 提供了很多限制选项，涉及安全的各个方面。
2.1 资源加载限制 以下选项限制各类资源的加载。</description>
    </item>
    
    <item>
      <title>Java IO流01</title>
      <link>https://iblog.zone/archives/java-io%E6%B5%8101/</link>
      <pubDate>Thu, 10 Mar 2022 16:22:30 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java-io%E6%B5%8101/</guid>
      <description>1.File类 1.1File类概述和构造方法【应用】   File类介绍
 它是文件和目录路径名的抽象表示 文件和目录是可以通过File封装成对象的 对于File而言,其封装的并不是一个真正存在的文件,仅仅是一个路径名而已.它可以是存在的,也可以是不存在的.将来是要通过具体的操作把这个路径的内容转换为具体存在的    File类的构造方法
   方法名 说明     File(String pathname) 通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例   File(String parent, String child) 从父路径名字符串和子路径名字符串创建新的 File实例   File(File parent, String child) 从父抽象路径名和子路径名字符串创建新的 File实例      示例代码
public class FileDemo01 {  public static void main(String[] args) {  //File(String pathname): 通过将给定的路径名字符串转换为抽象路径名来创建新的 File实例  File f1 = new File(&amp;#34;E:\\itcast\\java.txt&amp;#34;);  System.</description>
    </item>
    
    <item>
      <title>Java集合03</title>
      <link>https://iblog.zone/archives/java%E9%9B%86%E5%90%8803/</link>
      <pubDate>Tue, 08 Mar 2022 15:41:23 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E9%9B%86%E5%90%8803/</guid>
      <description>1.Map集合 1.1Map集合概述和特点【理解】   Map集合概述
interface Map&amp;lt;K,V&amp;gt; K：键的类型；V：值的类型   Map集合的特点
 双列集合,一个键对应一个值 键不可以重复,值可以重复    Map集合的基本使用
public class MapDemo01 {  public static void main(String[] args) {  //创建集合对象  Map&amp;lt;String,String&amp;gt; map = new HashMap&amp;lt;String,String&amp;gt;();   //V put(K key, V value) 将指定的值与该映射中的指定键相关联  map.put(&amp;#34;itheima001&amp;#34;,&amp;#34;林青霞&amp;#34;);  map.put(&amp;#34;itheima002&amp;#34;,&amp;#34;张曼玉&amp;#34;);  map.put(&amp;#34;itheima003&amp;#34;,&amp;#34;王祖贤&amp;#34;);  map.put(&amp;#34;itheima003&amp;#34;,&amp;#34;柳岩&amp;#34;);   //输出集合对象  System.out.println(map);  } }   1.2Map集合的基本功能【应用】   方法介绍
   方法名 说明     V put(K key,V value) 添加元素   V remove(Object key) 根据键删除键值对元素   void clear() 移除所有的键值对元素   boolean containsKey(Object key) 判断集合是否包含指定的键   boolean containsValue(Object value) 判断集合是否包含指定的值   boolean isEmpty() 判断集合是否为空   int size() 集合的长度，也就是集合中键值对的个数      示例代码</description>
    </item>
    
    <item>
      <title>Java集合02</title>
      <link>https://iblog.zone/archives/java%E9%9B%86%E5%90%8802/</link>
      <pubDate>Tue, 08 Mar 2022 14:13:24 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E9%9B%86%E5%90%8802/</guid>
      <description>1.Set集合 1.1Set集合概述和特点【应用】  不可以存储重复元素 没有索引,不能使用普通for循环遍历  1.2Set集合的使用【应用】 存储字符串并遍历
public class MySet1 {  public static void main(String[] args) {  //创建集合对象  Set&amp;lt;String&amp;gt; set = new TreeSet&amp;lt;&amp;gt;();  //添加元素  set.add(&amp;#34;ccc&amp;#34;);  set.add(&amp;#34;aaa&amp;#34;);  set.add(&amp;#34;aaa&amp;#34;);  set.add(&amp;#34;bbb&amp;#34;);  // for (int i = 0; i &amp;lt; set.size(); i++) { // //Set集合是没有索引的，所以不能使用通过索引获取元素的方法 // }   //遍历集合  Iterator&amp;lt;String&amp;gt; it = set.iterator();  while (it.hasNext()){  String s = it.next();  System.</description>
    </item>
    
    <item>
      <title>Java集合01</title>
      <link>https://iblog.zone/archives/java%E9%9B%86%E5%90%8801/</link>
      <pubDate>Tue, 08 Mar 2022 11:00:09 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E9%9B%86%E5%90%8801/</guid>
      <description>1.Collection集合 1.1数组和集合的区别【理解】   相同点
都是容器,可以存储多个数据
  不同点
  数组的长度是不可变的,集合的长度是可变的
  数组可以存基本数据类型和引用数据类型
集合只能存引用数据类型,如果要存基本数据类型,需要存对应的包装类
    1.2集合类体系结构【理解】 1.3Collection 集合概述和使用【应用】   Collection集合概述
 是单例集合的顶层接口,它表示一组对象,这些对象也称为Collection的元素 JDK 不提供此接口的任何直接实现.它提供更具体的子接口(如Set和List)实现    创建Collection集合的对象
 多态的方式 具体的实现类ArrayList    Collection集合常用方法
   方法名 说明     boolean add(E e) 添加元素   boolean remove(Object o) 从集合中移除指定的元素   boolean removeIf(Object o) 根据条件进行移除   void clear() 清空集合中的元素   boolean contains(Object o) 判断集合中是否存在指定的元素   boolean isEmpty() 判断集合是否为空   int size() 集合的长度，也就是集合中元素的个数      1.</description>
    </item>
    
    <item>
      <title>Java常用API02</title>
      <link>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api02/</link>
      <pubDate>Mon, 07 Mar 2022 17:58:13 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api02/</guid>
      <description>1.时间日期类 1.1 Date类（应用）   计算机中时间原点
1970年1月1日 00:00:00
  时间换算单位
1秒 = 1000毫秒
  Date类概述
Date 代表了一个特定的时间，精确到毫秒
  Date类构造方法
   方法名 说明     public Date() 分配一个 Date对象，并初始化，以便它代表它被分配的时间，精确到毫秒   public Date(long date) 分配一个 Date对象，并将其初始化为表示从标准基准时间起指定的毫秒数      示例代码
public class DateDemo01 {  public static void main(String[] args) {  //public Date()：分配一个 Date对象，并初始化，以便它代表它被分配的时间，精确到毫秒  Date d1 = new Date();  System.</description>
    </item>
    
    <item>
      <title>Java常用API01</title>
      <link>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api01/</link>
      <pubDate>Mon, 07 Mar 2022 16:42:06 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api01/</guid>
      <description>1.API 1.1 API概述【理解】   什么是API
​	API (Application Programming Interface) ：应用程序编程接口
  java中的API
​	指的就是 JDK 中提供的各种功能的 Java类，这些类将底层的实现封装了起来，我们不需要关心这些类是如何实现的，只需要学习这些类如何使用即可，我们可以通过帮助文档来学习这些API如何使用。
  1.2 如何使用API帮助文档【应用】   打开帮助文档
  找到索引选项卡中的输入框
  在输入框中输入Random
  看类在哪个包下
  看类的描述
  看构造方法
  看成员方法
  2.常用API 2.1 Math（应用）   1、Math类概述
 Math 包含执行基本数字运算的方法    2、Math中方法的调用方式
 Math类中无构造方法，但内部的方法都是静态的，则可以通过 类名.进行调用    3、Math类的常用方法
   方法名 方法名 说明     public static int abs(int a) 返回参数的绝对值   public static double ceil(double a) 返回大于或等于参数的最小double值，等于一个整数   public static double floor(double a) 返回小于或等于参数的最大double值，等于一个整数   public static int round(float a) 按照四舍五入返回最接近参数的int   public static int max(int a,int b) 返回两个int值中的较大值   public static int min(int a,int b) 返回两个int值中的较小值   public static double pow (double a,double b) 返回a的b次幂的值   public static double random() 返回值为double的正值，[0.</description>
    </item>
    
    <item>
      <title>使用Helm部署Consul集群</title>
      <link>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8helm%E9%83%A8%E7%BD%B2consul%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Fri, 04 Mar 2022 17:27:05 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8helm%E9%83%A8%E7%BD%B2consul%E9%9B%86%E7%BE%A4/</guid>
      <description>Helm 介绍 helm 是 kubernetes 的包管理器。它相当于 CentOS 的 yum ，Ubuntu 的 apt 。
在 helm 中有三大概念：
 Chart：Helm使用的包格式称为 chart。 chart 就是一个描述 Kubernetes 相关资源的文件集合。单个 chart 可以用来部署一些简单的， 类似于 memcache pod，或者某些复杂的 HTTP 服务器以及 web 全栈应用、数据库、缓存等 Repo：chart 的存放仓库，社区的 Helm chart 仓库位于 Artifact Hub，也可以创建运行自己的私有 chart 仓库 Release：运行在 Kubernetes 集群中的 chart 的实例。一个 chart 通常可以在同一个集群中安装多次，而每一次安装都会创建一个新的 release  总结：Helm 安装 charts 到 Kubernetes 集群中，每次安装都会创建一个新的 release 。你可以在 Helm 的 chart repositories 中寻找新的 chart 。
准备阶段 拥有一个 Kubernetes 集群，如下：
具体配置：</description>
    </item>
    
    <item>
      <title>K8S中使用Ceph集群动态和静态方式挂载PV与PVC</title>
      <link>https://iblog.zone/archives/k8s%E4%B8%AD%E4%BD%BF%E7%94%A8ceph%E9%9B%86%E7%BE%A4%E5%8A%A8%E6%80%81%E5%92%8C%E9%9D%99%E6%80%81%E6%96%B9%E5%BC%8F%E6%8C%82%E8%BD%BDpv%E4%B8%8Epvc/</link>
      <pubDate>Tue, 01 Mar 2022 14:12:42 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/k8s%E4%B8%AD%E4%BD%BF%E7%94%A8ceph%E9%9B%86%E7%BE%A4%E5%8A%A8%E6%80%81%E5%92%8C%E9%9D%99%E6%80%81%E6%96%B9%E5%BC%8F%E6%8C%82%E8%BD%BDpv%E4%B8%8Epvc/</guid>
      <description>一、CephFS介绍  Ceph File System (CephFS) 是与 POSIX 标准兼容的文件系统, 能够提供对 Ceph 存储集群上的文件访问. Jewel 版本 (10.2.0) 是第一个包含稳定 CephFS 的 Ceph 版本. CephFS 需要至少一个元数据服务器 (Metadata Server – MDS) daemon (ceph-mds) 运行, MDS daemon 管理着与存储在 CephFS 上的文件相关的元数据, 并且协调着对 Ceph 存储系统的访问。
对象存储的成本比起普通的文件存储还是较高，需要购买专门的对象存储软件以及大容量硬盘。如果对数据量要求不是海量，只是为了做文件共享的时候，直接用文件存储的形式好了，性价比高。
二、使用CephFS类型Volume直接挂载  cephfs卷允许将现有的cephfs卷挂载到你的Pod中，与emptyDir类型不同的是，emptyDir会在删除Pod时把数据清除掉，而cephfs卷的数据会被保留下来,仅仅是被卸载，并且cephfs可以被多个设备进行读写。
1、安装 Ceph 客户端 在部署 kubernetes 之前我们就已经有了 Ceph 集群，因此我们可以直接拿来用。但是 kubernetes 的所有节点（尤其是 master 节点）上依然需要安装 ceph 客户端。
yum install -y ceph-common  还需要将 ceph 的配置文件 ceph.conf 放在所有节点的 /etc/ceph 目录下  2、创建Ceph secret  注意： ceph_secret.</description>
    </item>
    
    <item>
      <title>Ceph文件系统—CephFS部署</title>
      <link>https://iblog.zone/archives/ceph%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Fcephfs%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Tue, 01 Mar 2022 11:34:22 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/ceph%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9Fcephfs%E9%83%A8%E7%BD%B2/</guid>
      <description>一、CephFS介绍  Ceph File System (CephFS) 是与 POSIX 标准兼容的文件系统, 能够提供对 Ceph 存储集群上的文件访问. Jewel 版本 (10.2.0) 是第一个包含稳定 CephFS 的 Ceph 版本. CephFS 需要至少一个元数据服务器 (Metadata Server – MDS) daemon (ceph-mds) 运行, MDS daemon 管理着与存储在 CephFS 上的文件相关的元数据, 并且协调着对 Ceph 存储系统的访问。
 注意：你集群里必须有MDS，不然无法进行下面的操作  二、CephFS创建   要使用 CephFS， 至少就需要一个 metadata server 进程；在admin节点通过以下命令进行创建  [root@ceph-admin ~]# su - cephu  [cephu@ceph-admin ~]$ cd ~/my-cluster/ [cephu@ceph-admin my-cluster]$ ceph-deploy mds create ceph-node2 #无报错则创建完成 三、CephFS部署  1、部署流程  在一个 Mon 节点上创建 Ceph 文件系统.</description>
    </item>
    
    <item>
      <title>Ceph存储集群部署</title>
      <link>https://iblog.zone/archives/ceph%E5%AD%98%E5%82%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Tue, 01 Mar 2022 10:50:57 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/ceph%E5%AD%98%E5%82%A8%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</guid>
      <description>一、CEPH 简介 不管你是想为云平台提供Ceph 对象存储或Ceph 块设备，还是想部署一个Ceph 文件系统或者把 Ceph 作为他用，所有Ceph 存储集群的部署都始于部署一个个Ceph 节点、网络和 Ceph 存储集群。 Ceph 存储集群至少需要一个 Ceph Monitor 和两个 OSD 守护进程。而运行 Ceph 文件系统客户端时，则必须要有元数据服务器（ Metadata Server ）。
 **Ceph OSDs：**Ceph OSD 守护进程（ Ceph OSD ）的功能是存储数据，处理数据的复制、恢复、回填、再均衡，并通过检查其他OSD 守护进程的心跳来向 Ceph Monitors 提供一些监控信息。当 Ceph 存储集群设定为有2个副本时，至少需要2个 OSD 守护进程，集群才能达到 active+clean 状态（ Ceph 默认有3个副本，但你可以调整副本数）。 **Monitors：**Ceph Monitor维护着展示集群状态的各种图表，包括监视器图、 OSD 图、归置组（ PG ）图、和 CRUSH 图。 Ceph 保存着发生在Monitors 、 OSD 和 PG上的每一次状态变更的历史信息（称为 epoch ）。 **MDSs：**Ceph 元数据服务器（ MDS ）为 Ceph 文件系统存储元数据（也就是说，Ceph 块设备和 Ceph 对象存储不使用MDS ）。元数据服务器使得 POSIX 文件系统的用户们，可以在不对 Ceph 存储集群造成负担的前提下，执行诸如 ls、find 等基本命令。  Ceph 把客户端数据保存为存储池内的对象。通过使用 CRUSH 算法， Ceph 可以计算出哪个归置组（PG）应该持有指定的对象(Object)，然后进一步计算出哪个 OSD 守护进程持有该归置组。 CRUSH 算法使得 Ceph 存储集群能够动态地伸缩、再均衡和修复。</description>
    </item>
    
    <item>
      <title>主流分布式文件系统选型</title>
      <link>https://iblog.zone/archives/%E4%B8%BB%E6%B5%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B/</link>
      <pubDate>Mon, 28 Feb 2022 14:18:20 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E4%B8%BB%E6%B5%81%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E9%80%89%E5%9E%8B/</guid>
      <description>一、概述 分布式文件系统是分布式领域的一个基础应用，其中最著名的毫无疑问是 HDFS/GFS。如今该领域已经趋向于成熟，但了解它的设计要点和思想，对我们将来面临类似场景/问题时，具有借鉴意义。
并且，分布式文件系统并非只有 HDFS/GFS 这一种形态，在它之外，还有其他形态各异、各有千秋的产品形态，对它们的了解，也对扩展我们的视野有所俾益。
本文试图分析和思考，在分布式文件系统领域，我们要解决哪些问题、有些什么样的方案、以及各自的选择依据。
二、过去的样子 在几十年以前，分布式文件系统就已经出现了，以 Sun 在 1984 年开发的“Network File System (NFS)”为代表，那时候解决的主要问题，是网络形态的磁盘，把磁盘从主机中独立出来。
这样不仅可以获得更大的容量，而且还可以随时切换主机，还可以实现数据共享、备份、容灾等，因为数据是电脑中最重要的资产。
NFS 的数据通信图如下：
部署在主机上的客户端，通过 TCP/IP 协议把文件命令转发到远程文件 Server 上执行，整个过程对主机用户透明。
到了互联网时代，流量和数据快速增长，分布式文件系统所要解决的主要场景变了，开始需要非常大的磁盘空间，这在磁盘体系上垂直扩容是无法达到的，必须要分布式，同时分布式架构下，主机都是可靠性不是非常好的普通服务器，因此容错、高可用、持久化、伸缩性等指标，就成为必须要考量的特性。
三、对分布式文件系统的要求 对一个分布式文件系统而言，有一些特性是必须要满足的，否则就无法有竞争力。主要如下：
 应该符合 POSIX 的文件接口标准，使该系统易于使用，同时对于用户的遗留系统也无需改造； 对用户透明，能够像使用本地文件系统那样直接使用； 持久化，保证数据不会丢失； 具有伸缩性，当数据压力逐渐增长时能顺利扩容； 具有可靠的安全机制，保证数据安全； 数据一致性，只要文件内容不发生变化，什么时候去读，得到的内容应该都是一样的。  除此之外，还有些特性是分布式加分项，具体如下：
 支持的空间越大越好； 支持的并发访问请求越多越好； 性能越快越好； 硬件资源的利用率越高越合理，就越好。  四、架构模型 从业务模型和逻辑架构上，分布式文件系统需要这几类组件：
 存储组件：负责存储文件数据，它要保证文件的持久化、副本间数据一致、数据块的分配 / 合并等等； 管理组件：负责 meta 信息，即文件数据的元信息，包括文件存放在哪台服务器上、文件大小、权限等，除此之外，还要负责对存储组件的管理，包括存储组件所在的服务器是否正常存活、是否需要数据迁移等； 接口组件：提供接口服务给应用使用，形态包括 SDK(Java/C/C++ 等)、CLI 命令行终端、以及支持 FUSE 挂载机制。  而在部署架构上，有着“中心化”和“无中心化”两种路线分歧，即是否把“管理组件”作为分布式文件系统的中心管理节点。两种路线都有很优秀的产品，下面分别介绍它们的区别。
1、有中心节点 以 GFS 为代表，中心节点负责文件定位、维护文件 meta 信息、故障检测、数据迁移等管理控制的职能，下图是 GFS 的架构图：
该图中GFS master 即为 GFS 的中心节点，GF chunkserver 为 GFS 的存储节点。其操作路径如下：</description>
    </item>
    
    <item>
      <title>Java接口和内部类</title>
      <link>https://iblog.zone/archives/java%E6%8E%A5%E5%8F%A3%E5%92%8C%E5%86%85%E9%83%A8%E7%B1%BB/</link>
      <pubDate>Mon, 28 Feb 2022 10:42:17 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E6%8E%A5%E5%8F%A3%E5%92%8C%E5%86%85%E9%83%A8%E7%B1%BB/</guid>
      <description>1.接口 1.1黑马信息管理系统集合改进 (应用)   使用数组容器的弊端
 容器长度是固定的，不能根据添加功能自动增长 没有提供用于赠删改查的方法    优化步骤
  创建新的StudentDao类，OtherStudentDao
  创建ArrayList集合容器对象
  OtherStudentDao中的方法声明，需要跟StudentDao保持一致
注意：如果不一致，StudentService中的代码就需要进行修改
  完善方法（添加、删除、修改、查看）
  替换StudentService中的Dao对象
    代码实现
OtherStudentDao类
public class OtherStudentDao {  // 集合容器  private static ArrayList&amp;lt;Student&amp;gt; stus = new ArrayList&amp;lt;&amp;gt;();   static {  Student stu1 = new Student(&amp;#34;heima001&amp;#34;,&amp;#34;张三&amp;#34;,&amp;#34;23&amp;#34;,&amp;#34;1999-11-11&amp;#34;);  Student stu2 = new Student(&amp;#34;heima002&amp;#34;,&amp;#34;李四&amp;#34;,&amp;#34;24&amp;#34;,&amp;#34;2000-11-11&amp;#34;);   stus.add(stu1);  stus.</description>
    </item>
    
    <item>
      <title>Java继承</title>
      <link>https://iblog.zone/archives/java%E7%BB%A7%E6%89%BF/</link>
      <pubDate>Wed, 23 Feb 2022 18:25:50 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E7%BB%A7%E6%89%BF/</guid>
      <description>1. 继承 1.1 继承的实现（掌握）   继承的概念
 继承是面向对象三大特征之一，可以使得子类具有父类的属性和方法，还可以在子类中重新定义，以及追加属性和方法    实现继承的格式
 继承通过extends实现 格式：class 子类 extends 父类 { }  举例：class Dog extends Animal { }      继承带来的好处
 继承可以让类与类之间产生关系，子父类关系，产生子父类后，子类则可以使用父类中非私有的成员。    示例代码
public class Fu {  public void show() {  System.out.println(&amp;#34;show方法被调用&amp;#34;);  } } public class Zi extends Fu {  public void method() {  System.out.println(&amp;#34;method方法被调用&amp;#34;);  } } public class Demo {  public static void main(String[] args) {  //创建对象，调用方法  Fu f = new Fu();  f.</description>
    </item>
    
    <item>
      <title>Java分类和static</title>
      <link>https://iblog.zone/archives/java%E5%88%86%E7%B1%BB%E5%92%8Cstatic/</link>
      <pubDate>Wed, 23 Feb 2022 16:44:32 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%88%86%E7%B1%BB%E5%92%8Cstatic/</guid>
      <description>1.案例驱动模式 1.1案例驱动模式概述 (理解) 通过我们已掌握的知识点,先实现一个案例,然后找出这个案例中,存在的一些问题,在通过新知识点解决问题
1.2案例驱动模式的好处 (理解)  解决重复代码过多的冗余,提高代码的复用性 解决业务逻辑聚集紧密导致的可读性差,提高代码的可读性 解决代码可维护性差,提高代码的维护性  2.分类思想 2.1分类思想概述 (理解) 分工协作,专人干专事
2.2黑马信息管理系统 (理解)   Student类 标准学生类,封装键盘录入的学生信息(id , name , age , birthday)
  StudentDao类 Dao : (Data Access Object 缩写) 用于访问存储数据的数组或集合
  StudentService类 用来进行业务逻辑的处理(例如: 判断录入的id是否存在)
  StudentController类 和用户打交道(接收用户需求,采集用户信息,打印数据到控制台)
  3.分包思想 3.1分包思想概述 (理解) 如果将所有的类文件都放在同一个包下,不利于管理和后期维护,所以,对于不同功能的类文件,可以放在不同的包下进行管理
3.2包的概述 (记忆)   包
本质上就是文件夹
  创建包
多级包之间使用 &amp;quot; . &amp;quot; 进行分割 多级包的定义规范：公司的网站地址翻转(去掉www) 比如：黑马程序员的网站址为www.itheima.com 后期我们所定义的包的结构就是：com.itheima.其他的包名
  包的命名规则</description>
    </item>
    
    <item>
      <title>Git的安装及使用</title>
      <link>https://iblog.zone/archives/git%E7%9A%84%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Mon, 21 Feb 2022 17:31:16 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/git%E7%9A%84%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/</guid>
      <description>1.Git介绍 1.1版本控制(理解) 无论是代码编写，还是文档编写，我们都会遇到对文档内容反复修改的情况
1.2开发中存在的问题(理解)  程序员小明负责的模块就要完成了，就在即将提交发布之前的一瞬间，电脑突然蓝屏，硬盘光荣下岗！  几个月来的努力付之东流
  老王需要在项目中加入一个很复杂的功能，一边尝试，一边修改代码，就这样摸索了一个星期。 可是这被改得面目全非的代码已经回不到从前了。
  小明和老王先后从文件服务器上下载了同一个文件
  因项目中Bug过多，导致项目进度拖延，项目经理老徐因此被骂，但不清楚Bug是手下哪一个程序员写的
  开发中要解决的问题
 代码备份 版本控制 协同工作 责任追溯    1.3SVN版本控制(理解) SVN是集中式版本控制系统，版本库是集中放在中央服务器的，而开发人员工作的时候，用的都是自己的电脑， 所以首先要从中央服务器下载最新的版本，然后开发，开发完后，需要把自己开发的代码提交到中央服务器。
  服务器单点故障
将会导致所有人员无法工作
  而服务器硬盘损坏
这意味着，你可能失去了该项目的所有历史记录，这是毁灭性的。
  1.4Git版本控制(理解) Git是在2005年，Linux系统的创建者Linus Torvalds,为了帮助全球的开发者，维护Linux系统内核的开发 而开发了自己的开源分布式版本控制工具,分为两种类型的仓库：本地仓库和远程仓库。
  每一个客户端都保存了完整的历史记录
服务器的故障，都可以通过客户端的记录得以恢复。
  2.Git下载和安装 2.1Git的下载(应用) 官网下载地址：https://git-scm.com/downloads
2.2Git的安装(应用)   双击安装包，进入安装向导界面
  指定安装目录
  一路next下一步
  等待安装
  安装完成</description>
    </item>
    
    <item>
      <title>Java ArrayList集合&amp;学生管理系统</title>
      <link>https://iblog.zone/archives/java-arraylist%E9%9B%86%E5%90%88%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Mon, 21 Feb 2022 16:57:09 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java-arraylist%E9%9B%86%E5%90%88%E5%AD%A6%E7%94%9F%E7%AE%A1%E7%90%86%E7%B3%BB%E7%BB%9F/</guid>
      <description>1.ArrayList 集合和数组的区别 :
​	共同点：都是存储数据的容器
​	不同点：数组的容量是固定的，集合的容量是可变的
1.1 -ArrayList的构造方法和添加方法    public ArrayList() 创建一个空的集合对象     public boolean add(E e) 将指定的元素追加到此集合的末尾   public void add(int index,E element) 在此集合中的指定位置插入指定的元素    ArrayList&amp;lt;E&amp;gt; ：
​	可调整大小的数组实现
​	&amp;lt;E&amp;gt; : 是一种特殊的数据类型，泛型。
怎么用呢 ?
​	在出现E的地方我们使用引用数据类型替换即可
​	举例：ArrayList&amp;lt;String&amp;gt;, ArrayList&amp;lt;Student&amp;gt;
1.2ArrayList类常用方法【应用】 **成员方法 : **
   public boolean remove(Object o) 删除指定的元素，返回删除是否成功     public E remove(int index) 删除指定索引处的元素，返回被删除的元素   public E set(int index,E element) 修改指定索引处的元素，返回被修改的元素   public E get(int index) 返回指定索引处的元素   public int size() 返回集合中的元素的个数    示例代码 :</description>
    </item>
    
    <item>
      <title>生产环境搭建高可用Harbor</title>
      <link>https://iblog.zone/archives/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8harbor/</link>
      <pubDate>Fri, 18 Feb 2022 18:15:43 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E9%AB%98%E5%8F%AF%E7%94%A8harbor/</guid>
      <description>前言 因资源成本问题，本Harbor高可用架构为最小开销方案，如果资源充足，可以将PG、Redis全部使用使用云厂商集群模式。
同时为了配置简单，并没有使用keepalived与heartbeat等高可用开源组件。
准备工作    阿里云SLB 阿里云ECS 共享存储 Redis     最小实例SLB 2c4g 2台 阿里云NFS 阿里云Redis    操作系统为Ubuntu18.04，在2台ECS上搭建主从PG，如果不想用阿里云redis，也可以使用ECS搭建Redis。
安装Harbor，用于导出基础harbor数据，恢复到PG集群中.   安装docker-compose
curl -L &amp;#34;https://github.com/docker/compose/releases/download/1.24.0/docker-compose-$(uname -s)-$(uname -m)&amp;#34; -o /usr/local/bin/docker-compose sudo chmod +x /usr/local/bin/docker-compose sudo add-apt-repository &amp;#34;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs)stable&amp;#34; # 添加国内阿里云 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - #更新 sudo apt-get update [[查看docker]]版本 apt-cache madison docker-ce #安装最新版 sudo apt-get install -y docker-ce [[安装5]]:19.</description>
    </item>
    
    <item>
      <title>超好用的k8s中pod诊断工具：kubectl-debug</title>
      <link>https://iblog.zone/archives/%E8%B6%85%E5%A5%BD%E7%94%A8%E7%9A%84k8s%E4%B8%ADpod%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7kubectl-debug/</link>
      <pubDate>Fri, 18 Feb 2022 11:24:51 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E8%B6%85%E5%A5%BD%E7%94%A8%E7%9A%84k8s%E4%B8%ADpod%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7kubectl-debug/</guid>
      <description>背景 容器技术的一个最佳实践是构建尽可能精简的容器镜像。但这一实践却会给排查问题带来麻烦：精简后的容器中普遍缺失常用的排障工具，部分容器里甚至没有 shell (比如 FROM scratch ）。 在这种状况下，我们只能通过日志或者到宿主机上通过 docker-cli 或 nsenter 来排查问题，效率很低，在K8s环境部署应用后，经常遇到需要进入pod进行排错。除了查看pod logs和describe方式之外，传统的解决方式是在业务pod基础镜像中提前安装好procps、net-tools、tcpdump、vim等工具。但这样既不符合最小化镜像原则，又徒增Pod安全漏洞风险。
今天为大家推荐一款K8s pod诊断工具，kubectl-debug是一个简单、易用、强大的 kubectl 插件, 能够帮助你便捷地进行 Kubernetes 上的 Pod 排障诊断。它通过启动一个排错工具容器，并将其加入到目标业务容器的pid, network, user 以及 ipc namespace 中，这时我们就可以在新容器中直接用 netstat, tcpdump 这些熟悉的工具来解决问题了, 而业务容器可以保持最小化, 不需要预装任何额外的排障工具。 kubectl-debug 主要包含以下两部分:
 kubectl-debug：命令行工具 debug-agent：部署在K8s的node上，用于启动关联排错工具容器  工作原理 我们知道，容器本质上是带有 cgroup 资源限制和 namespace 隔离的一组进程。因此，我们只要启动一个进程，并且让这个进程加入到目标容器的各种 namespace 中，这个进程就能 “进入容器内部”（注意引号），与容器中的进程”看到”相同的根文件系统、虚拟网卡、进程空间了——这也正是 docker exec 和 kubectl exec 等命令的运行方式。
现在的状况是，我们不仅要 “进入容器内部”，还希望带一套工具集进去帮忙排查问题。那么，想要高效管理一套工具集，又要可以跨平台，最好的办法就是把工具本身都打包在一个容器镜像当中。 接下来，我们只需要通过这个”工具镜像”启动容器，再指定这个容器加入目标容器的的各种 namespace，自然就实现了 “携带一套工具集进入容器内部”。事实上，使用 docker-cli 就可以实现这个操作：
export TARGET_ID=666666666 # 加入目标容器的 network, pid 以及 ipc namespace docker run -it --network=container:$TARGET_ID --pid=container:$TARGET_ID --ipc=container:$TARGET_ID busybox 这就是 kubectl-debug 的出发点： 用工具容器来诊断业务容器 。背后的设计思路和 sidecar 等模式是一致的：每个容器只做一件事情。</description>
    </item>
    
    <item>
      <title>Java常用API</title>
      <link>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api/</link>
      <pubDate>Wed, 16 Feb 2022 16:20:54 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%B8%B8%E7%94%A8api/</guid>
      <description>1.API 1.1 API概述-帮助文档的使用   什么是API
​	API (Application Programming Interface) ：应用程序编程接口
  java中的API
​	指的就是 JDK 中提供的各种功能的 Java类，这些类将底层的实现封装了起来，我们不需要关心这些类是如何实现的，只需要学习这些类如何使用即可，我们可以通过帮助文档来学习这些API如何使用。
  如何使用API帮助文档 :
  打开帮助文档
  找到索引选项卡中的输入框
  在输入框中输入Random
  看类在哪个包下
  看类的描述
  看构造方法
  看成员方法
  1.2 键盘录入字符串 Scanner类 :
​	next() : 遇到了空格, 就不再录入数据了 , 结束标记: 空格, tab键
​	nextLine() : 可以将数据完整的接收过来 , 结束标记: 回车换行符
代码实现 :
package com.</description>
    </item>
    
    <item>
      <title>CentOS8安装oracle客户端</title>
      <link>https://iblog.zone/archives/centos8%E5%AE%89%E8%A3%85oracle%E5%AE%A2%E6%88%B7%E7%AB%AF/</link>
      <pubDate>Tue, 15 Feb 2022 17:44:41 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos8%E5%AE%89%E8%A3%85oracle%E5%AE%A2%E6%88%B7%E7%AB%AF/</guid>
      <description>1、进入oracle官网 https://www.oracle.com/database/technologies/instant-client/linux-x86-64-downloads.html
下载：
oracle-instantclient-basic-21.3.0.0.0-1.el8.x86_64.rpm oracle-instantclient-sqlplus-21.3.0.0.0-1.el8.x86_64.rpm oracle-instantclient-devel-21.3.0.0.0-1.el8.x86_64.rpm 依次安装：
rpm -ivh oracle-instantclient-basic-21.3.0.0.0-1.el8.x86_64.rpm rpm -ivh oracle-instantclient-sqlplus-21.3.0.0.0-1.el8.x86_64.rpm rpm -ivh oracle-instantclient-devel-21.3.0.0.0-1.el8.x86_64.rpm 安装的文件默认放在两个位置： 头文件：/usr/include/oracle/21/client64 下，如果在使用时报错找不到头文件，记得看路径是否是这个。 包文件：/usr/lib/oracle/21/client64下，包含{bin、lib}两个文件夹；
2、创建监听文件，并添加内容
cd /usr/lib/oracle/21/client64/lib/network/admin
vi tnsnames.ora
ORCL =  (DESCRIPTION =  (ADDRESS = (PROTOCOL = TCP)(HOST = 192.169.1.109)(PORT = 1521))  (CONNECT_DATA =  (SERVER = DEDICATED)  (SERVICE_NAME = orcl)  )  ) Note:host是远程数据库的ip地址，service_name为远程数据库的sid
配置环境变量 vi /etc/profile，添加
#配置ORACLE环境变量 vi /etc/profile export ORACLE_BASE=/usr/lib/oracle/21 export ORACLE_VERSION=21 export ORACLE_HOME=/usr/lib/oracle/21/client64 export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH export SQLPATH=$ORACLE_HOME/lib/network/admin export TNS_ADMIN=$ORACLE_HOME/lib/network/admin export NLS_LANG=AMERICAN_AMERICA.</description>
    </item>
    
    <item>
      <title>RabbitMQ安装和使用</title>
      <link>https://iblog.zone/archives/rabbitmq%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Tue, 15 Feb 2022 11:10:06 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/rabbitmq%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/</guid>
      <description>RabbitMQ安装步骤   *虚拟机：VMware workstation 12.0*
  Linux系统：CentOS 7.0
安装Erlang环境 由于RabbitMQ是采用Erlang编写的，首先需要安装该语言库，以便运行代理服务器，可以参考Erlang官方文档。
  erlang-solution配置信息安装
  wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpm sudo rpm -Uvh erlang-solutions-1.0-1.noarch.rpm rpm --import http://packages.erlang-solutions.com/rpm/erlang_solutions.asc  第三方yum源依赖  wget http://packages.sw.be/rpmforge-release/rpmforge-release-0.5.2-2.el6.rf.x86_64.rpm rpm –import http://apt.sw.be/RPM-GPG-KEY.dag.txt sudo rpm -i rpmforge-release-0.5.2-2.el6.rf.*.rpm  安装erlang  sudo yum install erlang  运行*erl*命令进行测试  安装RabbitMQ  首先下载最新版的RabbitMQ  wget http://www.rabbitmq.com/releases/rabbitmq-server/v3.6.1/rabbitmq-server-3.6.1-1.noarch.rpm  使用rpm和yum进行安装  rpm --import http://www.rabbitmq.com/rabbitmq-signing-key-public.asc yum install rabbitmq-server-3.6.1-1.noarch.rpm  启动RabbitMQ管理插件，用于web界面管理  rabbitmq-plugins enable rabbitmq_management service rabbitmq-server restart  测试安装完成的RabbitMQ  rabbitmqctl status 具体内容可以参考RabbitMQ安装官方文档。</description>
    </item>
    
    <item>
      <title>常用 Git 命令清单</title>
      <link>https://iblog.zone/archives/%E5%B8%B8%E7%94%A8-git-%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/</link>
      <pubDate>Fri, 11 Feb 2022 11:50:49 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E5%B8%B8%E7%94%A8-git-%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/</guid>
      <description>仓库 # 在当前目录新建一个Git代码库 $ git init  # 新建一个目录，将其初始化为Git代码库 $ git init [project-name]  # 下载一个项目和它的整个代码历史 $ git clone [url] 配置 # 显示当前的Git配置 $ git config --list  # 编辑Git配置文件 $ git config -e [--global]  # 设置提交代码时的用户信息 $ git config [--global] user.name &amp;#34;[name]&amp;#34; $ git config [--global] user.email &amp;#34;[email address]&amp;#34; 增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ...  # 添加指定目录到暂存区，包括子目录 $ git add [dir]  # 添加当前目录的所有文件到暂存区 $ git add .</description>
    </item>
    
    <item>
      <title>Nginx安装和高可用</title>
      <link>https://iblog.zone/archives/nginx%E5%AE%89%E8%A3%85%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
      <pubDate>Fri, 11 Feb 2022 10:50:49 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/nginx%E5%AE%89%E8%A3%85%E5%92%8C%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
      <description>一、Nginx安装 1、去官网http://nginx.org/下载对应的nginx包，推荐使用稳定版本 2、上传nginx到linux系统 3、安装依赖环境 (1)安装gcc环境
yum install gcc-c++ (2)安装PCRE库，用于解析正则表达式
yum install -y pcre pcre-devel (3)zlib压缩和解压缩依赖
yum install -y zlib zlib-devel (4)SSL 安全的加密的套接字协议层，用于HTTP安全传输，也就是https
yum install -y openssl openssl-devel 4、解压，需要注意，解压后得到的是源码，源码需要编译后才能安装 tar -zxvf nginx-1.16.1.tar.gz 5、编译之前，先创建nginx临时目录，如果不创建，在启动nginx的过程中会报错 mkdir /var/temp/nginx -p 6、在nginx目录，输入如下命令进行配置，目的是为了创建makefile文件 ./configure \  --prefix=/usr/local/nginx \  --pid-path=/var/run/nginx/nginx.pid \  --lock-path=/var/lock/nginx.lock \  --error-log-path=/var/log/nginx/error.log \  --http-log-path=/var/log/nginx/access.log \  --with-http_gzip_static_module \  --http-client-body-temp-path=/var/temp/nginx/client \  --http-proxy-temp-path=/var/temp/nginx/proxy \  --http-fastcgi-temp-path=/var/temp/nginx/fastcgi \  --http-uwsgi-temp-path=/var/temp/nginx/uwsgi \  --http-scgi-temp-path=/var/temp/nginx/scgi 注：代表在命令行中换行，用于提高可读性配置命令：</description>
    </item>
    
    <item>
      <title>Firewall防火墙常用操作</title>
      <link>https://iblog.zone/archives/firewall%E9%98%B2%E7%81%AB%E5%A2%99%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</link>
      <pubDate>Thu, 10 Feb 2022 16:24:38 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/firewall%E9%98%B2%E7%81%AB%E5%A2%99%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/</guid>
      <description>  查看防火墙某个端口是否开放
firewall-cmd &amp;ndash;query-port=3306/tcp
  开放防火墙端口3306
firewall-cmd &amp;ndash;zone=public &amp;ndash;add-port=3306/tcp &amp;ndash;permanent
注意：开放端口后要重启防火墙生效
  重启防火墙
systemctl restart firewalld
  关闭防火墙端口
firewall-cmd &amp;ndash;remove-port=3306/tcp &amp;ndash;permanent
  查看防火墙状态
systemctl status firewalld
  关闭防火墙
systemctl stop firewalld
  打开防火墙
systemctl start firewalld
  开放一段端口
firewall-cmd &amp;ndash;zone=public &amp;ndash;add-port=40000-45000/tcp &amp;ndash;permanent
  查看开放的端口列表
firewall-cmd &amp;ndash;zone=public &amp;ndash;list-ports
  </description>
    </item>
    
    <item>
      <title>Java性能分析工具Async-profiler(火焰图)使用</title>
      <link>https://iblog.zone/archives/java%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7async-profiler%E7%81%AB%E7%84%B0%E5%9B%BE%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Thu, 10 Feb 2022 10:36:59 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7async-profiler%E7%81%AB%E7%84%B0%E5%9B%BE%E4%BD%BF%E7%94%A8/</guid>
      <description>如果你经常遇到 Java 线上性能问题束手无策，看着线上服务 CPU 飙升一筹莫展，发现内存不断泄露满脸茫然。别慌，这里有一款低开销、自带火焰图、让你大呼好用的 Java 性能分析工具 - async-profiler。
最近 Arthas 性能分析工具上线了火焰图分析功能，Arthas 使用 async-profiler 生成 CPU/内存火焰图进行性能分析，弥补了之前内存分析的不足。在 Arthas 上使用还是比较方便的，使用方式可以看官方文档。这篇文章介绍 async-profiler 相关内容。
Arthas 火焰图官方文档：alibaba.github.io/arthas/prof…
如果你想了解更多 Arthas 信息，可以参考：Arthas - Java 线上问题定位处理的终极利器
async-profiler 介绍 async-profiler 是一款开源的 Java 性能分析工具，原理是基于 HotSpot 的 API，以微乎其微的性能开销收集程序运行中的堆栈信息、内存分配等信息进行分析。
使用 async-profiler 可以做下面几个方面的分析。
 CPU cycles Hardware and Software performance counters like cache misses, branch misses, page faults, context switches etc. Allocations in Java Heap Contented lock attempts, including both Java object monitors and ReentrantLocks  我们常用的是 CPU 性能分析和 Heap 内存分配分析。在进行 CPU 性能分析时，仅需要非常低的性能开销就可以进行分析，这也是这个工具的优点之一。</description>
    </item>
    
    <item>
      <title>redis-shake数据同步&amp;迁移工具</title>
      <link>https://iblog.zone/archives/redis-shake%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%81%E7%A7%BB%E5%B7%A5%E5%85%B7/</link>
      <pubDate>Tue, 08 Feb 2022 17:59:42 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/redis-shake%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E8%BF%81%E7%A7%BB%E5%B7%A5%E5%85%B7/</guid>
      <description>一、简介 redis-shake是阿里云Redis&amp;amp;MongoDB团队开源的用于redis数据同步的工具。
1.1基本功能 它支持解析、恢复、备份、同步四个功能。以下主要介绍同步sync。
 恢复restore：将RDB文件恢复到目的redis数据库。 备份dump：将源redis的全量数据通过RDB文件备份起来。 解析decode：对RDB文件进行读取，并以json格式解析存储。 同步sync：支持源redis和目的redis的数据同步，支持全量和增量数据的迁移。 同步rump：支持源redis和目的redis的数据同步，仅支持全量的迁移。采用scan和restore命令进行迁移。  1.2 基本原理 redis-shake的基本原理就是模拟一个从节点加入源redis集群，首先进行全量拉取并回放，然后进行增量的拉取（通过psync命令）。如下图所示：
如果源端是集群模式，只需要启动一个redis-shake进行拉取，同时不能开启源端的move slot操作。如果目的端是集群模式，可以写入到一个结点，然后再进行slot的迁移，当然也可以多对多写入。 目前，redis-shake到目的端采用单链路实现，对于正常情况下，这不会成为瓶颈，但对于极端情况，qps比较大的时候，此部分性能可能成为瓶颈，后续我们可能会计划对此进行优化。另外，redis-shake到目的端的数据同步采用异步的方式，读写分离在2个线程操作，降低因为网络时延带来的同步性能下降。
1.3 高效性 全量同步阶段并发执行，增量同步阶段异步执行，能够达到毫秒级别延迟（取决于网络延迟）。同时，我们还对大key同步进行分批拉取，优化同步性能。
1.4 监控 用户可以通过我们提供的restful拉取metric来对redis-shake进行实时监控：curl 127.0.0.1:9320/metric。
1.5 校验 可采用redis-full-check来校验同步的正确性。
二、安装redis-shake 2.1 下载 wget https://github.com/alibaba/RedisShake/releases/download/release-v2.0.3-20200724/redis-shake-v2.0.3.tar.gz; tar zxvf redis-shake-v2.0.3.tar.gz; cd redis-shake-v2.0.3; 2.2 修改配置文件 vim redis-shake.conf - source.type: 源redis的类型，支持一下4种类型： standalone: 单db节点/主从版模式。 sentinel: sentinel模式。 cluster: 集群模式。 proxy: proxy模式。如果是阿里云redis的集群版，从proxy拉取/写入请选择proxy - source.address: 源redis的地址，不同的类型对应不同的地址： standalone模式下，需填写单个db节点的地址，主从版需输入master或者slave的地址。 sentinel模式下，例如：master:master@127.0.0.1:26379;127.0.0.1:26380 cluster模式下，需填写集群地址，以分号（;）分割。例如：10.1.1.1:20331;10.1.1.2:20441 proxy模式下，需要填写单个proxy的地址，此模式目前仅用于rump。 - source.password_raw：源redis的密码。 - target.type: 目的redis的类型 - target.address：目的redis的地址。 sentinel模式，例如：mymaster@127.0.0.1:26379;127.0.0.1:26380 cluster模式，参见source.address。 proxy模式下，填写proxy的地址，如果是多个proxy，则round-robin循环负载均衡连接，保证一个源端db连接只会对应一个proxy。 - target.</description>
    </item>
    
    <item>
      <title>Java面向对象</title>
      <link>https://iblog.zone/archives/java%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</link>
      <pubDate>Tue, 08 Feb 2022 16:07:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1/</guid>
      <description>1. 类和对象 面向对象和面向过程的思想对比 :
​	**面向过程 ：**是一种以过程为中心的编程思想，实现功能的每一步，都是自己实现的
​	**面向对象 ：**是一种以对象为中心的编程思想，通过指挥对象实现具体的功能
1.1 类和对象的关系 客观存在的事物皆为对象 ，所以我们也常常说万物皆对象。
 类  类的理解  类是对现实生活中一类具有共同属性和行为的事物的抽象 类是对象的数据类型，类是具有相同属性和行为的一组对象的集合 简单理解：类就是对现实事物的一种描述   类的组成  属性：指事物的特征，例如：手机事物（品牌，价格，尺寸） 行为：指事物能执行的操作，例如：手机事物（打电话，发短信）     类和对象的关系  类：类是对现实生活中一类具有共同属性和行为的事物的抽象 对象：是能够看得到摸的着的真实存在的实体 简单理解：类是对事物的一种描述，对象则为具体存在的事物    1.2 类的定义【应用】 类的组成是由属性和行为两部分组成
 **属性：**在类中通过成员变量来体现（类中方法外的变量） **行为：**在类中通过成员方法来体现（和前面的方法相比去掉static关键字即可）  类的定义步骤：
​	① 定义类
​	② 编写类的成员变量
​	③ 编写类的成员方法
public class Student {  // 属性 : 姓名, 年龄  // 成员变量: 跟之前定义变量的格式一样, 只不过位置发生了改变, 类中方法外  String name;  int age;   // 行为 : 学习  // 成员方法: 跟之前定义方法的格式一样, 只不过去掉了static关键字.</description>
    </item>
    
    <item>
      <title>Java Debug&amp;进制&amp;二维数组</title>
      <link>https://iblog.zone/archives/java-debug%E8%BF%9B%E5%88%B6%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84/</link>
      <pubDate>Mon, 07 Feb 2022 14:44:39 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java-debug%E8%BF%9B%E5%88%B6%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84/</guid>
      <description>1.Debug模式 1.1 什么是Debug模式 是供程序员使用的程序调试工具，它可以用于查看程序的执行流程，也可以用于追踪程序执行过程来调试程序。
1.2 Debug介绍与操作流程   如何加断点
 选择要设置断点的代码行，在行号的区域后面单击鼠标左键即可    如何运行加了断点的程序
 在代码区域右键Debug执行    看哪里
  看Debugger窗口
  看Console窗口
    点哪里
 点Step Into (F7)这个箭头，也可以直接按F7    如何删除断点
  选择要删除的断点，单击鼠标左键即可
  如果是多个断点，可以每一个再点击一次。也可以一次性全部删除
    2. 进制的介绍与书写格式 2.1 进制的介绍与书写格式 代码 :
public class Demo1 {  /* 十进制：Java中，数值默认都是10进制，不需要加任何修饰。 二进制：数值前面以0b开头，b大小写都可以。 八进制：数值前面以0开头。 十六进制：数值前面以0x开头，x大小写都可以。 注意: 书写的时候, 虽然加入了进制的标识, 但打印在控制台展示的都是十进制数据. */  public static void main(String[] args) {  System.</description>
    </item>
    
    <item>
      <title>Java方法</title>
      <link>https://iblog.zone/archives/java%E6%96%B9%E6%B3%95/</link>
      <pubDate>Mon, 07 Feb 2022 14:35:54 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E6%96%B9%E6%B3%95/</guid>
      <description>1. 方法概述 1.1 方法的概念 ​	方法（method）是将具有独立功能的代码块组织成为一个整体，使其具有特殊功能的代码集
 注意：  方法必须先创建才可以使用，该过程成为方法定义 方法创建后并不是直接可以运行的，需要手动使用后，才执行，该过程成为方法调用    2. 方法的定义和调用 2.1 无参数方法定义和调用   定义格式：
public static void 方法名 ( ) { 	// 方法体; }   范例：
public static void method ( ) { 	// 方法体; }   调用格式：
方法名();   范例：
method();   注意：
​	方法必须先定义，后调用，否则程序将报错
  2.2 方法的调用过程  总结：每个方法在被调用执行的时候，都会进入栈内存，并且拥有自己独立的内存空间，方法内部代码调用完毕之后，会从栈内存中弹栈消失。  2.3 方法练习-奇偶数判断  需求：判断一个数是奇数还是偶数 代码：  public class Demo1Method {  /* 带参数方法的定义格式: public static void 方法名 ( 参数 ) { … … } public static void 方法名 ( 数据类型 变量名 ) { … … } 带参数方法的调用格式: 方法名 ( 参数 ) ; 方法名 ( 变量名/常量值 ) ; tips: 参数可以是一个, 也可以是多个.</description>
    </item>
    
    <item>
      <title>Java数组</title>
      <link>https://iblog.zone/archives/java%E6%95%B0%E7%BB%84/</link>
      <pubDate>Mon, 07 Feb 2022 14:25:44 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E6%95%B0%E7%BB%84/</guid>
      <description>1.数组 1.1 数组介绍 ​	数组就是存储数据长度固定的容器，存储多个数据的数据类型要一致。
1.2 数组的定义格式 1.2.1 第一种格式 ​	数据类型[] 数组名
​	示例：
int[] arr; double[] arr; char[] arr; 1.2.2 第二种格式 ​	数据类型 数组名[]
​	示例：
int arr[]; double arr[]; char arr[]; 1.3 数组的动态初始化 1.3.1 什么是动态初始化 ​	数组动态初始化就是只给定数组的长度，由系统给出默认初始化值
1.3.2 动态初始化格式 数据类型[] 数组名 = new 数据类型[数组长度]; int[] arr = new int[3]; 1.3.3 动态初始化格式详解  等号左边：  int:数组的数据类型 []:代表这是一个数组 arr:代表数组的名称   等号右边：  new:为数组开辟内存空间 int:数组的数据类型 []:代表这是一个数组 5:代表数组的长度    代码 :</description>
    </item>
    
    <item>
      <title>Centos6 yum源配置</title>
      <link>https://iblog.zone/archives/centos6-yum%E6%BA%90%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Fri, 28 Jan 2022 16:57:19 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos6-yum%E6%BA%90%E9%85%8D%E7%BD%AE/</guid>
      <description>截止2022-01-28日有效
CentOS-Base.repo
[extras] gpgcheck=0 gpgkey=http://mirrors.tencentyun.com/centos/RPM-GPG-KEY-Centos-6 enabled=1 baseurl=https://mirrors.cloud.tencent.com/centos-vault/6.9/extras/$basearch/ name=Qcloud centos extras - $basearch  [os] gpgcheck=0 gpgkey=http://mirrors.tencentyun.com/centos/RPM-GPG-KEY-Centos-6 enabled=1 baseurl=https://mirrors.cloud.tencent.com/centos-vault/6.9/os/$basearch/ name=Qcloud centos os - $basearch  [updates] gpgcheck=0 gpgkey=http://mirrors.tencentyun.com/centos/RPM-GPG-KEY-Centos-6 enabled=1 baseurl=https://mirrors.cloud.tencent.com/centos-vault/6.9/updates/$basearch/ name=Qcloud centos updates - $basearch epel.repo
[epel] name=epel for redhat/centos $releasever - $basearch failovermethod=priority enable=1 baseurl=https://mirrors.cloud.tencent.com/epel-archive/6/$basearch/ </description>
    </item>
    
    <item>
      <title>rsync工具使用</title>
      <link>https://iblog.zone/archives/rsync%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Fri, 28 Jan 2022 15:28:34 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/rsync%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/</guid>
      <description>一、简介 rsync 是一个常用的 Linux 应用程序，用于文件同步。
它可以在本地计算机与远程计算机之间，或者两个本地目录之间同步文件（但不支持两台远程计算机之间的同步）。它也可以当作文件复制工具，替代cp和mv命令。
它名称里面的r指的是 remote，rsync 其实就是&amp;quot;远程同步&amp;quot;（remote sync）的意思。与其他文件传输工具（如 FTP 或 scp）不同，rsync 的最大特点是会检查发送方和接收方已有的文件，仅传输有变动的部分（默认规则是文件大小或修改时间有变动）。
二、安装 如果本机或者远程计算机没有安装 rsync，可以用下面的命令安装。
 # Debian $ sudo apt-get install rsync  # Red Hat $ sudo yum install rsync  # Arch Linux $ sudo pacman -S rsync  注意，传输的双方都必须安装 rsync。
三、基本用法 3.1 -r 参数 本机使用 rsync 命令时，可以作为cp和mv命令的替代方法，将源目录同步到目标目录。
 $ rsync -r source destination  上面命令中，-r表示递归，即包含子目录。注意，-r是必须的，否则 rsync 运行不会成功。source目录表示源目录，destination表示目标目录。
如果有多个文件或目录需要同步，可以写成下面这样。
 $ rsync -r source1 source2 destination  上面命令中，source1、source2都会被同步到destination目录。</description>
    </item>
    
    <item>
      <title>Java循环</title>
      <link>https://iblog.zone/archives/java%E5%BE%AA%E7%8E%AF/</link>
      <pubDate>Fri, 28 Jan 2022 14:21:06 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E5%BE%AA%E7%8E%AF/</guid>
      <description>1. switch语句 1.1 分支语句switch语句   格式
switch (表达式) { 	case 1: 	语句体1; 	break; 	case 2: 	语句体2; 	break; 	... 	default: 	语句体n+1; 	break; }   执行流程：
 首先计算出表达式的值 其次，和case依次比较，一旦有对应的值，就会执行相应的语句，在执行的过程中，遇到break就会结 束。 最后，如果所有的case都和表达式的值不匹配，就会执行default语句体部分，然后程序结束掉。    1.2 switch案例-减肥计划  需求：键盘录入星期数，显示今天的减肥活动  周一：跑步 周二：游泳 周三：慢走 周四：动感单车 周五：拳击 周六：爬山 周日：好好吃一顿  示例代码：  public static void main(String[] args){ 	// 1. 键盘录入星期数据，使用变量接收 	Scanner sc = new Scanner(System.</description>
    </item>
    
    <item>
      <title>Java运算符</title>
      <link>https://iblog.zone/archives/java%E8%BF%90%E7%AE%97%E7%AC%A6/</link>
      <pubDate>Thu, 27 Jan 2022 16:46:06 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E8%BF%90%E7%AE%97%E7%AC%A6/</guid>
      <description>1 类型转换 在Java中，一些数据类型之间是可以相互转换的。分为两种情况：自动类型转换和强制类型转换。
1.1 隐式转换(理解) ​	把一个表示数据范围小的数值或者变量赋值给另一个表示数据范围大的变量。这种转换方式是自动的，直接书写即可。例如：
double num = 10; // 将int类型的10直接赋值给double类型 System.out.println(num); // 输出10.0 ​	类型从小到大关系图：
说明：
 整数默认是int类型，byte、short和char类型数据参与运算均会自动转换为int类型。  byte b1 = 10; byte b2 = 20; byte b3 = b1 + b2; // 第三行代码会报错，b1和b2会自动转换为int类型，计算结果为int，int赋值给byte需要强制类型转换。 // 修改为: int num = b1 + b2; // 或者： byte b3 = (byte) (b1 + b2); boolean类型不能与其他基本数据类型相互转换。  1.2 强制转换(理解) ​	把一个表示数据范围大的数值或者变量赋值给另一个表示数据范围小的变量。
​	强制类型转换格式：目标数据类型 变量名 = (目标数据类型)值或者变量;
​	例如：
double num1 = 5.</description>
    </item>
    
    <item>
      <title>Java环境搭建及入门</title>
      <link>https://iblog.zone/archives/java%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%85%A5%E9%97%A8/</link>
      <pubDate>Wed, 26 Jan 2022 18:19:37 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%85%A5%E9%97%A8/</guid>
      <description>1. Java概述 1.1 Java语言背景介绍（了解） 语言：人与人交流沟通的表达方式
计算机语言：人与计算机之间进行信息交流沟通的一种特殊语言
Java语言是美国Sun公司（Stanford University Network）在1995年推出的计算机语言
Java之父：詹姆斯·高斯林（James Gosling）
2009年，Sun公司被甲骨文公司收购，所以我们现在访问oracle官网即可：https://www.oracle.com
java语言的三个版本：
​	JavaSE: Java 语言的（标准版），用于桌面应用的开发，是其他两个版本的基础
​	JavaME: Java 语言的（小型版），用于嵌入式消费类电子设备
​	JavaEE: Java 语言的（企业版），用于 Web 方向的网站开发
1.2 Java语言跨平台原理（理解） Java程序并非是直接运行的，Java编译器将Java源程序编译成与平台无关的字节码文件(class文件)，然后由Java虚拟机（JVM）对字节码文件解释执行。所以在不同的操作系统下，只需安装不同的Java虚拟机即可实现java程序的跨平台。
1.3 JRE和JDK（记忆） JVM（Java Virtual Machine），Java虚拟机
JRE（Java Runtime Environment），Java运行环境，包含了JVM和Java的核心类库（Java API）
JDK（Java Development Kit）称为Java开发工具，包含了JRE和开发工具
总结：我们只需安装JDK即可，它包含了java的运行环境和虚拟机。
1.4 JDK的下载和安装（应用） 1.4.1 下载 通过官方网站获取JDK
http://www.oracle.com
注意：针对不同的操作系统，需要下载对应版本的JDK。
1.4.2 安装 傻瓜式安装，下一步即可。但默认的安装路径是在C:\Program Files下，为方便统一管理建议修改安装路径，将与开发相关的软件都安装到一个目录下，例如：E:\develop。
注意：安装路径不要包含中文或者空格等特殊字符（使用纯英文目录）。
1.4.3 JDK的安装目录介绍    目录名称 说明     bin 该路径下存放了JDK的各种工具命令。javac和java就放在这个目录。   conf 该路径下存放了JDK的相关配置文件。   include 该路径下存放了一些平台特定的头文件。   jmods 该路径下存放了JDK的各种模块。   legal 该路径下存放了JDK各模块的授权文档。   lib 该路径下存放了JDK工具的一些补充JAR包。    2.</description>
    </item>
    
    <item>
      <title>The server selected protocol version TLS10 is not accepted by client preferences [TLS12] 连接数据库报错</title>
      <link>https://iblog.zone/archives/the-server-selected-protocol-version-tls10-is-not-accepted-by-client-preferences-tls12-%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%A5%E9%94%99/</link>
      <pubDate>Thu, 20 Jan 2022 16:30:33 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/the-server-selected-protocol-version-tls10-is-not-accepted-by-client-preferences-tls12-%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%8A%A5%E9%94%99/</guid>
      <description>由于oracle jdk1.8_301扫描出漏洞，故升级jdk到openjdk 1.8.0_312，升级后出现兼容性问题，访问数据库出现以下错误
The server selected protocol version TLS10 is not accepted by client preferences [TLS12] 查询后为新版的 JDK 不推荐使用旧的 TLSV1.0 的协议，所以默认删除 TLS10 的支持导致，可按照下面方法修复
cd /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64/jre  cd lib/security/  vim java.security  # 698行，将 TLSv1, TLSv1.1, 3DES_EDE_CBC 删除，删除后为以下内容 jdk.tls.disabledAlgorithms=SSLv3, RC4, DES, MD5withRSA, \  DH keySize &amp;lt; 1024, EC keySize &amp;lt; 224, anon, NULL, \  include jdk.disabled.namedCurves 再次访问，问题解决</description>
    </item>
    
    <item>
      <title>使用xrdp连接kali远程桌面</title>
      <link>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8xrdp%E8%BF%9E%E6%8E%A5kali%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/</link>
      <pubDate>Thu, 20 Jan 2022 16:23:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8xrdp%E8%BF%9E%E6%8E%A5kali%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2/</guid>
      <description>1、安装xrdp
apt-get install xrdp 2、接下来安装xfce4
apt-get instlal xfce4 3、最重要的一步
用vim打开 /etc/xrdp/startwm.sh
vim /etc/xrdp/startwm.sh 4、在里面添加
 echo “xfce4-session” &amp;gt;~/.xsession 5、启动xrdp
service xrdp start 6、创建vnc用户
useradd -m vnc passwd vnc 7、连接</description>
    </item>
    
    <item>
      <title>kali-linux-2021.2安装openvas</title>
      <link>https://iblog.zone/archives/kali-linux-2021.2%E5%AE%89%E8%A3%85openvas/</link>
      <pubDate>Thu, 20 Jan 2022 16:05:36 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/kali-linux-2021.2%E5%AE%89%E8%A3%85openvas/</guid>
      <description>kali-linux-2021.2安装openvas 1.安装 sudo apt-get update // 软件库更新  sudo apt-get upgrade // 软件升级  sudo apt-get dist-upgrade // 升级系统  # 由于在2021.1版本中，openvas已经改名为gvm，所以使用以下命令安装openvas sudo apt-get install gvm 使用gvm-setup安装openvas
安装完成，注意这里的密码，你可以通过gvmd &amp;ndash;user=admin &amp;ndash;new-password=admin修改密码为admin（如果修改无效，请参考最下面的操作命令）
启动服务gvm-start，并通过netstat -antp查看状态
访问https://127.0.0.1:9392即可,注意这里是https
如果需要在其他地址访问，则需要修改服务监听地址
vim /lib/systemd/system/greenbone-security-assistant.service 2.操作命令 这里附上完整流程所需的命令
//安装过程命令 sudo apt-get update // 软件库更新 sudo apt-get upgrade // 软件升级 sudo apt-get dist-upgrade // 升级系统 apt-get install gvm //下载安装包 gvm-setup //安装 安装完成 //这里得注意记住初始密码 gvm-check-setup //检查安装是否成功 gvm-start //启动服务 netstat -antp //查看状态，特别注意这里有个空格 浏览器访问https://127.0.0.1:9392 //这里注意是https vim /lib/systemd/system/greenbone-security-assistant.</description>
    </item>
    
    <item>
      <title>基于Istio实现微服务治理</title>
      <link>https://iblog.zone/archives/%E5%9F%BA%E4%BA%8Eistio%E5%AE%9E%E7%8E%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/</link>
      <pubDate>Wed, 12 Jan 2022 17:38:42 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E5%9F%BA%E4%BA%8Eistio%E5%AE%9E%E7%8E%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%B2%BB%E7%90%86/</guid>
      <description>基于Istio实现微服务治理 微服务架构可谓是当前软件开发领域的技术热点，它在各种博客、社交媒体和会议演讲上的出镜率非常之高，无论是做基础架构还是做业务系统的工程师，对微服务都相当关注，而这个现象与热度到目前为止，已经持续了近 5 年之久。
尤其是近些年来，微服务架构逐渐发展成熟，从最初的星星之火到现在的大规模的落地与实践，几乎已经成为分布式环境下的首选架构。微服务成为时下技术热点，大量互联网公司都在做微服务架构的落地和推广。同时，也有很多传统企业基于微服务和容器，在做互联网技术转型。
而在这个技术转型中，国内有一个趋势，以 Spring Cloud 与 Dubbo 为代表的微服务开发框架非常普及和受欢迎。然而软件开发没有银弹，基于这些传统微服务框架构建的应用系统在享受其优势的同时，痛点也越加明显。这些痛点包括但不限于以下几点：
 侵入性强。想要集成 SDK 的能力，除了需要添加相关依赖，往往还需要在业务代码中增加一部分的代码、或注解、或配置；业务代码与治理层代码界限不清晰。 升级成本高。每次升级都需要业务应用修改 SDK 版本，重新进行功能回归测试，并且对每一台机器进行部署上线，而这对于业务方来说，与业务的快速迭代开发是有冲突的，大多不愿意停下来做这些与业务目标不太相关的事情。 版本碎片化严重。由于升级成本高，而中间件却不会停止向前发展的步伐，久而久之，就会导致线上不同服务引用的 SDK 版本不统一、能力参差不齐，造成很难统一治理。 中间件演变困难。由于版本碎片化严重，导致中间件向前演进的过程中就需要在代码中兼容各种各样的老版本逻辑，带着 “枷锁” 前行，无法实现快速迭代。 内容多、门槛高。Spring Cloud 被称为微服务治理的全家桶，包含大大小小几十个组件，内容相当之多，往往需要几年时间去熟悉其中的关键组件。而要想使用 Spring Cloud 作为完整的治理框架，则需要深入了解其中原理与实现，否则遇到问题还是很难定位。 治理功能不全。不同于 RPC 框架，Spring Cloud 作为治理全家桶的典型，也不是万能的，诸如协议转换支持、多重授权机制、动态请求路由、故障注入、灰度发布等高级功能并没有覆盖到。而这些功能往往是企业大规模落地不可获缺的功能，因此公司往往还需要投入其它人力进行相关功能的自研或者调研其它组件作为补充。  Service Mesh 服务网格 架构和概念 目的是解决系统架构微服务化后的服务间通信和治理问题。设计初衷是提供一种通用的服务治理方案。
Sidecar 在软件系统架构中特指边车模式。这个模式的灵感来源于我们生活中的边三轮：即在两轮摩托车的旁边添加一个边车的方式扩展现有的服务和功能。
这个模式的精髓在于实现了数据面（业务逻辑）和控制面的解耦：原来两轮摩托车的驾驶者集中注意力跑赛道，边车上的领航员专注周围信息和地图，专注导航。
Service Mesh 这个服务网络专注于处理服务和服务间的通讯。其主要负责构造一个稳定可靠的服务通讯的基础设施，并让整个架构更为的先进和 Cloud Native。在工程中，Service Mesh 基本来说是一组轻量级的与应用逻辑服务部署在一起的服务代理，并且对于应用服务是透明的。
开源实现 第一代服务网格 Linkerd和Envoy Linkerd 使用Scala编写，是业界第一个开源的service mesh方案。作者 William Morgan 是 service mesh 的布道师和践行者。Envoy 基于C++ 11编写，无论是理论上还是实际上，后者性能都比 Linkderd 更好。这两个开源实现都是以 sidecar 为核心，绝大部分关注点都是如何做好proxy，并完成一些通用控制面的功能。 但是，当你在容器中大量部署 sidecar 以后，如何管理和控制这些 sidecar 本身就是一个不小的挑战。于是，第二代 Service Mesh 应运而生。</description>
    </item>
    
    <item>
      <title>SpringBoot与SpringCloud微服务项目交付</title>
      <link>https://iblog.zone/archives/springboot%E4%B8%8Espringcloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E4%BA%A4%E4%BB%98/</link>
      <pubDate>Tue, 11 Jan 2022 15:30:27 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/springboot%E4%B8%8Espringcloud%E5%BE%AE%E6%9C%8D%E5%8A%A1%E9%A1%B9%E7%9B%AE%E4%BA%A4%E4%BB%98/</guid>
      <description>Spring Cloud微服务项目交付 微服务扫盲篇 微服务并没有一个官方的定义，想要直接描述微服务比较困难，我们可以通过对比传统WEB应用，来理解什么是微服务。
单体应用架构 如下是传统打车软件架构图：
这种单体应用比较适合于小项目，优点是：
 开发简单直接，集中式管理 基本不会重复开发 功能都在本地，没有分布式的管理开销和调用开销  当然它的缺点也十分明显，特别对于互联网公司来说：
 开发效率低：所有的开发在一个项目改代码，递交代码相互等待，代码冲突不断 代码维护难：代码功能耦合在一起，新人不知道何从下手 部署不灵活：构建时间长，任何小修改必须重新构建整个项目，这个过程往往很长 稳定性不高：一个微不足道的小问题，可以导致整个应用挂掉 扩展性不够：无法满足高并发情况下的业务需求  微服务应用架构 微服务架构的设计思路不是开发一个巨大的单体式应用，而是将应用分解为小的、互相连接的微服务。一个微服务完成某个特定功能，比如乘客管理和下单管理等。每个微服务都有自己的业务逻辑和适配器。一些微服务还会提供API接口给其他微服务和应用客户端使用。
比如，前面描述的系统可被分解为：
每个业务逻辑都被分解为一个微服务，微服务之间通过REST API通信。一些微服务也会向终端用户或客户端开发API接口。但通常情况下，这些客户端并不能直接访问后台微服务，而是通过API Gateway来传递请求。API Gateway一般负责服务路由、负载均衡、缓存、访问控制和鉴权等任务。
微服务架构优点：
 解决了复杂性问题。它将单体应用分解为一组服务。虽然功能总量不变，但应用程序已被分解为可管理的模块或服务 体系结构使得每个服务都可以由专注于此服务的团队独立开发。只要符合服务API契约，开发人员可以自由选择开发技术。这就意味着开发人员可以采用新技术编写或重构服务，由于服务相对较小，所以这并不会对整体应用造成太大影响 微服务架构可以使每个微服务独立部署。这些更改可以在测试通过后立即部署。所以微服务架构也使得CI／CD成为可能  微服务架构问题及挑战 微服务的一个主要缺点是微服务的分布式特点带来的复杂性。开发人员需要基于RPC或者消息实现微服务之间的调用和通信，而这就使得服务之间的发现、服务调用链的跟踪和质量问题变得的相当棘手。
 微服务的一大挑战是跨多个服务的更改  比如在传统单体应用中，若有A、B、C三个服务需要更改，A依赖B，B依赖C。我们只需更改相应的模块，然后一次性部署即可。 在微服务架构中，我们需要仔细规划和协调每个服务的变更部署。我们需要先更新C，然后更新B，最后更新A。   部署基于微服务的应用也要复杂得多  单体应用可以简单的部署在一组相同的服务器上，然后前端使用负载均衡即可。 微服务由不同的大量服务构成。每种服务可能拥有自己的配置、应用实例数量以及基础服务地址。这里就需要不同的配置、部署、扩展和监控组件。此外，我们还需要服务发现机制，以便服务可以发现与其通信的其他服务的地址    以上问题和挑战可大体概括为：
 API Gateway 服务间调用 服务发现 服务容错 服务部署 数据调用  https://www.kancloud.cn/owenwangwen/open-capacity-platform/1480155，自助餐吃吃喝喝，竟然秒懂微服务
微服务框架 如何应对上述挑战，出现了如下微服务领域的框架：
  Spring Cloud（各个微服务基于Spring Boot实现）
  Dubbo</description>
    </item>
    
    <item>
      <title>基于sharedLibrary进行CICD流程的优化</title>
      <link>https://iblog.zone/archives/%E5%9F%BA%E4%BA%8Esharedlibrary%E8%BF%9B%E8%A1%8Ccicd%E6%B5%81%E7%A8%8B%E7%9A%84%E4%BC%98%E5%8C%96/</link>
      <pubDate>Mon, 10 Jan 2022 18:27:44 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E5%9F%BA%E4%BA%8Esharedlibrary%E8%BF%9B%E8%A1%8Ccicd%E6%B5%81%E7%A8%8B%E7%9A%84%E4%BC%98%E5%8C%96/</guid>
      <description>基于sharedLibrary进行CI/CD流程的优化 由于公司内部项目众多，大量的项目使用同一套流程做CICD
 那么势必会存在大量的重复代码 一旦某个公共的地方需要做调整，每个项目都需要修改  因此本章主要通过使用groovy实现Jenkins的sharedLibrary的开发，以提取项目在CICD实践过程中的公共逻辑，提供一系列的流程的接口供公司内各项目调用。
开发完成后，对项目进行Jenkinsfile的改造，最后仅需通过简单的Jenkinsfile的配置，即可优雅的完成CICD流程的整个过程，此方式已在大型企业内部落地应用。
Library工作模式 由于流水线被组织中越来越多的项目所采用，常见的模式很可能会出现。 在多个项目之间共享流水线有助于减少冗余并保持代码 &amp;ldquo;DRY&amp;rdquo;。
流水线支持引用 &amp;ldquo;共享库&amp;rdquo; ，可以在外部源代码控制仓库中定义并加载到现有的流水线中。
@Library(&amp;#39;my-shared-library&amp;#39;) _ 在实际运行过程中，会把library中定义的groovy功能添加到构建目录中：
/var/jenkins_home/jobs/test-maven-build/branches/feature-CDN-2904.cm507o/builds/2/libs/my-shared-library/vars/devops.groovy 使用library后，Jenkinsfile大致的样子如下：
@Library(&amp;#39;my-shared-library&amp;#39;) _  ...  stages {  stage(&amp;#39;build image&amp;#39;) {  steps {  container(&amp;#39;tools&amp;#39;) {  devops.buildImage(&amp;#34;Dockerfile&amp;#34;,&amp;#34;172.21.51.67:5000/demo:latest&amp;#34;)  }  }  }  }   post {  success {  script {  container(&amp;#39;tools&amp;#39;) {  devops.notificationSuccess(&amp;#34;dingTalk&amp;#34;)  }  }  }  } .</description>
    </item>
    
    <item>
      <title>从零开始构建基于Kubernetes的Devops平台</title>
      <link>https://iblog.zone/archives/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8Ekubernetes%E7%9A%84devops%E5%B9%B3%E5%8F%B0/</link>
      <pubDate>Fri, 07 Jan 2022 14:26:43 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8Ekubernetes%E7%9A%84devops%E5%B9%B3%E5%8F%B0/</guid>
      <description>基于Kubernetes的DevOps平台实践 持续集成工具：
 Jenkins gitlabci Tekton  本章基于k8s集群部署gitlab、sonarQube、Jenkins等工具，并把上述工具集成到Jenkins中，以Django项目和SpringBoot项目为例，通过多分支流水线及Jenkinsfile实现项目代码提交到不同的仓库分支，实现自动代码扫描、单元测试、docker容器构建、k8s服务的自动部署。
 DevOps、CI、CD介绍 Jenkins、sonarQube、gitlab的快速部署 Jenkins初体验 流水线入门及Jenkinsfile使用 Jenkins与Kubernetes的集成 sonarQube代码扫描与Jenkins的集成 实践Django项目的基于Jenkinsfile实现开发、测试环境的CI/CD  DevOps、CI、CD介绍 Continuous Integration (CI) / Continuous Delivery (CD)
软件交付流程
一个软件从零开始到最终交付，大概包括以下几个阶段：规划、编码、构建、测试、发布、部署和维护，基于这些阶段，我们的软件交付模型大致经历了几个阶段：
瀑布式流程 前期需求确立之后，软件开发人员花费数周和数月编写代码，把所有需求一次性开发完，然后将代码交给QA（质量保障）团队进行测试，然后将最终的发布版交给运维团队去部署。瀑布模型，简单来说，就是等一个阶段所有工作完成之后，再进入下一个阶段。这种模式的问题也很明显，产品迭代周期长，灵活性差。一个周期动辄几周几个月，适应不了当下产品需要快速迭代的场景。
敏捷开发 任务由大拆小，开发、测试协同工作，注重开发敏捷，不重视交付敏捷
DevOps 开发、测试、运维协同工作, 持续开发+持续交付。
我们是否可以认为DevOps = 提倡开发、测试、运维协同工作来实现持续开发、持续交付的一种软件交付模式？
大家想一下为什么最初的开发模式没有直接进入DevOps的时代？
原因是：沟通成本。
各角色人员去沟通协作的时候都是手动去做，交流靠嘴，靠人去指挥，很显然会出大问题。所以说不能认为DevOps就是一种交付模式，因为解决不了沟通协作成本，这种模式就不具备可落地性。
那DevOps时代如何解决角色之间的成本问题？DevOps的核心就是自动化。自动化的能力靠什么来支撑，工具和技术。
DevOps工具链
靠这些工具和技术，才实现了自动化流程，进而解决了协作成本，使得devops具备了可落地性。因此我们可以大致给devops一个定义：
devops = 提倡开发、测试、运维协同工作来实现持续开发、持续交付的一种软件交付模式 + 基于工具和技术支撑的自动化流程的落地实践。
因此devops不是某一个具体的技术，而是一种思想+自动化能力，来使得构建、测试、发布软件能够更加地便捷、频繁和可靠的落地实践。本次课程核心内容就是要教会大家如何利用工具和技术来实现完整的DevOps平台的建设。我们主要使用的工具有：
 gitlab，代码仓库，企业内部使用最多的代码版本管理工具。 Jenkins， 一个可扩展的持续集成引擎，用于自动化各种任务，包括构建、测试和部署软件。 robotFramework， 基于Python的自动化测试框架 sonarqube，代码质量管理平台 maven，java包构建管理工具 Kubernetes Docker  Jenkins初体验 Kubernetes环境中部署jenkins 其他部署方式
注意点：
 第一次启动很慢 因为后面Jenkins会与kubernetes集群进行集成，会需要调用kubernetes集群的api，因此安装的时候创建了ServiceAccount并赋予了cluster-admin的权限 默认部署到jenkins=true的节点 初始化容器来设置权限 ingress来外部访问 数据存储通过hostpath挂载到宿主机中  jenkins/jenkins-all.</description>
    </item>
    
    <item>
      <title>Linux iowait高问题排查及处理</title>
      <link>https://iblog.zone/archives/linux-iowait%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E5%8F%8A%E5%A4%84%E7%90%86/</link>
      <pubDate>Fri, 07 Jan 2022 14:11:47 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/linux-iowait%E9%AB%98%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5%E5%8F%8A%E5%A4%84%E7%90%86/</guid>
      <description>一、问题排查 由于资源问题，我们很多服务都共用一台机器，某天突发发现vpn登录不正常，连接后闪断频繁，登录机器查看，iowait特别高
通过iotop命令查看发现是mysql进程占用高，造成系统卡顿
二、问题处理 进入mysql，使用show full processlist 可以看到所有链接的情况，但是大多链接的 state 其实是 Sleep 的，这种的其实是空闲状态，没有太多查看价值
我们要观察的是有问题的，所以可以进行过滤：
-- 查询非 Sleep 状态的链接，按消耗时间倒序展示，自己加条件过滤 select id, db, user, host, command, time, state, info from information_schema.processlist where command != &amp;#39;Sleep&amp;#39; order by time desc; 这样就过滤出来哪些是正在干活的，然后按照消耗时间倒叙展示，排在最前面的，极大可能就是有问题的链接了，然后查看 info 一列，就能看到具体执行的什么 SQL 语句了，针对分析
展示列解释：
 id - 线程ID，可以用：kill id; 杀死一个线程，很有用 db - 数据库 user - 用户 host - 连库的主机IP command - 当前执行的命令，比如最常见的：Sleep，Query，Connect 等 time - 消耗时间，单位秒，很有用 state - 执行状态，比如：Sending data，Sorting for group，Creating tmp table，Locked等等，很有用，其他状态可以看看本文最后的参考文章 info - 执行的SQL语句，很有用  kill 使用 上面提到的 线程ID 是可以通过 kill 杀死的；所以上面基本上可以把有问题的执行语句找出来，然后就可以 kill 掉了，那么一个一个来 kill 么？</description>
    </item>
    
    <item>
      <title>Kubernetes集群的日志及监控</title>
      <link>https://iblog.zone/archives/kubernetes%E9%9B%86%E7%BE%A4%E7%9A%84%E6%97%A5%E5%BF%97%E5%8F%8A%E7%9B%91%E6%8E%A7/</link>
      <pubDate>Thu, 06 Jan 2022 17:22:02 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/kubernetes%E9%9B%86%E7%BE%A4%E7%9A%84%E6%97%A5%E5%BF%97%E5%8F%8A%E7%9B%91%E6%8E%A7/</guid>
      <description>第四天 Kubernetes集群的日志及监控 k8s日志收集架构 https://kubernetes.io/docs/concepts/cluster-administration/logging/
总体分为三种方式：
 使用在每个节点上运行的节点级日志记录代理。 在应用程序的 pod 中，包含专门记录日志的 sidecar 容器。 将日志直接从应用程序中推送到日志记录后端。  使用节点级日志代理 容器日志驱动：
https://docs.docker.com/config/containers/logging/configure/
查看当前的docker主机的驱动：
$ docker info --format &amp;#39;{{.LoggingDriver}}&amp;#39; json-file格式，docker会默认将标准和错误输出保存为宿主机的文件，路径为：
/var/lib/docker/containers/&amp;lt;container-id&amp;gt;/&amp;lt;container-id&amp;gt;-json.log
并且可以设置日志轮转：
{  &amp;#34;log-driver&amp;#34;: &amp;#34;json-file&amp;#34;,  &amp;#34;log-opts&amp;#34;: {  &amp;#34;max-size&amp;#34;: &amp;#34;10m&amp;#34;,  &amp;#34;max-file&amp;#34;: &amp;#34;3&amp;#34;,  &amp;#34;labels&amp;#34;: &amp;#34;production_status&amp;#34;,  &amp;#34;env&amp;#34;: &amp;#34;os,customer&amp;#34;  } } 优势：
 部署方便，使用DaemonSet类型控制器来部署agent即可 对业务应用的影响最小，没有侵入性  劣势:
 只能收集标准和错误输出，对于容器内的文件日志，暂时收集不到  使用 sidecar 容器和日志代理   方式一：sidecar 容器将应用程序日志传送到自己的标准输出。 思路：在pod中启动一个sidecar容器，把容器内的日志文件吐到标准输出，由宿主机中的日志收集agent进行采集。
$ cat count-pod.yaml apiVersion: v1 kind: Pod metadata:  name: counter spec:  containers:  - name: count  image: busybox  args:  - /bin/sh  - -c  - &amp;gt;  i=0;  while true;  do  echo &amp;#34;$i: $(date)&amp;#34; &amp;gt;&amp;gt; /var/log/1.</description>
    </item>
    
    <item>
      <title>Kubernetes进阶实践</title>
      <link>https://iblog.zone/archives/kubernetes%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Wed, 05 Jan 2022 11:13:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/kubernetes%E8%BF%9B%E9%98%B6%E5%AE%9E%E8%B7%B5/</guid>
      <description>第三天 Kubernetes进阶实践 本章介绍Kubernetes的进阶内容，包含Kubernetes集群调度、CNI插件、认证授权安全体系、分布式存储的对接、Helm的使用等，让学员可以更加深入的学习Kubernetes的核心内容。
 ETCD数据的访问 kube-scheduler调度策略实践  预选与优选流程 生产中常用的调度配置实践   k8s集群网络模型  CNI介绍及集群网络选型 Flannel网络模型的实现  vxlan Backend hostgw Backend     集群认证与授权  APIServer安全控制模型 Kubectl的认证授权 RBAC kubelet的认证授权 Service Account   使用Helm管理复杂应用的部署  Helm工作原理详解 Helm的模板开发 实战：使用Helm部署Harbor仓库   kubernetes对接分部式存储  pv、pvc介绍 k8s集群如何使用cephfs作为分布式存储后端 利用storageClass实现动态存储卷的管理 实战：使用分部署存储实现有状态应用的部署   本章知识梳理及回顾  ETCD常用操作 拷贝etcdctl命令行工具：
$ docker exec -ti etcd_container which etcdctl $ docker cp etcd_container:/usr/local/bin/etcdctl /usr/bin/etcdctl 查看etcd集群的成员节点：
$ export ETCDCTL_API=3 $ etcdctl --endpoints=https://[127.</description>
    </item>
    
    <item>
      <title>Kubernetes落地实践之旅</title>
      <link>https://iblog.zone/archives/kubernetes%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5%E4%B9%8B%E6%97%85/</link>
      <pubDate>Tue, 04 Jan 2022 15:11:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/kubernetes%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5%E4%B9%8B%E6%97%85/</guid>
      <description>第二天 Kubernetes落地实践之旅 本章学习kubernetes的架构及工作流程，重点介绍如何使用Workload管理业务应用的生命周期，实现服务不中断的滚动更新，通过服务发现和集群内负载均衡来实现集群内部的服务间访问，并通过ingress实现外部使用域名访问集群内部的服务。
学习过程中会逐步对Django项目做k8s改造，从零开始编写所需的资源文件。通过本章的学习，学员会掌握高可用k8s集群的搭建，同时Django demo项目已经可以利用k8s的控制器、服务发现、负载均衡、配置管理等特性来实现生命周期的管理。
纯容器模式的问题  业务容器数量庞大，哪些容器部署在哪些节点，使用了哪些端口，如何记录、管理，需要登录到每台机器去管理？ 跨主机通信，多个机器中的容器之间相互调用如何做，iptables规则手动维护？ 跨主机容器间互相调用，配置如何写？写死固定IP+端口？ 如何实现业务高可用？多个容器对外提供服务如何实现负载均衡？ 容器的业务中断了，如何可以感知到，感知到以后，如何自动启动新的容器? 如何实现滚动升级保证业务的连续性？ &amp;hellip;&amp;hellip;  容器调度管理平台 Docker Swarm Mesos Google Kubernetes
2017年开始Kubernetes凭借强大的容器集群管理功能, 逐步占据市场,目前在容器编排领域一枝独秀
https://kubernetes.io/
架构图 分布式系统，两类角色：管理节点和工作节点
核心组件   ETCD：分布式高性能键值数据库,存储整个集群的所有元数据
  ApiServer: API服务器,集群资源访问控制入口,提供restAPI及安全访问控制
  Scheduler：调度器,负责把业务容器调度到最合适的Node节点
  Controller Manager：控制器管理,确保集群资源按照期望的方式运行
 Replication Controller Node controller ResourceQuota Controller Namespace Controller ServiceAccount Controller Token Controller Service Controller Endpoints Controller    kubelet：运行在每个节点上的主要的“节点代理”，脏活累活
 pod 管理：kubelet 定期从所监听的数据源获取节点上 pod/container 的期望状态（运行什么容器、运行的副本数量、网络或者存储如何配置等等），并调用对应的容器平台接口达到这个状态。 容器健康检查：kubelet 创建了容器之后还要查看容器是否正常运行，如果容器运行出错，就要根据 pod 设置的重启策略进行处理.</description>
    </item>
    
    <item>
      <title>Etcd v3备份与恢复</title>
      <link>https://iblog.zone/archives/etcd-v3%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</link>
      <pubDate>Thu, 30 Dec 2021 17:56:53 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/etcd-v3%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</guid>
      <description>ETCD 简介 ETCD 是用于共享配置和服务发现的分布式，一致性的KV存储系统。ETCD是CoreOS公司发起的一个开源项目，授权协议为Apache。
ETCD 使用场景 ETCD 有很多使用场景，包括但不限于：
 配置管理 服务注册于发现 选主 应用调度 分布式队列 分布式锁  ETCD 存储 k8s 所有数据信息 ETCD 是k8s集群极为重要的一块服务，存储了集群所有的数据信息。同理，如果发生灾难或者 etcd 的数据丢失，都会影响集群数据的恢复。所以，本文重点讲如何备份和恢复数据。
ETCD 一些查询操作  查看集群状态  $ ETCDCTL_API=3 etcdctl --cacert=/opt/kubernetes/ssl/ca.pem --cert=/opt/kubernetes/ssl/server.pem --key=/opt/kubernetes/ssl/server-key.pem --endpoints=https://192.168.1.36:2379,https://192.168.1.37:2379,https://192.168.1.38:2379 endpoint health  https://192.168.1.36:2379 is healthy: successfully committed proposal: took = 1.698385ms https://192.168.1.37:2379 is healthy: successfully committed proposal: took = 1.577913ms https://192.168.1.38:2379 is healthy: successfully committed proposal: took = 5.616079ms  获取某个 key 信息  $ ETCDCTL_API=3 etcdctl --cacert=/opt/kubernetes/ssl/ca.</description>
    </item>
    
    <item>
      <title>走进Docker的世界</title>
      <link>https://iblog.zone/archives/%E8%B5%B0%E8%BF%9Bdocker%E7%9A%84%E4%B8%96%E7%95%8C/</link>
      <pubDate>Thu, 30 Dec 2021 15:35:39 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E8%B5%B0%E8%BF%9Bdocker%E7%9A%84%E4%B8%96%E7%95%8C/</guid>
      <description>第一天 走进Docker的世界 介绍docker的前世今生，了解docker的实现原理，以Django项目为例，带大家如何编写最佳的Dockerfile构建镜像。通过本章的学习，大家会知道docker的概念及基本操作，并学会构建自己的业务镜像，并通过抓包的方式掌握Docker最常用的bridge网络模式的通信。
认识docker  why what how  为什么出现docker 需要一种轻量、高效的虚拟化能力
Docker 公司位于旧金山,原名dotCloud，底层利用了Linux容器技术（LXC）（在操作系统中实现资源隔离与限制）。为了方便创建和管理这些容器，dotCloud 开发了一套内部工具，之后被命名为“Docker”。Docker就是这样诞生的。
Hypervisor： 一种运行在基础物理服务器和操作系统之间的中间软件层，可允许多个操作系统和应用共享硬件 。常见的VMware的 Workstation 、ESXi、微软的Hyper-V或者思杰的XenServer。
Container Runtime：通过Linux内核虚拟化能力管理多个容器，多个容器共享一套操作系统内核。因此摘掉了内核占用的空间及运行所需要的耗时，使得容器极其轻量与快速。
什么是docker 基于操作系统内核，提供轻量级虚拟化功能的CS架构的软件产品。
基于轻量的特性，解决软件交付过程中的环境依赖
docker能做什么  可以把应用程序代码及运行依赖环境打包成镜像，作为交付介质，在各环境部署 可以将镜像（image）启动成为容器(container)，并且提供多容器的生命周期进行管理（启、停、删） container容器之间相互隔离，且每个容器可以设置资源限额 提供轻量级虚拟化功能，容器就是在宿主机中的一个个的虚拟的空间，彼此相互隔离，完全独立  版本管理  Docker 引擎主要有两个版本：企业版（EE）和社区版（CE） 每个季度(1-3,4-6,7-9,10-12)，企业版和社区版都会发布一个稳定版本(Stable)。社区版本会提供 4 个月的支持，而企业版本会提供 12 个月的支持 每个月社区版还会通过 Edge 方式发布月度版 从 2017 年第一季度开始，Docker 版本号遵循 YY.MM-xx 格式，类似于 Ubuntu 等项目。例如，2018 年 6 月第一次发布的社区版本为 18.06.0-ce  发展史 13年成立，15年开始，迎来了飞速发展。
Docker 1.8之前，使用LXC，Docker在上层做了封装， 把LXC复杂的容器创建与使用方式简化为自己的一套命令体系。
之后，为了实现跨平台等复杂的场景，Docker抽出了libcontainer项目，把对namespace、cgroup的操作封装在libcontainer项目里，支持不同的平台类型。
2015年6月，Docker牵头成立了 OCI（Open Container Initiative开放容器计划）组织，这个组织的目的是建立起一个围绕容器的通用标准 。 容器格式标准是一种不受上层结构绑定的协议，即不限于某种特定操作系统、硬件、CPU架构、公有云等 ， 允许任何人在遵循该标准的情况下开发应用容器技术，这使得容器技术有了一个更广阔的发展空间。</description>
    </item>
    
    <item>
      <title>nginx php-fpm安装配置</title>
      <link>https://iblog.zone/archives/nginx-php-fpm%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Wed, 29 Dec 2021 15:38:23 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/nginx-php-fpm%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/</guid>
      <description>nginx本身不能处理PHP，它只是个web服务器，当接收到请求后，如果是php请求，则发给php解释器处理，并把结果返回给客户端。
nginx一般是把请求发fastcgi管理进程处理，fascgi管理进程选择cgi子进程处理结果并返回被nginx
本文以php-fpm为例介绍如何使nginx支持PHP
一、编译安装php-fpm
什么是PHP-FPM
PHP-FPM是一个PHP FastCGI管理器，是只用于PHP的,可以在 http://php-fpm.org/download下载得到.
PHP-FPM其实是PHP源代码的一个补丁，旨在将FastCGI进程管理整合进PHP包中。必须将它patch到你的PHP源代码中，在编译安装PHP后才可以使用。
新版PHP已经集成php-fpm了，不再是第三方的包了，推荐使用。PHP-FPM提供了更好的PHP进程管理方式，可以有效控制内存和进程、可以平滑重载PHP配置，比spawn-fcgi具有更多优点，所以被PHP官方收录了。在./configure的时候带 –enable-fpm参数即可开启PHP-FPM，其它参数都是配置php的，具体选项含义可以查看这里。
安装前准备 centos下执行
yum -y install gcc automake autoconf libtool make yum -y install gcc gcc-c++ glibc yum -y install libmcrypt-devel mhash-devel libxslt-devel \ libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel \ zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel \ ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel \ krb5 krb5-devel libidn libidn-devel openssl openssl-devel 新版php-fpm安装(推荐安装方式)
wget http://cn2.php.net/distributions/php-5.4.7.tar.gz tar zvxf php-5.</description>
    </item>
    
    <item>
      <title>CentOS7.9.2009 卸载自带的python及yum并重装</title>
      <link>https://iblog.zone/archives/centos7.9.2009-%E5%8D%B8%E8%BD%BD%E8%87%AA%E5%B8%A6%E7%9A%84python%E5%8F%8Ayum%E5%B9%B6%E9%87%8D%E8%A3%85/</link>
      <pubDate>Wed, 29 Dec 2021 15:27:19 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos7.9.2009-%E5%8D%B8%E8%BD%BD%E8%87%AA%E5%B8%A6%E7%9A%84python%E5%8F%8Ayum%E5%B9%B6%E9%87%8D%E8%A3%85/</guid>
      <description>一：删除之前的python和yum 1、删除python rpm -qa|grep python|xargs rpm -ev --allmatches --nodeps ##强制删除已安装程序及其关联 whereis python |xargs rm -frv ##删除所有残余文件 ##xargs，允许你对输出执行其他某些命令 whereis python ##验证删除，返回无结果 2、删除现有的yum rpm -qa|grep yum|xargs rpm -ev --allmatches --nodeps whereis yum |xargs rm -frv whereis yum ##验证删除，返回无结果 二：下载安装包 https://mirrors.ustc.edu.cn/centos/7.9.2009/os/x86_64/Packages/
三：安装 rpm -Uvh --replacepkgs *.rpm #意思是安装当前目录下所有的rpm文件 </description>
    </item>
    
    <item>
      <title>CentOS7升级python2.7.5到python3.7以上版本</title>
      <link>https://iblog.zone/archives/centos7%E5%8D%87%E7%BA%A7python2.7.5%E5%88%B0python3.7%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC/</link>
      <pubDate>Wed, 29 Dec 2021 15:19:27 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E5%8D%87%E7%BA%A7python2.7.5%E5%88%B0python3.7%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC/</guid>
      <description>CentOS7中自带的python版本是python-2.7.5，由于新开的虚拟机需要使用python3，于是便升级一下版本。
安装Python3.7.3 官网下载地址：https://www.python.org/downlo&amp;hellip;
这里选择下载python 3.7.3。
# 下载 wget https://www.python.org/ftp/python/3.7.3/Python-3.7.3.tgz # 解压 tar -zxf Python-3.7.3.tgz # 安装依赖包 yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc libffi-devel # 进入python目录 cd Python-3.7.3 # 编译 ./configure --prefix=/usr/local/python3.7 #安装 make &amp;amp;&amp;amp; make install 关于Python3.7以上的版本，需要多安装一个依赖包:
 yum install -y libffi-devel 否则会出现ModuleNotFoundError: No module named &#39;_ctypes&#39;的报错。
在make install后执行echo $?，为0表示没有出错。如果没有报错，在/usr/local会生成python3.7目录。
然后将系统默认的python2备份
mv /usr/bin/python /usr/bin/python.bak 创建新的软连接
ln -s /usr/local/python/bin/python3.7 /usr/bin/python 查看版本
[root@moli-linux03 src]# python -V Python 3.7.3 升级完成了。</description>
    </item>
    
    <item>
      <title>yum下载全量rpm依赖包及离线安装</title>
      <link>https://iblog.zone/archives/yum%E4%B8%8B%E8%BD%BD%E5%85%A8%E9%87%8Frpm%E4%BE%9D%E8%B5%96%E5%8C%85%E5%8F%8A%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</link>
      <pubDate>Tue, 28 Dec 2021 18:15:53 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/yum%E4%B8%8B%E8%BD%BD%E5%85%A8%E9%87%8Frpm%E4%BE%9D%E8%B5%96%E5%8C%85%E5%8F%8A%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85/</guid>
      <description>简介 通常生产环境由于安全原因都无法访问互联网。此时就需要进行离线安装，主要有两种方式：源码编译、rpm包安装。源码编译耗费时间长且缺乏编译环境，所以一般都选择使用离线 rpm 包安装。
验证环境 Centos 7.2
查看依赖包 可以使用“yum deplist”命令来查找 rpm 包的依赖列表。例如，要查找“ansible”rpm的依赖包：
$ yum deplist ansible 软件包：ansible.noarch 2.9.3-1.el7  依赖：/usr/bin/env  provider: coreutils.x86_64 8.22-24.el7  依赖：/usr/bin/python2  provider: python.x86_64 2.7.5-86.el7  依赖：PyYAML  provider: PyYAML.x86_64 3.10-11.el7  依赖：python(abi) = 2.7  provider: python.x86_64 2.7.5-86.el7  依赖：python-httplib2  provider: python-httplib2.noarch 0.9.2-1.el7  依赖：python-jinja2  provider: python-jinja2.noarch 2.7.2-4.el7  依赖：python-paramiko  provider: python-paramiko.noarch 2.1.1-9.el7  依赖：python-setuptools  provider: python-setuptools.noarch 0.9.8-7.el7  依赖：python-six  provider: python-six.</description>
    </item>
    
    <item>
      <title>centos7 openssh升级到最新版本</title>
      <link>https://iblog.zone/archives/centos7-openssh%E5%8D%87%E7%BA%A7%E5%88%B0%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC/</link>
      <pubDate>Fri, 24 Dec 2021 11:13:27 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos7-openssh%E5%8D%87%E7%BA%A7%E5%88%B0%E6%9C%80%E6%96%B0%E7%89%88%E6%9C%AC/</guid>
      <description>注意事项 本文的环境都是系统自带的openssh，若是手动编译安装的，不保证成功。若是自带的，则升级过程中不需要卸载旧版本openssh。
安装之前可以先试试yum更新,若是可以更新，就不需要往下看了
# centos8  $ yum update openssh -y # 重启sshd $ systemctl restart sshd 准备工作 系统说明  系统版本：CentOS Linux release 7.7.1908 (Core) openssh：OpenSSH_7.4p1, OpenSSL 1.0.2k-fips 26 Jan 2017 openssl: OpenSSL 1.0.2k-fips 26 Jan 2017  下载最新包  openssh openssl  本文选择的是: openssh-8.2p1.tar.gz openssl-1.1.1g.tar.gz
$ wget https://cdn.openbsd.org/pub/OpenBSD/OpenSSH/portable/openssh-8.2p1.tar.gz  $ wget https://ftp.openssl.org/source/openssl-1.1.1g.tar.gz 安装telnet备用（可选） 安装新的ssh之后，只要配置好启动，就可以做到无缝切换，但是中途断开就不能连接了，为了防止这种情况，我们可以安装telnet当作备用，若是你能保证中途不会断开，此步骤可以忽略
1.安装
$ yum install telnet telnet-server -y 2.启动
$ systemctl enable telnet.socket $ systemctl start telnet.</description>
    </item>
    
    <item>
      <title>Centos7升级内核版本</title>
      <link>https://iblog.zone/archives/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC/</link>
      <pubDate>Thu, 23 Dec 2021 11:38:27 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E7%89%88%E6%9C%AC/</guid>
      <description>小版本升级
1. 查看当前和可升级版本
[root@jksb_qz ~]# yum list kernel Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile  * base: mirrors.aliyun.com  * extras: mirrors.aliyun.com  * updates: mirrors.aliyun.com Installed Packages kernel.x86_64 3.10.0-693.el7 kernel.x86_64 3.10.0-1160.49.1.el7 2. 升级
[root@jksb_qz ~]# yum update kernel -y  3. 重启并检查
 [root@jksb_qz ~]# reboot    [root@jksb_qz ~]# uname -r  大版本升级
1. 载入公钥
[root@jksb_qz ~]# rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org 2. 升级安装ELRepo
[root@jksb_qz ~]# rpm -Uvh http://www.</description>
    </item>
    
    <item>
      <title>Windows配置端口转发</title>
      <link>https://iblog.zone/archives/windows%E9%85%8D%E7%BD%AE%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/</link>
      <pubDate>Wed, 22 Dec 2021 17:02:53 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/windows%E9%85%8D%E7%BD%AE%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/</guid>
      <description>//显示所有 portproxy 参数，包括 v4tov4、v4tov6、v6tov4 和 v6tov6 的端口/地址对。 C:\&amp;gt;netsh interface portproxy show all //因为没有配置过它，所以没有东西可以显示。  //添加配置: 本机监听10022端口,当有socket连接到10022端口时,本机就连接到192.168.2.53的22端口,本机的10022端口可以接受的连接地址为&amp;#34;*&amp;#34;,使用的协议为tcp,当前仅支持传输控制协议 (TCP)。 C:\&amp;gt;netsh interface portproxy add v4tov4 listenport=10022 connectaddress=192.168.2.53 connectport=22 listenaddress=* protocol=tcp //添加完毕。  //显示所有。 C:\&amp;gt;netsh interface portproxy show all  侦听 ipv4: 连接到 ipv4:  地址 端口 地址 端口 --------------- ---------- --------------- ---------- * 10022 192.168.2.53 22  //删除配置: 本机的监听端口为10022,10022端口接受的连接地址为&amp;#34;*&amp;#34;,使用的协议为tcp,当前仅支持TCP协议。 C:\&amp;gt;netsh interface portproxy delete v4tov4 listenport=10022 listenaddress=* protocol=tcp //删除完毕。  //显示所有。 C:\&amp;gt;netsh interface portproxy show all //因为所有的配置均已删除，所以没有东西可以显示。  //查看帮助信息。 C:\&amp;gt;netsh interface portproxy /?</description>
    </item>
    
    <item>
      <title>配置Nginx访问网页需要密码</title>
      <link>https://iblog.zone/archives/%E9%85%8D%E7%BD%AEnginx%E8%AE%BF%E9%97%AE%E7%BD%91%E9%A1%B5%E9%9C%80%E8%A6%81%E5%AF%86%E7%A0%81/</link>
      <pubDate>Tue, 21 Dec 2021 14:28:29 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E9%85%8D%E7%BD%AEnginx%E8%AE%BF%E9%97%AE%E7%BD%91%E9%A1%B5%E9%9C%80%E8%A6%81%E5%AF%86%E7%A0%81/</guid>
      <description>1. 安装密码生成工具 $ yum -y install httpd-tools 2. 生成用户和密码文件 生成用户和密码
$ htpasswd -c /usr/local/nginx/password username # 回车后输入密码 # -c 创建一个加密文件 查看生成的用户和密码
如果要修改密码，或者删除密码，请参考下面操作
删除用户和密码
$ htpasswd -D /usr/local/nginx/password username # -D 删除指定的用户 修改用户和密码
$ htpasswd -D /usr/local/nginx/password username $ htpasswd -b /usr/local/nginx/password username pass # -D 删除指定的用户 # -b htpassswd命令行中一并输入用户名和密码而不是根据提示输入密码 # -p htpassswd命令不对密码进行进行加密，即明文密码 3. 配置Nginx认证 找到 nginx 配置文件，通常默认的配置文件在/usr/local/nginx/conf/nginx.conf，要对整个站点开启验证，需在配置文件中的server加上认证配置 auth_basic 和 auth_basic_user_file
server {  listen 80;  server_name localhost;  # .</description>
    </item>
    
    <item>
      <title>Kubernetes1.16安装[kubadm方式]</title>
      <link>https://iblog.zone/archives/kubernetes1.16%E5%AE%89%E8%A3%85kubadm%E6%96%B9%E5%BC%8F/</link>
      <pubDate>Wed, 15 Dec 2021 14:58:45 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/kubernetes1.16%E5%AE%89%E8%A3%85kubadm%E6%96%B9%E5%BC%8F/</guid>
      <description>集群信息 1. 节点规划 部署k8s集群的节点按照用途可以划分为如下2类角色：
 master：集群的master节点，集群的初始化节点，基础配置不低于2C4G slave：集群的slave节点，可以多台，基础配置不低于2C4G  本例为了演示slave节点的添加，会部署一台master+2台slave，节点规划如下：
   主机名 节点ip 角色 部署组件     k8s-master 192.168.136.128 master etcd, kube-apiserver, kube-controller-manager, kubectl, kubeadm, kubelet, kube-proxy, flannel   k8s-slave1 192.168.136.131 slave kubectl, kubelet, kube-proxy, flannel   k8s-slave2 192.168.136.132 slave kubectl, kubelet, kube-proxy, flannel    2. 组件版本    组件 版本 说明     CentOS 7.6.1810    Kernel Linux 3.</description>
    </item>
    
    <item>
      <title>k8s搭建consul集群</title>
      <link>https://iblog.zone/archives/k8s%E6%90%AD%E5%BB%BAconsul%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Tue, 14 Dec 2021 14:44:57 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/k8s%E6%90%AD%E5%BB%BAconsul%E9%9B%86%E7%BE%A4/</guid>
      <description>部署一个Service  vim consul-server-service.yaml apiVersion: v1 kind: Service metadata:  name: consul-server  labels:  name: consul-server spec:  selector:  name: consul-server  ports:  - name: http  port: 8500  targetPort: 8500  - name: https  port: 8443  targetPort: 8443  - name: rpc  port: 8400  targetPort: 8400  - name: serf-lan-tcp  protocol: &amp;#34;TCP&amp;#34;  port: 8301  targetPort: 8301  - name: serf-lan-udp  protocol: &amp;#34;UDP&amp;#34;  port: 8301  targetPort: 8301  - name: serf-wan-tcp  protocol: &amp;#34;TCP&amp;#34;  port: 8302  targetPort: 8302  - name: serf-wan-udp  protocol: &amp;#34;UDP&amp;#34;  port: 8302  targetPort: 8302  - name: server  port: 8300  targetPort: 8300  - name: consul-dns  port: 8600  targetPort: 8600 kubect create -f consul-server-service.</description>
    </item>
    
    <item>
      <title>Docker 常用命令大全</title>
      <link>https://iblog.zone/archives/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</link>
      <pubDate>Sat, 11 Dec 2021 18:14:07 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/docker-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%A7%E5%85%A8/</guid>
      <description>本文包括容器生命周期管理命令、容器操作命令、容器rootfs命令、镜像仓库命令、本地镜像管理命令和基础版本信息命令。
容器生命周期管理命令 run 创建一个新的容器。
# 使用docker镜像nginx:latest以后台模式启动一个容器, # 并将容器命名为mynginx。  docker run --name mynginx -d nginx:latest  # 使用镜像 nginx:latest，以后台模式启动一个容器, # 将容器的 80 端口映射到主机的 80 端口, # 主机的目录 /data 映射到容器的 /data。  docker run -p 80:80 -v /data:/data -d nginx:latest  # 使用镜像nginx:latest以交互模式启动一个容器, # 在容器内执行/bin/bash命令。  docker run -it nginx:latest /bin/bash start/stop/restart  docker start : 启动一个或多个已经被停止的容器。 docker stop : 停止一个运行中的容器。 docker restart : 重启容器。  # 启动已被停止的容器mynginx  docker start mynginx  # 停止运行中的容器mynginx  docker stop mynginx  # 重启容器mynginx  docker restart mynginx kill 杀掉一个运行中的容器。可选参数：</description>
    </item>
    
    <item>
      <title>Java中的常见OOM及原因</title>
      <link>https://iblog.zone/archives/java%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81oom%E5%8F%8A%E5%8E%9F%E5%9B%A0/</link>
      <pubDate>Fri, 10 Dec 2021 16:20:43 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/java%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81oom%E5%8F%8A%E5%8E%9F%E5%9B%A0/</guid>
      <description>Java中的OOM（Out of Memory）指java.lang.OutOfMemoryError错误。了解JVM的基本原理后，很容易理解以下几种常见的OOM。
java.lang.OutOfMemoryError:Java heap space 这是最常见的OOM原因。
堆中主要存放各种对象实例，还有常量池等结构。当JVM发现堆中没有足够的空间分配给新对象时，抛出该异常。具体来讲，在刚发现空间不足时，会先进行一次Full GC，如果GC后还是空间不足，再抛出异常。
引起空间不足的原因主要有：
 业务高峰，创建对象过多 内存泄露 内存碎片严重，无法分配给大对象  java.lang.OutOfMemoryError:Metaspace 方法区主要存储类的元信息，实现在元数据区。当JVM发现元数据区没有足够的空间分配给加载的类时，抛出该异常。
引起元数据区空间不足的原因主要有：
 加载的类太多，常见于Tomcat等容器中  但是元数据区被实现在堆外，主要受到进程本身的内存限制，这种实现下很难溢出。
java.lang.OutOfMemoryError:Permgen space jdk7中，方法区被实现在永久代中，错误原因同上。
永久代非常小，而且不会被回收，很容易溢出，因此，jdk8彻底废除了永久代，将方法区实现在元数据区。
java.lang.OutOfMemoryError:Unable to create new native thread 以Linux系统为例，JVM创建的线程与操作系统中的线程一一对应，受到以下限制：
 进程和操作系统的内存资源限制。其中，一个JVM线程至少要占用OS的线程栈+JVM的虚拟机栈 = 8MB + 1MB = 9MB（当然JVM实现可以选择不使用这1MB的JVM虚拟机栈）。 进程和操作系统的线程数限制。 Linux中的线程被实现为轻量级进程，因此，还受到pid数量的限制。  当无法在操作系统中继续创建线程时，抛出上述异常。
解决办法从原因中找：
 内存资源：调小OS的线程栈、JVM的虚拟机栈。 线程数：增大线程数限制。 pid：增大pid范围。  其他异常 java.lang.OutOfMemoryError:GC overhead limit exceeded 默认配置下，如果GC花费了98%的时间，回收的内存都不足2%的话，抛出该异常。
java.lang.OutOfMemoryError:Out of swap space 如果JVM申请的内存大于可用物理内存，操作系统会将内存中的数据交换到磁盘上去（交换区）。如果交换区空间不足，抛出该异常。</description>
    </item>
    
    <item>
      <title>使用宝塔面板将Hexo部署到腾讯轻量级应用服务器</title>
      <link>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF%E5%B0%86hexo%E9%83%A8%E7%BD%B2%E5%88%B0%E8%85%BE%E8%AE%AF%E8%BD%BB%E9%87%8F%E7%BA%A7%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Thu, 09 Dec 2021 11:47:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E4%BD%BF%E7%94%A8%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF%E5%B0%86hexo%E9%83%A8%E7%BD%B2%E5%88%B0%E8%85%BE%E8%AE%AF%E8%BD%BB%E9%87%8F%E7%BA%A7%E5%BA%94%E7%94%A8%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>一、安装宝塔面板 yum install -y wget &amp;amp;&amp;amp; wget -O install.sh http://download.bt.cn/install/install_6.0.sh &amp;amp;&amp;amp; sh install.sh 安装成功后，显示如下内容
外网面板地址: http://xx:8888/xx 内网面板地址: http://10.0.16.13:8888/xx username: xx password: xx If you cannot access the panel, release the following panel port [8888] in the security group 若无法访问面板，请检查防火墙/安全组是否有放行面板[8888]端口 在宝塔面板网站管理中，添加站点（第一次进入需要安装nginx，点击快速安装即可）
二、Git仓库创建 1、服务端增加git用户
adduser git passwd git 2、给git用户授权
vim /etc/sudoers  #在root ALL=(ALL) ALL 下方添加一行  git ALL=(ALL) ALL 3、用户端跟服务端做免密登录
用户端生成密钥对
ssh-keygen 将秘钥传到服务端
ssh-copy-id git@server_ip # 输入git刚创建的git用户的密码 验证
ssh git@server_ip # 如果没有要求输入密码就登录进去了 说明免密成功 4、创建git仓库</description>
    </item>
    
    <item>
      <title>OpenVPN 设置账号密码登录</title>
      <link>https://iblog.zone/archives/openvpn-%E8%AE%BE%E7%BD%AE%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/</link>
      <pubDate>Wed, 08 Dec 2021 17:09:00 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/openvpn-%E8%AE%BE%E7%BD%AE%E8%B4%A6%E5%8F%B7%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95/</guid>
      <description>前面我们是使用openvpn 秘钥的方式登录，这种登录安全性比较高。但是运维操作起来比较麻烦，如果有ldap的也推荐使用ldap集成openvpn。但是这里我们偷个懒，通过设置账号密码的方式连接vpn
配置OpenVPN 首先我们需要编写一个用户认证的脚本 (脚本是由openvpn官网提供的)
vim /etc/openvpn/checkpsw.sh #!/bin/sh ########################################################### # checkpsw.sh (C) 2004 Mathias Sundman  # # This script will authenticate OpenVPN users against # a plain text file. The passfile should simply contain # one row per user with the username first followed by # one or more space(s) or tab(s) and then the password.  PASSFILE=&amp;#34;/etc/openvpn/psw-file&amp;#34; LOG_FILE=&amp;#34;/etc/openvpn/openvpn-password.log&amp;#34; TIME_STAMP=`date &amp;#34;+%Y-%m-%d %T&amp;#34;`  ###########################################################  if [ ! -r &amp;#34;${PASSFILE}&amp;#34; ]; then  echo &amp;#34;${TIME_STAMP}: Could not open password file \&amp;#34;${PASSFILE}\&amp;#34; for reading.</description>
    </item>
    
    <item>
      <title>centos7.4 安装mysql 5.7</title>
      <link>https://iblog.zone/archives/centos7.4-%E5%AE%89%E8%A3%85mysql-5.7/</link>
      <pubDate>Tue, 07 Dec 2021 14:39:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos7.4-%E5%AE%89%E8%A3%85mysql-5.7/</guid>
      <description>以centos为例(以root身份登录)
目录约定  安装文件下载目录：/data/software mysql目录安装位置：/usr/local/mysql 数据库保存位置：/data/mysql 日志保存位置：/data/log/mysql  #如果这3个文件夹不存在，先创建 mkdir -p /data/software mkdir -p /data/mysql mkdir -p /data/log/mysql  #创建错误日志文件 cd /data/log/mysql touch error.log  #/usr/local/mysql这个目录待会解压安装包的时候一并创建 下载并解压 在官网选择mysql5.7.24 Linux - Generic版本下载
 文件较大推荐服务器使用wget命令下载，或者本地使用迅雷下载，然后上传到服务器
 cd /data/software wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz  tar -zxvf mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz #这里注意mysql后面没有/ mv mysql-5.7.24-linux-glibc2.12-x86_64 /usr/local/mysql 新建mysql组、用户 groupadd mysql #新建msyql用户禁止登录shell useradd -r -g mysql mysql -s /sbin/nologin  #更改目录权限 chown -R mysql:mysql /usr/local/mysql chown -R mysql:mysql /data/log/mysql 配置参数 bin/mysqld --initialize-insecure --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql  bin/mysql_ssl_rsa_setup --datadir=/data/mysql  cd /usr/local/mysql/support-files cp mysql.</description>
    </item>
    
    <item>
      <title>解决npm install下载chromedriver@2.46.0依赖包超级慢问题</title>
      <link>https://iblog.zone/archives/%E8%A7%A3%E5%86%B3npm-install%E4%B8%8B%E8%BD%BDchromedriver2.46.0%E4%BE%9D%E8%B5%96%E5%8C%85%E8%B6%85%E7%BA%A7%E6%85%A2%E9%97%AE%E9%A2%98/</link>
      <pubDate>Mon, 06 Dec 2021 18:06:03 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E8%A7%A3%E5%86%B3npm-install%E4%B8%8B%E8%BD%BDchromedriver2.46.0%E4%BE%9D%E8%B5%96%E5%8C%85%E8%B6%85%E7%BA%A7%E6%85%A2%E9%97%AE%E9%A2%98/</guid>
      <description>一、问题出现原因 使用gitlab-runner部署前端js项目时，下载chromedriver@2.46.0有时候相当的慢。
主要原因是npm install老去国外github下载
&amp;gt; chromedriver@2.45.0 install /app/node_modules/chromedriver &amp;gt; node install.js  Current existing ChromeDriver binary is unavailable, proceding with download and extraction. Downloading from file: https://chromedriver.storage.googleapis.com/2.45/chromedriver_linux64.zip Saving to file: /app/node_modules/chromedriver/chromedriver/chromedriver_linux64.zip ... 后来去放置gitlab-runner那台主机wget一下，结果一直响应中
cuiyf@gitlabrunner:~$ wget https://chromedriver.storage.googleapis.com/2.46/chromedriver_linux64.zip --2019-08-05 17:46:32-- https://chromedriver.storage.googleapis.com/2.46/chromedriver_linux64.zip Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 216.58.200.48, 2404:6800:4008:801::2010 Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|216.58.200.48|:443... connected. HTTP request sent, awaiting response... 二、解决思路 设法使其去淘宝镜像源地址下载
https://registry.npm.taobao.org/ 三、解决方案 由于我是用docker部署的，修改Dockerfile添加如下配置 npm install chromedriver --chromedriver_cdnurl=http://cdn.npm.taobao.org/dist/chromedriver
FROMcuiyf/node:8.12.0-alpine as build-stageCOPY . /appWORKDIR/appRUN npm config set registry http://172.</description>
    </item>
    
    <item>
      <title>CentOS 7 搭建OpenVPN服务器</title>
      <link>https://iblog.zone/archives/centos-7-%E6%90%AD%E5%BB%BAopenvpn%E6%9C%8D%E5%8A%A1%E5%99%A8/</link>
      <pubDate>Sun, 05 Dec 2021 22:02:39 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/centos-7-%E6%90%AD%E5%BB%BAopenvpn%E6%9C%8D%E5%8A%A1%E5%99%A8/</guid>
      <description>OpenVPN的工作原理 在Linux2.4版本以上，操作系统支持一个名为tun的设备，tun设备的驱动程序中包含两个部分，一部分是字符设备驱动，一部分是网卡驱动。网卡的驱动把从TCP/IP协议栈收到的数据包结构skb放于tun设备的读取队列，用户进程通过调用字符设备接口read获得完整的IP数据包，字符驱动read函数的功能是从设备的读取队列读取数据，将核心态的skb传递给用户；反过来字符驱动write函数给用户提供了把用户态的数据写入核心态的接口，write函数把用户数据写入核心空间并穿入TCP/IP协议栈。该设备既能以字符设备的方式被读写，作为系统的虚拟网卡，也具有和物理网卡相同的特点：能够配置IP地址和路由。对虚拟网卡的使用是OpenVPN实现其SSL VPN功能的关键。
OpenVPN服务器一般需要配置一个虚拟IP地址池和一个自用的静态虚拟IP地址（静态地址和地址池必须在同一个子网中），然后为每一个成功建立SSL连接的客户端动态分配一个虚拟IP地址池中未分配的地址。这样，物理网络中的客户端和OpenVPN服务器就连接成一个虚拟网络上的星型结构局域网，OpenVPN服务器成为每个客户端在虚拟网络上的网关。OpenVPN服务器同时提供对客户端虚拟网卡的路由管理。当客户端对OpenVPN服务器后端的应用服务器的任何访问时，数据包都会经过路由流经虚拟网卡，OpenVPN程序在虚拟网卡上截获数据IP报文，然后使用SSL协议将这些IP报文封装起来，再经过物理网卡发送出去。OpenVPN的服务器和客户端在虚拟网卡之上建立起一个虚拟的局域网络，这个虚拟的局域网对系统的用户来说是透明的。
OpenVPN的服务器和客户端支持tcp和udp两种连接方式，只需在服务端和客户端预先定义好使用的连接方式（tcp或udp）和端口号，客户端和服务端在这个连接的基础上进行SSL握手。连接过程包括SSL的握手以及虚拟网络上的管理信息，OpenVPN将虚拟网上的网段、地址、路由发送给客户端。连接成功后，客户端和服务端建立起SSL安全连接，客户端和服务端的数据都流入虚拟网卡做SSL的处理，再在tcp或udp的连接上从物理网卡发送出去
环境说明 192.168.0.10外网 10.4.82.10 内网  系统环境 [root@vpn ~]# cat /etc/redhat-release CentOS Linux release 7.7.1908 (Core) [root@vpn ~]# uname -r 3.10.0-1062.9.1.el7.x86_64  网卡为双网卡 [root@vpn ~]# ifconfig eth0: flags=4163&amp;lt;UP,BROADCAST,RUNNING,MULTICAST&amp;gt; mtu 1500  inet 192.168.0.11 netmask 255.255.255.0 broadcast 192.168.0.255  inet6 fe80::6b5a:9ab8:1bb:5f8d prefixlen 64 scopeid 0x20  ether 00:0c:29:32:b2:36 txqueuelen 1000 (Ethernet)  RX packets 15104 bytes 16993218 (16.2 MiB)  RX errors 0 dropped 0 overruns 0 frame 0  TX packets 8661 bytes 889872 (869.</description>
    </item>
    
    
    
  </channel>
</rss>
