<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>故障排查 on ylw&#39;s blog</title>
    <link>https://iblog.zone/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/</link>
    <description>Recent content in 故障排查 on ylw&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 24 Mar 2022 16:49:20 +0800</lastBuildDate><atom:link href="https://iblog.zone/categories/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nignx导致java程序TruncatedChunkException解决办法</title>
      <link>https://iblog.zone/archives/nignx%E5%AF%BC%E8%87%B4java%E7%A8%8B%E5%BA%8Ftruncatedchunkexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</link>
      <pubDate>Thu, 24 Mar 2022 16:49:20 +0800</pubDate>
      
      <guid>https://iblog.zone/archives/nignx%E5%AF%BC%E8%87%B4java%E7%A8%8B%E5%BA%8Ftruncatedchunkexception%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/</guid>
      <description>#项目异常信息 org.apache.http.TruncatedChunkException: Truncated chunk ( expected size: 7752; actual size: 4077)  at org.apache.http.impl.io.ChunkedInputStream.read(ChunkedInputStream.java:186)  at org.apache.http.conn.EofSensorInputStream.read(EofSensorInputStream.java:138)  at &amp;lt;mypackage&amp;gt;.&amp;lt;MyServlet&amp;gt;.service(&amp;lt;MyServlet&amp;gt;.java:XXX)  at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)  at org.jboss.resteasy.plugins.server.servlet.FilterDispatcher.doFilter(FilterDispatcher.java:63)  at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)  at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)  at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)  at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)  at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)  at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)  at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)  at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)  at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859)  at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:602)  at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)  at java.lang.Thread.run(Thread.java:724) 当系统报以上错误时，接口表现出来的是数据传输不完整， 比如说接口返回 json ， 那么接收到的数据可能会少一截，json 数据说不定会少个 ｝ ，此时json就无法反序列化了。说白了就是丢包了。</description>
    </item>
    
    <item>
      <title>超好用的k8s中pod诊断工具：kubectl-debug</title>
      <link>https://iblog.zone/archives/%E8%B6%85%E5%A5%BD%E7%94%A8%E7%9A%84k8s%E4%B8%ADpod%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7kubectl-debug/</link>
      <pubDate>Fri, 18 Feb 2022 11:24:51 +0000</pubDate>
      
      <guid>https://iblog.zone/archives/%E8%B6%85%E5%A5%BD%E7%94%A8%E7%9A%84k8s%E4%B8%ADpod%E8%AF%8A%E6%96%AD%E5%B7%A5%E5%85%B7kubectl-debug/</guid>
      <description>背景 容器技术的一个最佳实践是构建尽可能精简的容器镜像。但这一实践却会给排查问题带来麻烦：精简后的容器中普遍缺失常用的排障工具，部分容器里甚至没有 shell (比如 FROM scratch ）。 在这种状况下，我们只能通过日志或者到宿主机上通过 docker-cli 或 nsenter 来排查问题，效率很低，在K8s环境部署应用后，经常遇到需要进入pod进行排错。除了查看pod logs和describe方式之外，传统的解决方式是在业务pod基础镜像中提前安装好procps、net-tools、tcpdump、vim等工具。但这样既不符合最小化镜像原则，又徒增Pod安全漏洞风险。
今天为大家推荐一款K8s pod诊断工具，kubectl-debug是一个简单、易用、强大的 kubectl 插件, 能够帮助你便捷地进行 Kubernetes 上的 Pod 排障诊断。它通过启动一个排错工具容器，并将其加入到目标业务容器的pid, network, user 以及 ipc namespace 中，这时我们就可以在新容器中直接用 netstat, tcpdump 这些熟悉的工具来解决问题了, 而业务容器可以保持最小化, 不需要预装任何额外的排障工具。 kubectl-debug 主要包含以下两部分:
 kubectl-debug：命令行工具 debug-agent：部署在K8s的node上，用于启动关联排错工具容器  工作原理 我们知道，容器本质上是带有 cgroup 资源限制和 namespace 隔离的一组进程。因此，我们只要启动一个进程，并且让这个进程加入到目标容器的各种 namespace 中，这个进程就能 “进入容器内部”（注意引号），与容器中的进程”看到”相同的根文件系统、虚拟网卡、进程空间了——这也正是 docker exec 和 kubectl exec 等命令的运行方式。
现在的状况是，我们不仅要 “进入容器内部”，还希望带一套工具集进去帮忙排查问题。那么，想要高效管理一套工具集，又要可以跨平台，最好的办法就是把工具本身都打包在一个容器镜像当中。 接下来，我们只需要通过这个”工具镜像”启动容器，再指定这个容器加入目标容器的的各种 namespace，自然就实现了 “携带一套工具集进入容器内部”。事实上，使用 docker-cli 就可以实现这个操作：
export TARGET_ID=666666666 # 加入目标容器的 network, pid 以及 ipc namespace docker run -it --network=container:$TARGET_ID --pid=container:$TARGET_ID --ipc=container:$TARGET_ID busybox 这就是 kubectl-debug 的出发点： 用工具容器来诊断业务容器 。背后的设计思路和 sidecar 等模式是一致的：每个容器只做一件事情。</description>
    </item>
    
  </channel>
</rss>
